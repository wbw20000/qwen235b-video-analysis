"""
äº‹æ•…åˆ†æè‡ªåŠ¨è¯Šæ–­æŠ¥å‘Šç³»ç»Ÿ

æ¯æ¬¡pipelineè¿è¡Œåè‡ªåŠ¨ç”Ÿæˆï¼š
- report.md: äººç±»å¯è¯»çš„è¯Šæ–­æŠ¥å‘Š
- report.json: æœºå™¨å¯è¯»çš„å®Œæ•´æŠ¥å‘Š
- summary.json: ç®€è¦æ‘˜è¦
- stage_stats.json: å„é˜¶æ®µç»Ÿè®¡
- config_snapshot.yaml: é…ç½®å¿«ç…§
- env.txt: ç¯å¢ƒä¿¡æ¯
- clips/<clip_id>/: è¯æ®ç›®å½•
"""

import json
import os
import subprocess
import sys
import platform
import hashlib
from dataclasses import dataclass, field, asdict
from datetime import datetime, timezone
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple
import statistics

try:
    import yaml
    HAS_YAML = True
except ImportError:
    HAS_YAML = False

try:
    import numpy as np
    HAS_NUMPY = True
except ImportError:
    HAS_NUMPY = False


# ============ JSONå®‰å…¨åºåˆ—åŒ– ============

def safe_json_serialize(obj: Any) -> Any:
    """é€’å½’è½¬æ¢numpy/tensorç­‰ç±»å‹ä¸ºPythonåŸç”Ÿç±»å‹ï¼Œé¿å…json.dumpå´©æºƒ"""
    if HAS_NUMPY:
        import numpy as np
        if isinstance(obj, (np.bool_, )):
            return bool(obj)
        elif isinstance(obj, (np.integer, np.int32, np.int64, np.int16, np.int8)):
            return int(obj)
        elif isinstance(obj, (np.floating, np.float32, np.float64, np.float16)):
            return float(obj)
        elif isinstance(obj, np.ndarray):
            return obj.tolist()

    # PyTorch tensor
    if hasattr(obj, 'item') and callable(obj.item):
        try:
            return obj.item()
        except (ValueError, RuntimeError):
            pass
    if hasattr(obj, 'tolist') and callable(obj.tolist):
        try:
            return obj.tolist()
        except (ValueError, RuntimeError):
            pass

    # åŸºæœ¬ç±»å‹
    if isinstance(obj, bool):
        return bool(obj)
    elif isinstance(obj, (int, float, str, type(None))):
        return obj
    elif isinstance(obj, dict):
        return {str(k): safe_json_serialize(v) for k, v in obj.items()}
    elif isinstance(obj, (list, tuple)):
        return [safe_json_serialize(i) for i in obj]
    elif isinstance(obj, datetime):
        return obj.isoformat()
    elif isinstance(obj, Path):
        return str(obj)
    elif hasattr(obj, '__dict__'):
        return safe_json_serialize(vars(obj))
    else:
        # å…œåº•ï¼šè½¬å­—ç¬¦ä¸²
        return str(obj)


def safe_json_dumps(obj: Any, **kwargs) -> str:
    """å®‰å…¨çš„json.dumpsï¼Œè‡ªåŠ¨å¤„ç†numpyç­‰ç±»å‹"""
    return json.dumps(safe_json_serialize(obj), **kwargs)


def safe_json_dump(obj: Any, fp, **kwargs):
    """å®‰å…¨çš„json.dumpï¼Œè‡ªåŠ¨å¤„ç†numpyç­‰ç±»å‹"""
    json.dump(safe_json_serialize(obj), fp, **kwargs)


# ============ è¿è¡Œä¸Šä¸‹æ–‡ ============

@dataclass
class StageStats:
    """å•é˜¶æ®µç»Ÿè®¡"""
    name: str
    duration_sec: float = 0.0
    success: bool = True
    input_count: int = 0
    output_count: int = 0
    skipped_count: int = 0
    error_count: int = 0
    details: Dict[str, Any] = field(default_factory=dict)

    def to_dict(self) -> Dict:
        return asdict(self)


@dataclass
class RunContext:
    """è¿è¡Œä¸Šä¸‹æ–‡ï¼Œæ”¶é›†pipelineè¿è¡Œä¿¡æ¯"""
    run_id: str = ""
    start_time: Optional[datetime] = None
    end_time: Optional[datetime] = None
    mode: str = ""  # "accident" | "violation"
    camera_id: str = ""
    date_str: str = ""

    # é…ç½®å¿«ç…§
    config_snapshot: Dict[str, Any] = field(default_factory=dict)

    # å„é˜¶æ®µç»Ÿè®¡
    stages: Dict[str, StageStats] = field(default_factory=dict)

    # å…³é”®è®¡æ•°
    n_source_videos: int = 0
    n_clips_cut: int = 0
    n_preprocessed: int = 0
    n_pass_score: int = 0
    n_vlm_analyzed: int = 0
    n_kept: int = 0
    n_topk: int = 0

    # é˜ˆå€¼
    clip_score_threshold: float = 0.0
    skip_low_score_vlm: bool = True
    top_clips: int = 3

    def generate_run_id(self) -> str:
        """ç”Ÿæˆrun_id: UTCæ—¶é—´æˆ³ + gitçŸ­hash"""
        ts = datetime.now(timezone.utc).strftime("%Y%m%d_%H%M%S")
        git_hash = self._get_git_short_hash()
        self.run_id = f"{ts}_{git_hash}"
        return self.run_id

    def _get_git_short_hash(self) -> str:
        """è·å–gitçŸ­hash"""
        try:
            result = subprocess.run(
                ["git", "rev-parse", "--short", "HEAD"],
                capture_output=True, text=True, timeout=5
            )
            if result.returncode == 0:
                return result.stdout.strip()
        except Exception:
            pass
        return "nogit"

    def add_stage(self, name: str, **kwargs) -> StageStats:
        """æ·»åŠ é˜¶æ®µç»Ÿè®¡"""
        stage = StageStats(name=name, **kwargs)
        self.stages[name] = stage
        return stage

    def get_total_duration(self) -> float:
        """è·å–æ€»è€—æ—¶"""
        if self.start_time and self.end_time:
            return (self.end_time - self.start_time).total_seconds()
        return sum(s.duration_sec for s in self.stages.values())

    def to_dict(self) -> Dict:
        return {
            "run_id": self.run_id,
            "start_time": self.start_time.isoformat() if self.start_time else None,
            "end_time": self.end_time.isoformat() if self.end_time else None,
            "total_duration_sec": self.get_total_duration(),
            "mode": self.mode,
            "camera_id": self.camera_id,
            "date_str": self.date_str,
            "counts": {
                "n_source_videos": self.n_source_videos,
                "n_clips_cut": self.n_clips_cut,
                "n_preprocessed": self.n_preprocessed,
                "n_pass_score": self.n_pass_score,
                "n_vlm_analyzed": self.n_vlm_analyzed,
                "n_kept": self.n_kept,
                "n_topk": self.n_topk,
            },
            "thresholds": {
                "clip_score_threshold": self.clip_score_threshold,
                "skip_low_score_vlm": self.skip_low_score_vlm,
                "top_clips": self.top_clips,
            },
            "stages": {k: v.to_dict() for k, v in self.stages.items()},
        }


# ============ Clipç»“æœ ============

@dataclass
class ClipResult:
    """å•ä¸ªclipçš„åˆ†æç»“æœ"""
    clip_id: str
    video_path: str = ""
    start_time: float = 0.0
    end_time: float = 0.0
    duration: float = 0.0

    # åˆ†æ•°
    clip_score: float = 0.0
    accident_score: float = 0.0
    final_score: float = 0.0
    coverage_score: float = 0.0
    coverage_effective: float = 0.0  # æœ‰æ•ˆè¦†ç›–åº¦
    t0: float = 0.0                  # ç¢°æ’æ—¶åˆ»ä¼°è®¡
    t0_validity: float = 0.0
    rank_score: float = 0.0          # å”¯ä¸€æ’åºä¸»åˆ†
    rank: int = 0                    # æ’å

    # è¿‡æ»¤çŠ¶æ€
    filter_status: str = "UNKNOWN"  # PASSED | SKIPPED | NOT_SELECTED
    skip_reason: str = ""

    # VLMç»“æœ
    vlm_verdict: str = ""  # YES | NO | POST_EVENT_ONLY | UNCERTAIN
    vlm_confidence: float = 0.0
    kept: bool = False
    keep_reason: str = ""

    # è¯æ®è·¯å¾„
    evidence_dir: str = ""
    frames_raw: List[str] = field(default_factory=list)
    frames_annotated: List[str] = field(default_factory=list)
    vlm_request_path: str = ""
    vlm_response_path: str = ""

    def to_dict(self) -> Dict:
        return asdict(self)


# ============ çŸ­è·¯è¯Šæ–­ ============

@dataclass
class RunGate:
    """è¿è¡Œé—¨ç¦æ£€æŸ¥ç‚¹"""
    name: str
    passed: bool
    value: Any = None
    threshold: Any = None
    message: str = ""
    severity: str = "INFO"  # INFO | WARN | FAIL

    def to_dict(self) -> Dict:
        return asdict(self)


class ShortCircuitDiagnostics:
    """çŸ­è·¯è¯Šæ–­å™¨ï¼šåˆ†æä¸ºä½•æ²¡æœ‰clipè¿›å…¥VLM"""

    def __init__(self, context: RunContext, clip_results: List[ClipResult]):
        self.context = context
        self.clip_results = clip_results
        self.gates: List[RunGate] = []

    def run_diagnostics(self) -> Tuple[str, List[RunGate]]:
        """è¿è¡Œè¯Šæ–­ï¼Œè¿”å› (æ€»ä½“ç»“è®º, é—¨ç¦åˆ—è¡¨)"""
        self.gates = []

        # Gate 1: æ˜¯å¦æœ‰æºè§†é¢‘
        self._check_source_videos()

        # Gate 2: æ˜¯å¦æˆåŠŸå‰ªè¾‘clips
        self._check_clips_cut()

        # Gate 3: Top-Ké€‰æ‹©
        self._check_topk_selection()

        # Gate 4: clip_scoreé˜ˆå€¼è¿‡æ»¤
        self._check_score_threshold()

        # Gate 5: VLMè¾“å…¥æ•°é‡
        self._check_vlm_input()

        # Gate 6: VLM verdictåˆ†å¸ƒ
        self._check_vlm_verdicts()

        # è®¡ç®—æ€»ä½“ç»“è®º
        conclusion = self._compute_conclusion()

        return conclusion, self.gates

    def _check_source_videos(self):
        n = self.context.n_source_videos
        gate = RunGate(
            name="source_videos",
            passed=n > 0,
            value=n,
            threshold=">0",
            severity="FAIL" if n == 0 else "INFO"
        )
        if n == 0:
            gate.message = "æ— æºè§†é¢‘è¾“å…¥"
        else:
            gate.message = f"æºè§†é¢‘æ•°: {n}"
        self.gates.append(gate)

    def _check_clips_cut(self):
        n = self.context.n_clips_cut
        gate = RunGate(
            name="clips_cut",
            passed=n > 0,
            value=n,
            threshold=">0",
            severity="FAIL" if n == 0 else "INFO"
        )
        if n == 0:
            gate.message = "å‰ªè¾‘é˜¶æ®µæœªç”Ÿæˆä»»ä½•clip"
        else:
            gate.message = f"æˆåŠŸå‰ªè¾‘: {n} clips"
        self.gates.append(gate)

    def _check_topk_selection(self):
        """æ£€æŸ¥Top-Ké€‰æ‹©"""
        n_cut = self.context.n_clips_cut
        n_preprocess = self.context.n_preprocessed
        top_k = self.context.top_clips

        gate = RunGate(
            name="topk_selection",
            passed=True,
            value=n_preprocess,
            threshold=f"top_clips={top_k}",
            severity="INFO"
        )

        if n_preprocess < n_cut:
            gate.message = f"Top-Kæˆªæ–­: {n_cut} clips -> åªé¢„å¤„ç†å‰ {n_preprocess} ä¸ª (top_clips={top_k})"
            if n_cut > top_k:
                gate.severity = "WARN"
        else:
            gate.message = f"å…¨éƒ¨ {n_preprocess} clipsè¿›å…¥é¢„å¤„ç†"

        self.gates.append(gate)

    def _check_score_threshold(self):
        """æ£€æŸ¥clip_scoreé˜ˆå€¼è¿‡æ»¤"""
        threshold = self.context.clip_score_threshold
        skip_enabled = self.context.skip_low_score_vlm

        # ç»Ÿè®¡åˆ†æ•°åˆ†å¸ƒ
        scores = [c.clip_score for c in self.clip_results if c.clip_score > 0]
        skipped = [c for c in self.clip_results if c.filter_status == "SKIPPED"]
        passed = [c for c in self.clip_results if c.filter_status == "PASSED"]

        gate = RunGate(
            name="clip_score_threshold",
            passed=len(passed) > 0 or not skip_enabled,
            value=len(passed),
            threshold=f"clip_score >= {threshold}" if skip_enabled else "disabled",
            severity="FAIL" if (skip_enabled and len(passed) == 0 and len(skipped) > 0) else "INFO"
        )

        if not skip_enabled:
            gate.message = "é˜ˆå€¼è¿‡æ»¤å·²ç¦ç”¨"
        elif len(skipped) == 0:
            gate.message = f"æ— clipè¢«é˜ˆå€¼è¿‡æ»¤ (threshold={threshold})"
        else:
            # è®¡ç®—åˆ†å¸ƒç»Ÿè®¡
            if scores:
                score_min = min(scores)
                score_max = max(scores)
                score_median = statistics.median(scores) if scores else 0
                score_mean = statistics.mean(scores) if scores else 0
            else:
                score_min = score_max = score_median = score_mean = 0

            gate.message = (
                f"é˜ˆå€¼è¿‡æ»¤: {len(skipped)}/{len(self.clip_results)} clipsè¢«è·³è¿‡\n"
                f"  é˜ˆå€¼: {threshold}\n"
                f"  åˆ†æ•°åˆ†å¸ƒ: min={score_min:.3f}, median={score_median:.3f}, max={score_max:.3f}\n"
                f"  é€šè¿‡: {len(passed)}, è·³è¿‡: {len(skipped)}"
            )

            gate.details = {
                "threshold": threshold,
                "total": len(self.clip_results),
                "passed": len(passed),
                "skipped": len(skipped),
                "score_distribution": {
                    "min": score_min,
                    "max": score_max,
                    "median": score_median,
                    "mean": score_mean,
                }
            }

        self.gates.append(gate)

    def _check_vlm_input(self):
        """æ£€æŸ¥VLMè¾“å…¥æ•°é‡"""
        n = self.context.n_vlm_analyzed

        gate = RunGate(
            name="vlm_input_clips",
            passed=n > 0,
            value=n,
            threshold=">0",
            severity="FAIL" if n == 0 else "INFO"
        )

        if n == 0:
            # åˆ†æåŸå› 
            reasons = []
            if self.context.n_clips_cut == 0:
                reasons.append("æ— å‰ªè¾‘è¾“å‡º")
            elif self.context.n_preprocessed == 0:
                reasons.append("Top-Kä¸º0æˆ–æ— clip")
            else:
                # æ£€æŸ¥æ˜¯å¦å…¨éƒ¨è¢«é˜ˆå€¼è¿‡æ»¤
                skipped = [c for c in self.clip_results if c.filter_status == "SKIPPED"]
                if len(skipped) == self.context.n_preprocessed:
                    reasons.append(f"å…¨éƒ¨ {len(skipped)} clipså› clip_score < {self.context.clip_score_threshold}è¢«è·³è¿‡")

            gate.message = f"0 clipsè¿›å…¥VLM! åŸå› : {'; '.join(reasons) if reasons else 'æœªçŸ¥'}"
        else:
            gate.message = f"{n} clipsé€å…¥VLMåˆ†æ"

        self.gates.append(gate)

    def _check_vlm_verdicts(self):
        """æ£€æŸ¥VLM verdictåˆ†å¸ƒ"""
        verdicts = [c.vlm_verdict for c in self.clip_results if c.vlm_verdict]
        if not verdicts:
            return

        from collections import Counter
        dist = Counter(verdicts)

        n_yes = dist.get("YES", 0)
        n_no = dist.get("NO", 0)
        n_post = dist.get("POST_EVENT_ONLY", 0)
        n_uncertain = dist.get("UNCERTAIN", 0)

        gate = RunGate(
            name="vlm_verdicts",
            passed=True,
            value=dict(dist),
            threshold="N/A",
            severity="INFO"
        )

        gate.message = f"VLMåˆ¤å†³åˆ†å¸ƒ: YES={n_yes}, NO={n_no}, POST_EVENT_ONLY={n_post}, UNCERTAIN={n_uncertain}"
        self.gates.append(gate)

    def _compute_conclusion(self) -> str:
        """è®¡ç®—æ€»ä½“ç»“è®º"""
        has_fail = any(g.severity == "FAIL" for g in self.gates)
        has_warn = any(g.severity == "WARN" for g in self.gates)

        if has_fail:
            return "FAIL"
        elif has_warn:
            return "WARN"
        else:
            return "PASS"

    def get_near_miss_clips(self, top_n: int = 10) -> List[Dict]:
        """è·å–æœ€æ¥è¿‘é˜ˆå€¼çš„Top N clipsï¼ˆNear Missåˆ†æï¼‰"""
        threshold = self.context.clip_score_threshold

        # ç­›é€‰è¢«è·³è¿‡çš„clipsï¼ŒæŒ‰clip_scoreé™åºæ’åˆ—
        skipped = [
            c for c in self.clip_results
            if c.filter_status == "SKIPPED" and c.clip_score > 0
        ]
        skipped.sort(key=lambda x: x.clip_score, reverse=True)

        near_miss = []
        for c in skipped[:top_n]:
            gap = threshold - c.clip_score
            near_miss.append({
                "clip_id": c.clip_id,
                "clip_score": c.clip_score,
                "gap_to_threshold": gap,
                "threshold": threshold,
                "would_pass_at": c.clip_score - 0.001,  # åªéœ€é™ä½é˜ˆå€¼åˆ°è¿™ä¸ªå€¼å³å¯é€šè¿‡
            })

        return near_miss

    def generate_recommendations(self) -> List[str]:
        """åŸºäºè¯Šæ–­ç»“æœç”Ÿæˆå»ºè®®"""
        recommendations = []

        # æ£€æŸ¥æ˜¯å¦æœ‰0 clipsè¿›å…¥VLMçš„æƒ…å†µ
        vlm_gate = next((g for g in self.gates if g.name == "vlm_input_clips"), None)
        if vlm_gate and not vlm_gate.passed:
            # æ£€æŸ¥æ˜¯å¦å› ä¸ºé˜ˆå€¼è¿‡æ»¤
            score_gate = next((g for g in self.gates if g.name == "clip_score_threshold"), None)
            if score_gate and hasattr(score_gate, 'details') and score_gate.details:
                details = score_gate.details
                if details.get("skipped", 0) > 0:
                    threshold = details["threshold"]
                    score_max = details["score_distribution"]["max"]

                    # å»ºè®®1ï¼šé™ä½é˜ˆå€¼
                    if score_max > 0:
                        suggested_threshold = max(0.15, score_max - 0.05)
                        recommendations.append(
                            f"å»ºè®®ä¸´æ—¶é™ä½clip_score_thresholdä»{threshold}åˆ°{suggested_threshold:.2f}ï¼Œ"
                            f"ä»¥ä¾¿åˆ†ææœ€é«˜åˆ†çš„clips"
                        )

                    # å»ºè®®2ï¼šç¦ç”¨é˜ˆå€¼è¿‡æ»¤
                    recommendations.append(
                        "æˆ–è®¾ç½® skip_low_score_vlm=False ç¦ç”¨é˜ˆå€¼è¿‡æ»¤ï¼Œå¼ºåˆ¶æ‰€æœ‰clipsé€VLM"
                    )

                    # å»ºè®®3ï¼šä¿ç•™TopKå…œåº•
                    recommendations.append(
                        "æˆ–å®ç°'TopKå…œåº•'é€»è¾‘ï¼šå³ä½¿åˆ†æ•°ä½äºé˜ˆå€¼ï¼Œä¹Ÿä¿ç•™Top3 clipsé€VLM"
                    )

        return recommendations


# ============ æŠ¥å‘Šç”Ÿæˆå™¨ ============

class ReportBuilder:
    """è¯Šæ–­æŠ¥å‘Šç”Ÿæˆå™¨"""

    def __init__(
        self,
        context: RunContext,
        clip_results: List[ClipResult],
        output_dir: str = "reports",
        vlm_results: Optional[List[Dict]] = None,
    ):
        self.context = context
        self.clip_results = clip_results
        self.vlm_results = vlm_results or []

        # ç¡®ä¿run_idå­˜åœ¨
        if not context.run_id:
            context.generate_run_id()

        self.output_dir = Path(output_dir) / context.run_id
        self.output_dir.mkdir(parents=True, exist_ok=True)

        # è¯Šæ–­å™¨
        self.diagnostics = ShortCircuitDiagnostics(context, clip_results)

    def build(self) -> str:
        """ç”Ÿæˆå®Œæ•´æŠ¥å‘Šï¼Œè¿”å›æŠ¥å‘Šç›®å½•è·¯å¾„"""
        try:
            # 1. è¿è¡Œè¯Šæ–­
            conclusion, gates = self.diagnostics.run_diagnostics()
            near_miss = self.diagnostics.get_near_miss_clips()
            recommendations = self.diagnostics.generate_recommendations()

            # 2. ç”Ÿæˆå„æ–‡ä»¶
            self._write_env_txt()
            self._write_config_snapshot()
            self._write_stage_stats()
            self._write_clip_evidence()
            self._write_summary_json(conclusion, gates, near_miss, recommendations)
            self._write_report_json(conclusion, gates, near_miss, recommendations)
            self._write_report_md(conclusion, gates, near_miss, recommendations)

            print(f"\n[ReportBuilder] è¯Šæ–­æŠ¥å‘Šå·²ç”Ÿæˆ: {self.output_dir}")
            return str(self.output_dir)

        except Exception as e:
            print(f"[ReportBuilder] æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return ""

    def _write_env_txt(self):
        """å†™å…¥ç¯å¢ƒä¿¡æ¯"""
        env_file = self.output_dir / "env.txt"
        lines = [
            f"Platform: {platform.platform()}",
            f"Python: {sys.version}",
            f"Working Dir: {os.getcwd()}",
            f"Run ID: {self.context.run_id}",
            f"Start Time: {self.context.start_time}",
            f"End Time: {self.context.end_time}",
        ]

        # GPUä¿¡æ¯
        try:
            import torch
            if torch.cuda.is_available():
                lines.append(f"CUDA: {torch.version.cuda}")
                lines.append(f"GPU: {torch.cuda.get_device_name(0)}")
                lines.append(f"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
        except ImportError:
            lines.append("PyTorch: Not installed")

        with open(env_file, "w", encoding="utf-8") as f:
            f.write("\n".join(lines))

    def _write_config_snapshot(self):
        """å†™å…¥é…ç½®å¿«ç…§"""
        config_file = self.output_dir / "config_snapshot.yaml"

        config_data = self.context.config_snapshot
        if not config_data:
            config_data = {
                "clip_score_threshold": self.context.clip_score_threshold,
                "skip_low_score_vlm": self.context.skip_low_score_vlm,
                "top_clips": self.context.top_clips,
            }

        if HAS_YAML:
            with open(config_file, "w", encoding="utf-8") as f:
                yaml.dump(safe_json_serialize(config_data), f, allow_unicode=True, default_flow_style=False)
        else:
            # fallback to JSON
            config_file = self.output_dir / "config_snapshot.json"
            with open(config_file, "w", encoding="utf-8") as f:
                safe_json_dump(config_data, f, ensure_ascii=False, indent=2)

    def _write_stage_stats(self):
        """å†™å…¥é˜¶æ®µç»Ÿè®¡"""
        stats_file = self.output_dir / "stage_stats.json"

        stages_data = {}
        for name, stage in self.context.stages.items():
            stages_data[name] = stage.to_dict()

        # ç¡®ä¿å…³é”®é˜¶æ®µéƒ½æœ‰è®°å½•
        required_stages = [
            "embedding", "clip_sampler", "yolo", "preprocess_filter",
            "frame_sampling", "vlm", "ranking"
        ]
        for stage_name in required_stages:
            if stage_name not in stages_data:
                stages_data[stage_name] = {
                    "name": stage_name,
                    "duration_sec": 0.0,
                    "success": True,
                    "input_count": 0,
                    "output_count": 0,
                    "details": {"note": "æœªæ‰§è¡Œæˆ–æœªè®°å½•"}
                }

        with open(stats_file, "w", encoding="utf-8") as f:
            safe_json_dump(stages_data, f, ensure_ascii=False, indent=2)

    def _write_clip_evidence(self):
        """å†™å…¥clipè¯æ®ç›®å½•"""
        clips_dir = self.output_dir / "clips"
        clips_dir.mkdir(exist_ok=True)

        for clip in self.clip_results:
            clip_dir = clips_dir / clip.clip_id
            clip_dir.mkdir(exist_ok=True)

            # clip_meta.json
            meta = {
                "clip_id": clip.clip_id,
                "video_path": clip.video_path,
                "time_range": f"{clip.start_time:.1f}s - {clip.end_time:.1f}s",
                "duration": clip.duration,
                "clip_score": clip.clip_score,
                "accident_score": clip.accident_score,
                "final_score": clip.final_score,
                "filter_status": clip.filter_status,
                "skip_reason": clip.skip_reason,
                "thresholds_snapshot": {
                    "clip_score_threshold": self.context.clip_score_threshold,
                    "skip_low_score_vlm": self.context.skip_low_score_vlm,
                },
                "vlm_verdict": clip.vlm_verdict,
                "vlm_confidence": clip.vlm_confidence,
                "kept": clip.kept,
                "keep_reason": clip.keep_reason,
            }

            with open(clip_dir / "clip_meta.json", "w", encoding="utf-8") as f:
                safe_json_dump(meta, f, ensure_ascii=False, indent=2)

            # å¯¹äºSKIPPEDçš„clipï¼Œç”Ÿæˆå ä½è¯´æ˜
            if clip.filter_status == "SKIPPED":
                with open(clip_dir / "SKIPPED_README.txt", "w", encoding="utf-8") as f:
                    f.write(f"æ­¤clipå›  {clip.skip_reason} è¢«è·³è¿‡ï¼Œæœªæ‰§è¡ŒæŠ½å¸§/VLMåˆ†æ\n")
                    f.write(f"clip_score: {clip.clip_score}\n")
                    f.write(f"é˜ˆå€¼: {self.context.clip_score_threshold}\n")

    def _write_summary_json(self, conclusion, gates, near_miss, recommendations):
        """å†™å…¥ç®€è¦æ‘˜è¦"""
        summary_file = self.output_dir / "summary.json"

        summary = {
            "run_id": self.context.run_id,
            "conclusion": conclusion,
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "mode": self.context.mode,
            "camera_id": self.context.camera_id,
            "total_duration_sec": self.context.get_total_duration(),
            "counts": {
                "n_source_videos": self.context.n_source_videos,
                "n_clips_cut": self.context.n_clips_cut,
                "n_preprocessed": self.context.n_preprocessed,
                "n_pass_score": self.context.n_pass_score,
                "n_vlm_analyzed": self.context.n_vlm_analyzed,
                "n_kept": self.context.n_kept,
            },
            "gates_summary": [
                {"name": g.name, "passed": g.passed, "severity": g.severity}
                for g in gates
            ],
            "has_near_miss": len(near_miss) > 0,
            "near_miss_count": len(near_miss),
            "recommendations_count": len(recommendations),
        }

        with open(summary_file, "w", encoding="utf-8") as f:
            safe_json_dump(summary, f, ensure_ascii=False, indent=2)

    def _write_report_json(self, conclusion, gates, near_miss, recommendations):
        """å†™å…¥å®Œæ•´JSONæŠ¥å‘Š"""
        report_file = self.output_dir / "report.json"

        report = {
            "run_id": self.context.run_id,
            "conclusion": conclusion,
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "context": self.context.to_dict(),
            "gates": [g.to_dict() for g in gates],
            "near_miss_clips": near_miss,
            "recommendations": recommendations,
            "clips": [c.to_dict() for c in self.clip_results],
        }

        with open(report_file, "w", encoding="utf-8") as f:
            safe_json_dump(report, f, ensure_ascii=False, indent=2)

    def _write_report_md(self, conclusion, gates, near_miss, recommendations):
        """å†™å…¥MarkdownæŠ¥å‘Š"""
        report_file = self.output_dir / "report.md"

        lines = []

        # æ ‡é¢˜
        lines.append(f"# äº‹æ•…åˆ†æè¯Šæ–­æŠ¥å‘Š")
        lines.append("")
        lines.append(f"**Run ID**: `{self.context.run_id}`")
        lines.append(f"**æ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        lines.append(f"**æ¨¡å¼**: {self.context.mode}")
        lines.append(f"**ç›¸æœº**: {self.context.camera_id}")
        lines.append("")

        # æ€»ä½“ç»“è®º
        conclusion_emoji = {"PASS": "âœ…", "WARN": "âš ï¸", "FAIL": "âŒ"}.get(conclusion, "â“")
        lines.append(f"## {conclusion_emoji} æ€»ä½“ç»“è®º: **{conclusion}**")
        lines.append("")

        # å…³é”®è®¡æ•°
        lines.append("### å…³é”®è®¡æ•°")
        lines.append("")
        lines.append("| æŒ‡æ ‡ | å€¼ |")
        lines.append("|------|-----|")
        lines.append(f"| æºè§†é¢‘æ•° | {self.context.n_source_videos} |")
        lines.append(f"| å‰ªè¾‘clips | {self.context.n_clips_cut} |")
        lines.append(f"| é¢„å¤„ç†clips | {self.context.n_preprocessed} |")
        lines.append(f"| é€šè¿‡é˜ˆå€¼ | {self.context.n_pass_score} |")
        lines.append(f"| VLMåˆ†æ | {self.context.n_vlm_analyzed} |")
        lines.append(f"| æœ€ç»ˆä¿ç•™ | {self.context.n_kept} |")
        lines.append("")

        # Run Gatesï¼ˆçŸ­è·¯è¯Šæ–­ï¼‰
        lines.append("## ğŸš¦ Run Gatesï¼ˆçŸ­è·¯è¯Šæ–­ï¼‰")
        lines.append("")

        for gate in gates:
            emoji = {"PASS": "âœ…", "WARN": "âš ï¸", "FAIL": "âŒ", "INFO": "â„¹ï¸"}.get(
                "PASS" if gate.passed else gate.severity, "â“"
            )
            if gate.severity == "FAIL":
                lines.append(f"### {emoji} **[FAIL] {gate.name}**")
            elif gate.severity == "WARN":
                lines.append(f"### {emoji} **[WARN] {gate.name}**")
            else:
                lines.append(f"### {emoji} {gate.name}")

            lines.append("")
            lines.append(f"- **å€¼**: `{gate.value}`")
            lines.append(f"- **é˜ˆå€¼**: `{gate.threshold}`")

            # å¤šè¡Œmessage
            for msg_line in gate.message.split("\n"):
                lines.append(f"- {msg_line}")
            lines.append("")

        # Near Missåˆ†æ
        if near_miss:
            lines.append("## ğŸ¯ Near Missåˆ†æï¼ˆæœ€æ¥è¿‘é˜ˆå€¼çš„clipsï¼‰")
            lines.append("")
            lines.append("ä»¥ä¸‹clipsçš„clip_scoreæœ€æ¥è¿‘é˜ˆå€¼ï¼Œç¨å¾®é™ä½é˜ˆå€¼å³å¯é€šè¿‡ï¼š")
            lines.append("")
            lines.append("| Rank | Clip ID | clip_score | è·é˜ˆå€¼ | å»ºè®®é˜ˆå€¼ |")
            lines.append("|------|---------|------------|--------|----------|")

            for i, nm in enumerate(near_miss, 1):
                lines.append(
                    f"| {i} | `{nm['clip_id']}` | {nm['clip_score']:.3f} | "
                    f"{nm['gap_to_threshold']:.3f} | {nm['would_pass_at']:.3f} |"
                )
            lines.append("")

        # å»ºè®®
        if recommendations:
            lines.append("## ğŸ’¡ å»ºè®®")
            lines.append("")
            for i, rec in enumerate(recommendations, 1):
                lines.append(f"{i}. {rec}")
            lines.append("")

        # Clipåˆ—è¡¨
        lines.append("## ğŸ“‹ Clipåˆ—è¡¨")
        lines.append("")
        lines.append("| Clip ID | æ—¶é—´èŒƒå›´ | clip_score | çŠ¶æ€ | åŸå›  | VLM |")
        lines.append("|---------|----------|------------|------|------|-----|")

        for c in self.clip_results:
            time_range = f"{c.start_time:.1f}-{c.end_time:.1f}s"
            status_emoji = {"PASSED": "âœ…", "SKIPPED": "â­ï¸", "NOT_SELECTED": "â–"}.get(c.filter_status, "â“")
            vlm_info = c.vlm_verdict if c.vlm_verdict else "-"

            lines.append(
                f"| `{c.clip_id}` | {time_range} | {c.clip_score:.3f} | "
                f"{status_emoji} {c.filter_status} | {c.skip_reason or '-'} | {vlm_info} |"
            )
        lines.append("")

        # é˜¶æ®µç»Ÿè®¡
        lines.append("## â±ï¸ é˜¶æ®µç»Ÿè®¡")
        lines.append("")
        lines.append("| é˜¶æ®µ | è€—æ—¶(s) | è¾“å…¥ | è¾“å‡º | è·³è¿‡ | çŠ¶æ€ |")
        lines.append("|------|---------|------|------|------|------|")

        for name, stage in self.context.stages.items():
            status = "âœ…" if stage.success else "âŒ"
            lines.append(
                f"| {name} | {stage.duration_sec:.2f} | {stage.input_count} | "
                f"{stage.output_count} | {stage.skipped_count} | {status} |"
            )
        lines.append("")

        # å†™å…¥æ–‡ä»¶
        with open(report_file, "w", encoding="utf-8") as f:
            f.write("\n".join(lines))


# ============ ä¾¿æ·å‡½æ•° ============

def create_report_from_pipeline(
    pipeline_result: Dict,
    config: Any,
    output_dir: str = "reports",
    run_id: Optional[str] = None,
) -> str:
    """ä»pipelineç»“æœåˆ›å»ºæŠ¥å‘Šçš„ä¾¿æ·å‡½æ•°"""

    # åˆ›å»ºä¸Šä¸‹æ–‡
    context = RunContext()
    if run_id:
        context.run_id = run_id
    else:
        context.generate_run_id()

    # ä»configæå–é˜ˆå€¼
    if hasattr(config, 'vlm'):
        context.clip_score_threshold = getattr(config.vlm, 'clip_score_threshold', 0.35)
        context.skip_low_score_vlm = getattr(config.vlm, 'skip_low_score_vlm', True)
        context.top_clips = getattr(config.vlm, 'top_clips', 3)

    # ä»pipeline_resultæå–è®¡æ•°
    context.n_source_videos = pipeline_result.get("n_source_videos", 1)
    context.n_clips_cut = pipeline_result.get("n_clips_cut", 0)
    context.n_preprocessed = pipeline_result.get("n_preprocessed", 0)
    context.n_pass_score = pipeline_result.get("n_pass_score", 0)
    context.n_vlm_analyzed = pipeline_result.get("n_vlm_analyzed", 0)
    context.n_kept = pipeline_result.get("n_kept", 0)

    # è½¬æ¢clipç»“æœ
    clip_results = []
    for clip_data in pipeline_result.get("clips", []):
        clip = ClipResult(
            clip_id=clip_data.get("clip_id", "unknown"),
            video_path=clip_data.get("video_path", ""),
            start_time=clip_data.get("start_time", 0),
            end_time=clip_data.get("end_time", 0),
            duration=clip_data.get("duration", 0),
            clip_score=clip_data.get("clip_score", 0),
            accident_score=clip_data.get("accident_score", 0),
            filter_status=clip_data.get("filter_status", "UNKNOWN"),
            skip_reason=clip_data.get("skip_reason", ""),
            vlm_verdict=clip_data.get("vlm_verdict", ""),
            kept=clip_data.get("kept", False),
        )
        clip_results.append(clip)

    # ç”ŸæˆæŠ¥å‘Š
    builder = ReportBuilder(context, clip_results, output_dir)
    return builder.build()
