"""
Qwen3-VL è§†é¢‘åˆ†æ Web åº”ç”¨
é€šè¿‡é˜¿é‡Œäº‘ DashScope API è°ƒç”¨ Qwen3-VL æ¨¡å‹è¿›è¡Œè§†é¢‘åˆ†æ
"""

import sys
import io
import os

# è®¾ç½®æ ‡å‡†è¾“å‡ºä¸º UTF-8 ç¼–ç ï¼ˆWindows å…¼å®¹ï¼‰
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

# è®¾ç½® HuggingFace æ¨¡å‹ç¼“å­˜ç›®å½•ï¼Œé¿å…é‡å¤ä¸‹è½½
HF_CACHE_DIR = os.path.join(os.path.dirname(__file__), "models", "huggingface")
os.makedirs(HF_CACHE_DIR, exist_ok=True)
os.environ["HF_HOME"] = HF_CACHE_DIR
os.environ["TRANSFORMERS_CACHE"] = HF_CACHE_DIR

# æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²ç¼“å­˜ï¼Œå¦‚æœå·²ç¼“å­˜åˆ™å¯ç”¨ç¦»çº¿æ¨¡å¼
_siglip_cache_path = os.path.join(HF_CACHE_DIR, "hub", "models--google--siglip-base-patch16-384")
if os.path.exists(_siglip_cache_path):
    os.environ["HF_HUB_OFFLINE"] = "1"  # å¼ºåˆ¶ç¦»çº¿æ¨¡å¼ï¼Œä¸è”ç½‘æ£€æŸ¥æ›´æ–°
    print(f"[HuggingFace] âœ“ æ£€æµ‹åˆ°æœ¬åœ°ç¼“å­˜ï¼Œå¯ç”¨ç¦»çº¿æ¨¡å¼")
else:
    # ä½¿ç”¨å›½å†…é•œåƒåŠ é€Ÿä¸‹è½½
    os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"
    print(f"[HuggingFace] æœ¬åœ°ç¼“å­˜ä¸å­˜åœ¨ï¼Œä½¿ç”¨é•œåƒç«™ä¸‹è½½æ¨¡å‹...")
print(f"[HuggingFace] æ¨¡å‹ç¼“å­˜ç›®å½•: {HF_CACHE_DIR}")

from flask import Flask, render_template, request, jsonify, send_file, Response, stream_with_context
import os
import base64
import subprocess
import math
import re
import json
import time
import threading
from queue import Queue
from openai import OpenAI

# æ–°å¢ï¼šè§†é¢‘æŠ½å¸§ç›¸å…³å¯¼å…¥
import cv2
import numpy as np
from PIL import Image
import tempfile
import shutil
from datetime import datetime

# TrafficVLM æ¨¡å—
from traffic_vlm.pipeline import TrafficVLMPipeline
from traffic_vlm.config import TrafficVLMConfig

# å¯é€‰ï¼šé«˜çº§æŠ½å¸§åº“
try:
    import decord
    HAS_DECORD = True
except ImportError:
    HAS_DECORD = False
    print("è­¦å‘Š: æœªå®‰è£…decordï¼Œå°†ä½¿ç”¨OpenCVæå–å¸§ï¼ˆé€Ÿåº¦è¾ƒæ…¢ï¼‰")

try:
    from scenedetect import detect, ContentDetector
    HAS_SCENEDETECT = True
except ImportError:
    HAS_SCENEDETECT = False
    print("è­¦å‘Š: æœªå®‰è£…scenedetectï¼Œåœºæ™¯æ£€æµ‹åŠŸèƒ½å°†ä¸å¯ç”¨")

app = Flask(__name__)

# é…ç½®
UPLOAD_FOLDER = 'uploads'
ALLOWED_EXTENSIONS = {'mp4', 'avi', 'mkv', 'mov', 'flv', 'wmv'}
MAX_VIDEO_SIZE = 500 * 1024 * 1024  # 500MB

app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER
app.config['MAX_CONTENT_LENGTH'] = MAX_VIDEO_SIZE

# ä¸Šä¼ åˆ° API çš„åŸå§‹è§†é¢‘ç›®æ ‡å¤§å°ï¼ˆä¸º base64 å¢é•¿é¢„ç•™è£•é‡ï¼‰
TARGET_ORIGINAL_MB = float(os.getenv('TARGET_ORIGINAL_MB', '7.2'))
# è‡ªé€‚åº”å‹ç¼©æœ€å¤§é‡è¯•æ¬¡æ•°
MAX_COMPRESS_RETRY = int(os.getenv('MAX_COMPRESS_RETRY', '3'))

# åˆ›å»ºä¸Šä¼ æ–‡ä»¶å¤¹
os.makedirs(UPLOAD_FOLDER, exist_ok=True)

# å…¨å±€è¿›åº¦é˜Ÿåˆ—ï¼ˆç”¨äºSSEæ¨é€ï¼‰
progress_queues = {}

# å…¨å±€åœæ­¢æ ‡å¿—ï¼ˆç”¨äºä¸­æ–­åˆ†æï¼‰
stop_flags = {}


def is_stopped(session_id: str) -> bool:
    """æ£€æŸ¥ä¼šè¯æ˜¯å¦å·²è¢«è¯·æ±‚åœæ­¢"""
    return stop_flags.get(session_id, False)

# é˜¿é‡Œäº‘ DashScope API é…ç½®
# ä»ç¯å¢ƒå˜é‡è·å– API Keyï¼Œæˆ–è€…ç›´æ¥åœ¨è¿™é‡Œè®¾ç½®
DASHSCOPE_API_KEY = os.getenv('DASHSCOPE_API_KEY', 'sk-5175677ff9b4459aa45ce7ec28037515')

# å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨
AVAILABLE_MODELS = {
    'qwen-vl-max': 'Qwen-VL-Maxï¼ˆæœ€å¼ºè§†è§‰ç†è§£èƒ½åŠ›ï¼‰',
    'qwen-vl-plus': 'Qwen-VL-Plusï¼ˆæ¨èï¼Œæ€§ä»·æ¯”é«˜ï¼‰',
    'qwen3-vl-plus': 'Qwen3-VL-Plusï¼ˆæœ€æ–°ç‰ˆæœ¬ï¼‰',
    'qwen3-vl-32b-instruct': 'Qwen3-VL-32B-Instructï¼ˆé˜¿é‡Œäº‘éƒ¨ç½²ï¼‰',
    'qwen3-vl-32b-thinking': 'Qwen3-VL-32B-Thinkingï¼ˆé˜¿é‡Œäº‘éƒ¨ç½²ï¼Œæ€ç»´é“¾æ¨¡å¼ï¼‰',
    'qwen3-vl-235b-a22b-instruct': 'Qwen3-VL-235B-A22B-Instructï¼ˆé˜¿é‡Œäº‘éƒ¨ç½²ï¼‰',
    'qwen3-vl-235b-a22b-thinking': 'Qwen3-VL-235B-A22B-Thinkingï¼ˆé˜¿é‡Œäº‘éƒ¨ç½²ï¼‰'
}

def allowed_file(filename):
    """æ£€æŸ¥æ–‡ä»¶æ‰©å±•åæ˜¯å¦å…è®¸"""
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

def get_remote_model_id(model_key: str) -> str:
    """æ ¹æ®æœ¬åœ°æ¨¡å‹é”®è·å–è¿œç«¯æ¨¡å‹ IDï¼Œå¯ç”¨ç¯å¢ƒå˜é‡è¦†ç›–ã€‚
    ç¯å¢ƒå˜é‡å‘½åï¼šMODEL_ID_{KEY_UPPER_UNDERSCORE}
    ä¾‹å¦‚ï¼šMODEL_ID_QWEN3_VL_235B_A22B_THINKING / MODEL_ID_QWEN_VLMAX_20250813
    æœªè®¾ç½®åˆ™è¿”å›åŸå§‹é”®å€¼ã€‚
    """
    try:
        env_key = 'MODEL_ID_' + re.sub(r'[^A-Z0-9_]', '_', model_key.upper())
        return os.getenv(env_key, model_key)
    except Exception:
        return model_key

def encode_video_to_base64(video_path):
    """
    å°†è§†é¢‘æ–‡ä»¶ç¼–ç ä¸º base64 å­—ç¬¦ä¸²

    Args:
        video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„

    Returns:
        str: base64 ç¼–ç çš„è§†é¢‘å­—ç¬¦ä¸²
    """
    with open(video_path, "rb") as video_file:
        return base64.b64encode(video_file.read()).decode("utf-8")

def check_ffmpeg():
    """æ£€æŸ¥ FFmpeg æ˜¯å¦å®‰è£…"""
    try:
        # Windows ç³»ç»Ÿä¸Šéœ€è¦ä½¿ç”¨ shell=True æˆ–è€…å®Œæ•´è·¯å¾„
        if sys.platform == 'win32':
            result = subprocess.run(['ffmpeg', '-version'],
                                  capture_output=True,
                                  text=True,
                                  timeout=5,
                                  shell=True)
        else:
            result = subprocess.run(['ffmpeg', '-version'],
                                  capture_output=True,
                                  text=True,
                                  timeout=5)
        return result.returncode == 0
    except Exception as e:
        print(f"FFmpeg æ£€æµ‹é”™è¯¯: {str(e)}")
        return False

def check_nvenc_support():
    """æ£€æŸ¥ FFmpeg æ˜¯å¦æ”¯æŒ NVIDIA NVENC ç¡¬ä»¶åŠ é€Ÿ"""
    try:
        if sys.platform == 'win32':
            result = subprocess.run(['ffmpeg', '-encoders'],
                                  capture_output=True,
                                  text=True,
                                  timeout=5,
                                  shell=True)
        else:
            result = subprocess.run(['ffmpeg', '-encoders'],
                                  capture_output=True,
                                  text=True,
                                  timeout=5)

        # æ£€æŸ¥æ˜¯å¦æ”¯æŒ h264_nvenc
        return 'h264_nvenc' in result.stdout
    except Exception as e:
        print(f"NVENC æ£€æµ‹é”™è¯¯: {str(e)}")
        return False

def compress_video(input_path, output_path, target_size_mb=6.5, session_id=None):
    """
    ä½¿ç”¨ FFmpeg å‹ç¼©è§†é¢‘åˆ°ç›®æ ‡å¤§å°ï¼Œå¹¶å®æ—¶æŠ¥å‘Šè¿›åº¦

    Args:
        input_path: è¾“å…¥è§†é¢‘è·¯å¾„
        output_path: è¾“å‡ºè§†é¢‘è·¯å¾„
        target_size_mb: ç›®æ ‡æ–‡ä»¶å¤§å°ï¼ˆMBï¼‰
        session_id: ä¼šè¯IDï¼Œç”¨äºè¿›åº¦æ¨é€

    Returns:
        bool: æ˜¯å¦æˆåŠŸ
    """
    try:
        # å‘é€è¿›åº¦æ›´æ–°
        def send_progress(percent, message):
            if session_id and session_id in progress_queues:
                progress_queues[session_id].put({
                    'type': 'compress',
                    'progress': percent,
                    'message': message
                })

        send_progress(0, 'æ­£åœ¨åˆ†æè§†é¢‘...')

        # è·å–è§†é¢‘æ—¶é•¿
        probe_cmd = [
            'ffprobe',
            '-v', 'error',
            '-show_entries', 'format=duration',
            '-of', 'default=noprint_wrappers=1:nokey=1',
            input_path
        ]

        # Windows éœ€è¦ shell=True
        if sys.platform == 'win32':
            result = subprocess.run(probe_cmd, capture_output=True, text=True, timeout=30, shell=True)
        else:
            result = subprocess.run(probe_cmd, capture_output=True, text=True, timeout=30)
        duration = float(result.stdout.strip())

        print(f"è§†é¢‘æ—¶é•¿: {duration:.2f} ç§’")
        send_progress(10, f'è§†é¢‘æ—¶é•¿: {duration:.2f}ç§’')

        # è®¡ç®—ç›®æ ‡ç ç‡ï¼ˆè€ƒè™‘éŸ³é¢‘ç ç‡çº¦128kbpsï¼‰
        target_bitrate = int((target_size_mb * 8 * 1024) / duration - 128)
        if target_bitrate < 100:
            target_bitrate = 100  # æœ€ä½100kbps

        print(f"ç›®æ ‡è§†é¢‘ç ç‡: {target_bitrate} kbps")
        send_progress(15, 'å¼€å§‹å‹ç¼©è§†é¢‘...')

        # æ¨¡æ‹Ÿè¿›åº¦æ›´æ–°
        import threading

        # è·å–è¾“å…¥æ–‡ä»¶å¤§å°ï¼Œç”¨äºæ›´å‡†ç¡®çš„è¿›åº¦ä¼°ç®—
        input_size_mb = os.path.getsize(input_path) / (1024 * 1024)

        # åŠ¨æ€è®¾å®šåˆ†è¾¨ç‡/å¸§ç‡ç­–ç•¥ï¼ˆéšç›®æ ‡ç ç‡é™ä½ï¼‰
        # æœ€å°å®½åº¦854ï¼Œé¿å…è¿‡åº¦å‹ç¼©æŸå¤±ç»†èŠ‚
        scale_width = None
        output_fps = None
        if target_bitrate < 220:
            scale_width = 854  # æœ€å°å®½åº¦854
            output_fps = 15
        elif target_bitrate < 350:
            scale_width = 854  # æœ€å°å®½åº¦854
            output_fps = 20
        elif target_bitrate < 600:
            scale_width = 854
        elif target_bitrate < 1000:
            scale_width = 1280

        # æ£€æµ‹æ˜¯å¦æ”¯æŒ NVIDIA GPU åŠ é€Ÿ
        use_gpu = check_nvenc_support()

        if use_gpu:
            print("âœ“ æ£€æµ‹åˆ° NVIDIA GPU æ”¯æŒï¼Œä½¿ç”¨ç¡¬ä»¶åŠ é€Ÿ")
            send_progress(15, 'ä½¿ç”¨ GPU ç¡¬ä»¶åŠ é€Ÿå‹ç¼©...')

            # GPU åŠ é€Ÿå‘½ä»¤ï¼ˆä½¿ç”¨ NVENCï¼‰
            compress_cmd = [
                'ffmpeg',
                '-hwaccel', 'cuda',                    # ç¡¬ä»¶åŠ é€Ÿ
                '-hwaccel_output_format', 'cuda',      # ä¿æŒæ•°æ®åœ¨GPUæ˜¾å­˜
                '-i', input_path,
                '-c:v', 'h264_nvenc',                  # NVIDIA H.264 ç¼–ç å™¨
                '-b:v', f'{target_bitrate}k',
                '-maxrate', f'{target_bitrate}k',
                '-bufsize', f'{target_bitrate * 2}k',
                '-preset', 'p4',                       # p4 = medium (p1æœ€å¿«/è´¨é‡æœ€ä½, p7æœ€æ…¢/è´¨é‡æœ€é«˜)
                '-rc', 'vbr',                          # å¯å˜ç ç‡
                '-vf', 'scale_cuda=trunc(iw/2)*2:trunc(ih/2)*2',  # GPUç¼©æ”¾æ»¤é•œ
                '-c:a', 'aac',                         # éŸ³é¢‘ç¼–ç 
                '-b:a', '128k',
                '-y',
                output_path
            ]
            # åŠ¨æ€è¿‡æ»¤å™¨ï¼ˆè¦†ç›–é»˜è®¤ -vfï¼‰ï¼Œåœ¨ GPU è·¯å¾„ä¸‹ä¹Ÿå…è®¸ä½¿ç”¨ CPU è¿‡æ»¤å™¨ä»¥è¾¾åˆ°æ›´å°ä½“ç§¯
            if 'compress_cmd' in locals():
                if scale_width or output_fps:
                    _filters = []
                    if scale_width:
                        _filters.append(f'scale={scale_width}:-2')
                    if output_fps:
                        _filters.append(f'fps={output_fps}')
                    try:
                        compress_cmd.insert(-1, '-filter:v')
                        compress_cmd.insert(-1, ','.join(_filters))
                    except Exception:
                        pass

            # GPU åŠ é€Ÿå¤§çº¦æ¯ç§’å¤„ç† 2-5 ç§’çš„è§†é¢‘å†…å®¹ï¼ˆæ¯”CPUå¿«3-10å€ï¼‰
            estimated_time = duration / 2.0  # ç§’
        else:
            print("âœ— æœªæ£€æµ‹åˆ° NVIDIA GPU æ”¯æŒï¼Œä½¿ç”¨ CPU ç¼–ç ")
            send_progress(15, 'ä½¿ç”¨ CPU å‹ç¼©ï¼ˆè¾ƒæ…¢ï¼‰...')

            # CPU ç¼–ç å‘½ä»¤
            compress_cmd = [
                'ffmpeg',
                '-i', input_path,
                '-c:v', 'libx264',                     # CPU H.264 ç¼–ç å™¨
                '-b:v', f'{target_bitrate}k',
                '-maxrate', f'{target_bitrate}k',
                '-bufsize', f'{target_bitrate * 2}k',
                '-preset', 'medium',                   # CPU preset
                '-vf', 'scale=trunc(iw/2)*2:trunc(ih/2)*2',
                '-c:a', 'aac',
                '-b:a', '128k',
                '-y',
                output_path
            ]
            # åŠ¨æ€è¿‡æ»¤å™¨ï¼ˆè¦†ç›–é»˜è®¤ -vfï¼‰
            if 'compress_cmd' in locals():
                if scale_width or output_fps:
                    _filters = []
                    if scale_width:
                        _filters.append(f'scale={scale_width}:-2')
                    if output_fps:
                        _filters.append(f'fps={output_fps}')
                    try:
                        compress_cmd.insert(-1, '-filter:v')
                        compress_cmd.insert(-1, ','.join(_filters))
                    except Exception:
                        pass

            # CPU å¤§çº¦æ¯ç§’å¤„ç† 0.3 ç§’çš„è§†é¢‘å†…å®¹
            estimated_time = duration / 0.3  # ç§’

        print(f"é¢„ä¼°å‹ç¼©æ—¶é—´: {estimated_time:.1f} ç§’ ({estimated_time/60:.1f} åˆ†é’Ÿ)")
        print(f"æ‰§è¡Œå‹ç¼©å‘½ä»¤: {' '.join(compress_cmd)}")

        # å¯åŠ¨å‹ç¼©è¿›ç¨‹ - å…³é”®ä¿®å¤ï¼šstderr é‡å®šå‘åˆ° DEVNULL é¿å…ç¼“å†²åŒºé˜»å¡
        if sys.platform == 'win32':
            process = subprocess.Popen(compress_cmd,
                                      stdout=subprocess.DEVNULL,
                                      stderr=subprocess.DEVNULL,  # é¿å… stderr ç¼“å†²åŒºé˜»å¡
                                      shell=True)
        else:
            process = subprocess.Popen(compress_cmd,
                                      stdout=subprocess.DEVNULL,
                                      stderr=subprocess.DEVNULL)

        # æ¨¡æ‹Ÿè¿›åº¦æ›´æ–°çº¿ç¨‹ - ä½¿ç”¨æ›´å‡†ç¡®çš„ä¼°ç®—
        def simulate_progress():
            start_time = time.time()
            last_progress = 15

            while process.poll() is None:  # è¿›ç¨‹è¿˜åœ¨è¿è¡Œ
                elapsed = time.time() - start_time

                # åŸºäºé¢„ä¼°æ—¶é—´è®¡ç®—è¿›åº¦ï¼ˆ15% -> 95%ï¼‰
                if estimated_time > 0:
                    progress_ratio = elapsed / estimated_time
                    estimated_progress = min(95, 15 + int(progress_ratio * 80))
                else:
                    # é™çº§æ–¹æ¡ˆï¼šåŸºäºè§†é¢‘æ—¶é•¿
                    estimated_progress = min(95, 15 + int((elapsed / (duration * 0.5)) * 80))

                # ç¡®ä¿è¿›åº¦åªå¢ä¸å‡
                estimated_progress = max(last_progress, estimated_progress)
                last_progress = estimated_progress

                # æ ¼å¼åŒ–æ¶ˆæ¯
                if elapsed < 60:
                    time_msg = f'å‹ç¼©ä¸­... {int(elapsed)}s'
                else:
                    minutes = int(elapsed / 60)
                    seconds = int(elapsed % 60)
                    time_msg = f'å‹ç¼©ä¸­... {minutes}m {seconds}s'

                # å¦‚æœè¶…è¿‡é¢„ä¼°æ—¶é—´ï¼Œæ˜¾ç¤ºæç¤º
                if elapsed > estimated_time * 1.2:
                    time_msg += ' (å³å°†å®Œæˆ...)'

                send_progress(estimated_progress, time_msg)
                time.sleep(2)  # æ¯2ç§’æ›´æ–°ä¸€æ¬¡

        progress_thread = threading.Thread(target=simulate_progress)
        progress_thread.daemon = True
        progress_thread.start()

        # ç­‰å¾…è¿›ç¨‹å®Œæˆ
        returncode = process.wait()

        # ç­‰å¾…è¿›åº¦çº¿ç¨‹ç»“æŸ
        progress_thread.join(timeout=1)

        # æ£€æŸ¥ç»“æœ
        if returncode == 0 and os.path.exists(output_path):
            output_size = os.path.getsize(output_path) / (1024 * 1024)
            print(f"å‹ç¼©æˆåŠŸï¼è¾“å‡ºæ–‡ä»¶å¤§å°: {output_size:.2f} MB")
            if use_gpu:
                send_progress(100, f'GPUåŠ é€Ÿå‹ç¼©å®Œæˆï¼æ–‡ä»¶å¤§å°: {output_size:.2f}MB')
            else:
                send_progress(100, f'å‹ç¼©å®Œæˆï¼æ–‡ä»¶å¤§å°: {output_size:.2f}MB')
            return True
        else:
            print(f"FFmpeg è¿”å›ç : {returncode}")

            # å¦‚æœ GPU åŠ é€Ÿå¤±è´¥ï¼Œè‡ªåŠ¨é™çº§åˆ° CPU ç¼–ç 
            if use_gpu and returncode != 0:
                print("âš  GPU åŠ é€Ÿå¤±è´¥ï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ° CPU ç¼–ç ...")
                send_progress(15, 'GPUå¤±è´¥ï¼Œåˆ‡æ¢åˆ°CPUç¼–ç ...')

                # CPU ç¼–ç å‘½ä»¤
                cpu_compress_cmd = [
                    'ffmpeg',
                    '-i', input_path,
                    '-c:v', 'libx264',
                    '-b:v', f'{target_bitrate}k',
                    '-maxrate', f'{target_bitrate}k',
                    '-bufsize', f'{target_bitrate * 2}k',
                    '-preset', 'medium',
                    '-vf', 'scale=trunc(iw/2)*2:trunc(ih/2)*2',
                    '-c:a', 'aac',
                    '-b:a', '128k',
                    '-y',
                    output_path
                ]

                print(f"ä½¿ç”¨ CPU ç¼–ç é‡è¯•...")
                print(f"æ‰§è¡Œå‘½ä»¤: {' '.join(cpu_compress_cmd)}")

                # é‡æ–°ä¼°ç®—æ—¶é—´ï¼ˆCPU è¾ƒæ…¢ï¼‰
                estimated_time = duration / 0.3

                # å¯åŠ¨ CPU ç¼–ç è¿›ç¨‹
                if sys.platform == 'win32':
                    cpu_process = subprocess.Popen(cpu_compress_cmd,
                                                   stdout=subprocess.DEVNULL,
                                                   stderr=subprocess.DEVNULL,
                                                   shell=True)
                else:
                    cpu_process = subprocess.Popen(cpu_compress_cmd,
                                                   stdout=subprocess.DEVNULL,
                                                   stderr=subprocess.DEVNULL)

                # é‡æ–°å¯åŠ¨è¿›åº¦çº¿ç¨‹
                def simulate_cpu_progress():
                    start_time = time.time()
                    last_progress = 15

                    while cpu_process.poll() is None:
                        elapsed = time.time() - start_time

                        if estimated_time > 0:
                            progress_ratio = elapsed / estimated_time
                            estimated_progress = min(95, 15 + int(progress_ratio * 80))
                        else:
                            estimated_progress = min(95, 15 + int((elapsed / (duration * 0.5)) * 80))

                        estimated_progress = max(last_progress, estimated_progress)
                        last_progress = estimated_progress

                        if elapsed < 60:
                            time_msg = f'CPUå‹ç¼©ä¸­... {int(elapsed)}s'
                        else:
                            minutes = int(elapsed / 60)
                            seconds = int(elapsed % 60)
                            time_msg = f'CPUå‹ç¼©ä¸­... {minutes}m {seconds}s'

                        if elapsed > estimated_time * 1.2:
                            time_msg += ' (å³å°†å®Œæˆ...)'

                        send_progress(estimated_progress, time_msg)
                        time.sleep(2)

                cpu_progress_thread = threading.Thread(target=simulate_cpu_progress)
                cpu_progress_thread.daemon = True
                cpu_progress_thread.start()

                # ç­‰å¾… CPU ç¼–ç å®Œæˆ
                cpu_returncode = cpu_process.wait()
                cpu_progress_thread.join(timeout=1)

                if cpu_returncode == 0 and os.path.exists(output_path):
                    output_size = os.path.getsize(output_path) / (1024 * 1024)
                    print(f"CPU ç¼–ç æˆåŠŸï¼è¾“å‡ºæ–‡ä»¶å¤§å°: {output_size:.2f} MB")
                    send_progress(100, f'CPUç¼–ç å®Œæˆï¼æ–‡ä»¶å¤§å°: {output_size:.2f}MB')
                    return True
                else:
                    print(f"CPU ç¼–ç ä¹Ÿå¤±è´¥äº†ï¼Œè¿”å›ç : {cpu_returncode}")
                    if not os.path.exists(output_path):
                        print("é”™è¯¯ï¼šè¾“å‡ºæ–‡ä»¶ä¸å­˜åœ¨")
                    send_progress(0, 'å‹ç¼©å¤±è´¥')
                    return False
            else:
                if not os.path.exists(output_path):
                    print("é”™è¯¯ï¼šè¾“å‡ºæ–‡ä»¶ä¸å­˜åœ¨")
                send_progress(0, 'å‹ç¼©å¤±è´¥')
                return False

    except Exception as e:
        print(f"å‹ç¼©è§†é¢‘æ—¶å‡ºé”™: {str(e)}")
        if session_id and session_id in progress_queues:
            progress_queues[session_id].put({
                'type': 'compress',
                'progress': 0,
                'message': f'å‹ç¼©å¤±è´¥: {str(e)}'
            })
        return False

# ============================================================
# è§†é¢‘æŠ½å¸§æ¨¡å—
# ============================================================

def extract_frames_uniform(video_path, fps=1.0, max_frames=None, session_id=None):
    """
    å‡åŒ€é‡‡æ ·ï¼šæŒ‰å›ºå®šFPSæå–å¸§

    Args:
        video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
        fps: é‡‡æ ·å¸§ç‡ï¼ˆæ¯ç§’æå–å‡ å¸§ï¼‰
        max_frames: æœ€å¤§å¸§æ•°é™åˆ¶
        session_id: ä¼šè¯IDï¼Œç”¨äºè¿›åº¦æ¨é€

    Returns:
        list: æå–çš„å¸§åˆ—è¡¨ï¼ˆPIL Imageå¯¹è±¡ï¼‰
        dict: å…ƒæ•°æ®ï¼ˆæ—¶é—´æˆ³ã€å¸§å·ç­‰ï¼‰
    """
    def send_progress(percent, message):
        if session_id and session_id in progress_queues:
            progress_queues[session_id].put({
                'type': 'sampling',
                'progress': percent,
                'message': message
            })

    try:
        send_progress(0, 'å¼€å§‹æå–å¸§...')

        # ä½¿ç”¨OpenCVæ‰“å¼€è§†é¢‘
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            raise ValueError("æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶")

        # è·å–è§†é¢‘ä¿¡æ¯
        video_fps = cap.get(cv2.CAP_PROP_FPS)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        duration = total_frames / video_fps

        print(f"è§†é¢‘ä¿¡æ¯: FPS={video_fps}, æ€»å¸§æ•°={total_frames}, æ—¶é•¿={duration:.2f}ç§’")
        send_progress(10, f'è§†é¢‘æ—¶é•¿{duration:.2f}ç§’ï¼Œå¼€å§‹æå–...')

        # è®¡ç®—é‡‡æ ·é—´éš”
        frame_interval = int(video_fps / fps)

        frames = []
        metadata = {
            'timestamps': [],
            'frame_indices': [],
            'video_fps': video_fps,
            'total_frames': total_frames,
            'duration': duration
        }

        frame_count = 0
        extracted_count = 0

        while True:
            ret, frame = cap.read()
            if not ret:
                break

            # æŒ‰é—´éš”æå–å¸§
            if frame_count % frame_interval == 0:
                # è½¬æ¢BGRåˆ°RGB
                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                pil_image = Image.fromarray(frame_rgb)

                frames.append(pil_image)
                metadata['timestamps'].append(frame_count / video_fps)
                metadata['frame_indices'].append(frame_count)

                extracted_count += 1

                # æ›´æ–°è¿›åº¦
                progress = int(10 + (frame_count / total_frames) * 80)
                send_progress(progress, f'å·²æå– {extracted_count} å¸§...')

                # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æœ€å¤§å¸§æ•°
                if max_frames and extracted_count >= max_frames:
                    break

            frame_count += 1

        cap.release()

        print(f"æå–å®Œæˆï¼šå…±æå– {len(frames)} å¸§")
        send_progress(100, f'æå–å®Œæˆï¼Œå…±{len(frames)}å¸§')

        return frames, metadata

    except Exception as e:
        print(f"æå–å¸§å¤±è´¥: {str(e)}")
        send_progress(0, f'æå–å¤±è´¥: {str(e)}')
        raise


def extract_frames_keyframes(video_path, num_keyframes=16, session_id=None):
    """
    å…³é”®å¸§æå–ï¼šå‡åŒ€æå–Nä¸ªå…³é”®å¸§

    Args:
        video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
        num_keyframes: æå–çš„å…³é”®å¸§æ•°é‡
        session_id: ä¼šè¯ID

    Returns:
        list: æå–çš„å¸§åˆ—è¡¨
        dict: å…ƒæ•°æ®
    """
    def send_progress(percent, message):
        if session_id and session_id in progress_queues:
            progress_queues[session_id].put({
                'type': 'sampling',
                'progress': percent,
                'message': message
            })

    try:
        send_progress(0, 'å¼€å§‹æå–å…³é”®å¸§...')

        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            raise ValueError("æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶")

        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        video_fps = cap.get(cv2.CAP_PROP_FPS)

        # è®¡ç®—å‡åŒ€é—´éš”
        indices = np.linspace(0, total_frames - 1, num_keyframes, dtype=int)

        frames = []
        metadata = {
            'timestamps': [],
            'frame_indices': [],
            'video_fps': video_fps,
            'total_frames': total_frames
        }

        for i, frame_idx in enumerate(indices):
            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
            ret, frame = cap.read()

            if ret:
                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                pil_image = Image.fromarray(frame_rgb)

                frames.append(pil_image)
                metadata['timestamps'].append(frame_idx / video_fps)
                metadata['frame_indices'].append(int(frame_idx))

                progress = int(10 + (i / len(indices)) * 90)
                send_progress(progress, f'æå–å…³é”®å¸§ {i+1}/{num_keyframes}...')

        cap.release()

        print(f"å…³é”®å¸§æå–å®Œæˆï¼š{len(frames)} å¸§")
        send_progress(100, f'æå–å®Œæˆï¼Œå…±{len(frames)}ä¸ªå…³é”®å¸§')

        return frames, metadata

    except Exception as e:
        print(f"æå–å…³é”®å¸§å¤±è´¥: {str(e)}")
        send_progress(0, f'æå–å¤±è´¥: {str(e)}')
        raise


def extract_frames_accident_analysis(video_path, config, session_id=None):
    """
    äº¤é€šäº‹æ•…åˆ†æä¸“ç”¨æŠ½å¸§ç­–ç•¥
    å®ç°å››é˜¶æ®µé‡‡æ ·ï¼ˆç®€åŒ–ç‰ˆï¼‰

    Args:
        video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
        config: é…ç½®å­—å…¸
        session_id: ä¼šè¯ID

    Returns:
        list: æå–çš„å¸§åˆ—è¡¨ï¼ˆæŒ‰é˜¶æ®µåˆ†ç»„ï¼‰
        dict: å…ƒæ•°æ®ï¼ˆåŒ…å«å„é˜¶æ®µä¿¡æ¯ï¼‰
    """
    def send_progress(percent, message):
        if session_id and session_id in progress_queues:
            progress_queues[session_id].put({
                'type': 'sampling',
                'progress': percent,
                'message': message
            })

    try:
        send_progress(0, 'äº¤é€šäº‹æ•…åˆ†æï¼šé˜¶æ®µ1 - ç²—æ‰«æ...')

        # é˜¶æ®µ1ï¼šç²—ç²’åº¦æ‰«æï¼ˆ1 FPSï¼‰
        frames_stage1, meta1 = extract_frames_uniform(
            video_path,
            fps=1.0,
            max_frames=600,  # æœ€å¤š10åˆ†é’Ÿ
            session_id=None  # ä¸é‡å¤æ¨é€è¿›åº¦
        )

        send_progress(25, f'é˜¶æ®µ1å®Œæˆï¼šæ‰«æ{len(frames_stage1)}å¸§')

        # é˜¶æ®µ2ï¼šé€‰æ‹©å…³é”®æ—¶é—´æ®µçš„å¸§ï¼ˆæ¨¡æ‹Ÿäº‹æ•…æ—¶åˆ»æ£€æµ‹ï¼‰
        # è¿™é‡Œç®€åŒ–ä¸ºé€‰æ‹©è§†é¢‘ä¸­æ®µçš„é«˜å¯†åº¦é‡‡æ ·
        duration = meta1['duration']
        accident_time = duration / 2  # å‡è®¾äº‹æ•…åœ¨ä¸­é—´

        send_progress(50, 'é˜¶æ®µ2ï¼šç²¾ç¡®å®šä½äº‹æ•…æ—¶åˆ»...')

        # æå–äº‹æ•…æ—¶åˆ»é™„è¿‘çš„å¯†é›†å¸§ï¼ˆÂ±10ç§’ï¼‰
        frames_stage2 = []
        for i, ts in enumerate(meta1['timestamps']):
            if abs(ts - accident_time) <= 10:  # äº‹æ•…å‰å10ç§’
                frames_stage2.append(frames_stage1[i])

        send_progress(75, f'é˜¶æ®µ2å®Œæˆï¼šå®šä½åˆ°{len(frames_stage2)}å¸§')

        # é˜¶æ®µ3ï¼šç¯å¢ƒåˆ†æå…³é”®å¸§ï¼ˆé€‰æ‹©5ä¸ªä»£è¡¨å¸§ï¼‰
        num_env_frames = min(5, len(frames_stage1))
        env_indices = np.linspace(0, len(frames_stage1)-1, num_env_frames, dtype=int)
        frames_stage3 = [frames_stage1[i] for i in env_indices]

        send_progress(90, 'é˜¶æ®µ3ï¼šæå–ç¯å¢ƒåˆ†æå¸§...')

        # åˆå¹¶æ‰€æœ‰å¸§ï¼ˆç®€å•åˆå¹¶ï¼Œä¸å»é‡ï¼Œå› ä¸ºPIL Imageå¯¹è±¡ä¸å¯å“ˆå¸Œï¼‰
        # ç”±äºframes_stage2å’Œframes_stage3æ˜¯ä»frames_stage1ä¸­é€‰å–çš„ï¼Œé‡å¤å½±å“ä¸å¤§
        all_frames = frames_stage1 + frames_stage2 + frames_stage3

        metadata = {
            'strategy': 'accident_analysis',
            'total_frames': len(all_frames),
            'stage1_frames': len(frames_stage1),
            'stage2_frames': len(frames_stage2),
            'stage3_frames': len(frames_stage3),
            'video_duration': duration,
            'estimated_accident_time': accident_time,
            'config': config
        }

        send_progress(100, f'äº‹æ•…åˆ†æå®Œæˆï¼šå…±{len(all_frames)}å¸§')

        return all_frames, metadata

    except Exception as e:
        print(f"äº‹æ•…åˆ†ææŠ½å¸§å¤±è´¥: {str(e)}")
        send_progress(0, f'æŠ½å¸§å¤±è´¥: {str(e)}')
        raise


def save_frames_to_folder(frames, strategy_name, video_name=None):
    """
    ä¿å­˜æŠ½å–çš„å¸§åˆ°æ–‡ä»¶å¤¹ï¼ˆç”¨äºè°ƒè¯•ï¼‰

    Args:
        frames: PIL Imageåˆ—è¡¨
        strategy_name: æŠ½å¸§ç­–ç•¥åç§°
        video_name: è§†é¢‘æ–‡ä»¶åï¼ˆå¯é€‰ï¼‰

    Returns:
        str: ä¿å­˜çš„æ–‡ä»¶å¤¹è·¯å¾„
    """
    from datetime import datetime

    # åˆ›å»ºæ—¶é—´æˆ³
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')

    # åˆ›å»ºæ–‡ä»¶å¤¹åç§°ï¼šç­–ç•¥å_æ—¶é—´æˆ³
    folder_name = f"{strategy_name}_{timestamp}"
    if video_name:
        # ç§»é™¤æ–‡ä»¶æ‰©å±•å
        video_base = os.path.splitext(video_name)[0]
        folder_name = f"{video_base}_{strategy_name}_{timestamp}"

    # åˆ›å»ºä¿å­˜è·¯å¾„
    debug_folder = os.path.join(app.config['UPLOAD_FOLDER'], 'debug_frames')
    os.makedirs(debug_folder, exist_ok=True)

    save_path = os.path.join(debug_folder, folder_name)
    os.makedirs(save_path, exist_ok=True)

    # ä¿å­˜æ‰€æœ‰å¸§
    print(f"\nğŸ’¾ ä¿å­˜æŠ½å¸§å›¾ç‰‡åˆ°: {save_path}")
    for i, frame in enumerate(frames):
        frame_path = os.path.join(save_path, f"frame_{i:04d}.jpg")
        frame.save(frame_path, format='JPEG', quality=95)

    print(f"âœ… å·²ä¿å­˜ {len(frames)} å¸§åˆ°æ–‡ä»¶å¤¹: {folder_name}\n")
    return save_path


def calculate_image_tokens(width, height):
    """
    è®¡ç®—å›¾ç‰‡çš„Tokenæ•°é‡ï¼ˆQwen3-VLè§„åˆ™ï¼šæ¯32x32åƒç´ =1 Tokenï¼‰

    Args:
        width: å›¾ç‰‡å®½åº¦
        height: å›¾ç‰‡é«˜åº¦

    Returns:
        int: Tokenæ•°é‡
    """
    import math
    # Qwen3-VL: æ¯32x32åƒç´ å¯¹åº”1ä¸ªToken
    tokens = math.ceil(width / 32) * math.ceil(height / 32)
    # æœ€å°‘4ä¸ªTokenï¼Œæœ€å¤š16384ä¸ªToken
    return max(4, min(tokens, 16384))


def frames_to_base64_images(frames, max_tokens=250000):
    """
    å°†å¸§åˆ—è¡¨è½¬æ¢ä¸ºbase64ç¼–ç çš„å›¾ç‰‡åˆ—è¡¨ï¼ˆç”¨äºAPIè°ƒç”¨ï¼‰
    ä½¿ç”¨Tokené™åˆ¶è€Œéæ–‡ä»¶å¤§å°é™åˆ¶ï¼Œç¡®ä¿ç¬¦åˆQwen-VL APIè¦æ±‚

    Args:
        frames: PIL Imageåˆ—è¡¨
        max_tokens: æœ€å¤§Tokenæ•°ï¼ˆé»˜è®¤250000ï¼Œä¸º258048ç•™ä½™é‡ï¼‰

    Returns:
        list: base64ç¼–ç çš„å›¾ç‰‡URLåˆ—è¡¨
    """
    import io

    base64_images = []
    total_tokens = 0
    total_size_mb = 0

    print(f"\nğŸ”¢ å¼€å§‹è½¬æ¢å¸§ï¼Œä½¿ç”¨Tokené™åˆ¶ç­–ç•¥ï¼ˆæœ€å¤§{max_tokens} tokensï¼‰")

    for i, frame in enumerate(frames):
        # å‹ç¼©å›¾ç‰‡ï¼šé™ä½åˆ†è¾¨ç‡ä»¥å‡å°‘Tokenæ¶ˆè€—
        # æœ€å¤§å®½åº¦1280pxï¼Œè¿™æ ·å¯ä»¥åœ¨ä¿æŒè´¨é‡çš„åŒæ—¶å‡å°‘Token
        max_width = 1280
        width, height = frame.size
        if width > max_width:
            ratio = max_width / width
            new_size = (max_width, int(height * ratio))
            frame = frame.resize(new_size, Image.Resampling.LANCZOS)
            width, height = new_size

        # è®¡ç®—è¿™å¼ å›¾ç‰‡éœ€è¦çš„Tokenæ•°
        frame_tokens = calculate_image_tokens(width, height)

        # æ£€æŸ¥Tokené™åˆ¶
        if total_tokens + frame_tokens > max_tokens:
            print(f"âš ï¸ å·²è¾¾åˆ°Tokené™åˆ¶ï¼ˆ{total_tokens}/{max_tokens}ï¼‰ï¼Œåœæ­¢æ·»åŠ æ›´å¤šå¸§")
            print(f"   æˆåŠŸå¤„ç† {i}/{len(frames)} å¸§")
            break

        # è½¬æ¢ä¸ºJPEGå¹¶å‹ç¼©
        buffer = io.BytesIO()
        frame.save(buffer, format='JPEG', quality=85, optimize=True)  # æé«˜è´¨é‡ï¼Œä¿ç•™æ›´å¤šç»†èŠ‚
        img_bytes = buffer.getvalue()

        # ç¼–ç ä¸ºbase64
        img_base64 = base64.b64encode(img_bytes).decode('utf-8')
        img_url = f"data:image/jpeg;base64,{img_base64}"

        # è®°å½•ç»Ÿè®¡ä¿¡æ¯
        img_size_mb = len(img_base64) / (1024 * 1024)
        total_size_mb += img_size_mb
        total_tokens += frame_tokens

        base64_images.append(img_url)

        # æ¯10å¸§æ‰“å°ä¸€æ¬¡è¿›åº¦
        if (i + 1) % 10 == 0:
            print(f"   è¿›åº¦: {i+1}/{len(frames)} å¸§ï¼ŒToken: {total_tokens}/{max_tokens}ï¼Œå¤§å°: {total_size_mb:.2f}MB")

    print(f"âœ… è½¬æ¢å®Œæˆï¼š{len(base64_images)}/{len(frames)} å¸§")
    print(f"   æ€»Tokenæ•°: {total_tokens} ({total_tokens/max_tokens*100:.1f}%)")
    print(f"   æ€»å¤§å°: {total_size_mb:.2f}MB")
    print(f"   å¹³å‡æ¯å¸§: {total_tokens/len(base64_images):.0f} tokens, {total_size_mb/len(base64_images):.2f}MB\n")

    return base64_images


def analyze_video_with_api(video_path=None, video_url=None, prompt='è¯·è¯¦ç»†æè¿°è¿™ä¸ªè§†é¢‘ä¸­å‘ç”Ÿäº†ä»€ä¹ˆã€‚', model='qwen-vl-plus', session_id=None):
    """
    ä½¿ç”¨é˜¿é‡Œäº‘ DashScope API åˆ†æè§†é¢‘å†…å®¹

    Args:
        video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„ï¼ˆæœ¬åœ°ä¸Šä¼ æ–¹å¼ï¼‰
        video_url: è§†é¢‘URLï¼ˆURLæ–¹å¼ï¼Œæ”¯æŒæœ€å¤§2GBï¼‰
        prompt: ç”¨æˆ·æé—®
        model: ä½¿ç”¨çš„æ¨¡å‹åç§°
        session_id: ä¼šè¯IDï¼Œç”¨äºè¿›åº¦æ¨é€

    Returns:
        str: æ¨¡å‹åˆ†æç»“æœ
    """
    try:
        # å‘é€è¿›åº¦æ›´æ–°
        def send_progress(percent, message):
            if session_id and session_id in progress_queues:
                progress_queues[session_id].put({
                    'type': 'upload',
                    'progress': percent,
                    'message': message
                })
        # æ£€æŸ¥ API Key
        if not DASHSCOPE_API_KEY:
            raise ValueError(
                "æœªè®¾ç½® DASHSCOPE_API_KEYï¼\n"
                "è¯·åœ¨ç¯å¢ƒå˜é‡ä¸­è®¾ç½® API Keyï¼Œæˆ–åœ¨ app.py ä¸­ç›´æ¥é…ç½®ã€‚\n"
                "è·å– API Key: https://dashscope.console.aliyun.com/apiKey"
            )

        send_progress(0, 'å¼€å§‹åˆ†æè§†é¢‘...')

        remote_model = get_remote_model_id(model)
        print(f"ä½¿ç”¨æ¨¡å‹: {model} -> {remote_model}")
        print(f"ç”¨æˆ·æé—®: {prompt}")

        # åˆ¤æ–­ä½¿ç”¨URLæ–¹å¼è¿˜æ˜¯æœ¬åœ°æ–‡ä»¶æ–¹å¼
        if video_url:
            # URLæ–¹å¼ - æ”¯æŒæœ€å¤§2GBè§†é¢‘
            print(f"ä½¿ç”¨URLæ–¹å¼åˆ†æè§†é¢‘: {video_url}")
            send_progress(10, 'ä½¿ç”¨URLæ–¹å¼ï¼Œå‡†å¤‡è°ƒç”¨API...')

            # æ„å»ºè¯·æ±‚æ¶ˆæ¯ - URLæ–¹å¼
            messages = [
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "video_url",
                            "video_url": {
                                "url": video_url
                            },
                        },
                        {
                            "type": "text",
                            "text": prompt
                        },
                    ]
                }
            ]

        else:
            # æœ¬åœ°æ–‡ä»¶æ–¹å¼ - base64ç¼–ç 
            print(f"å¼€å§‹åˆ†æè§†é¢‘: {video_path}")

            # æ£€æŸ¥è§†é¢‘æ–‡ä»¶å¤§å°
            video_size = os.path.getsize(video_path)
            video_size_mb = video_size / (1024 * 1024)
            print(f"è§†é¢‘æ–‡ä»¶å¤§å°: {video_size_mb:.2f} MB")

            send_progress(5, f'å‡†å¤‡ä¸Šä¼ è§†é¢‘ ({video_size_mb:.2f}MB)...')

            # APIé™åˆ¶ï¼šbase64ç¼–ç åä¸èƒ½è¶…è¿‡10MB
            # ç”±äºbase64ç¼–ç ä¼šå¢åŠ çº¦33%çš„å¤§å°ï¼ŒåŸå§‹æ–‡ä»¶åº”è¯¥å°äº7.5MB
            max_original_size = 7.5 * 1024 * 1024  # 7.5MB
            # ä½¿ç”¨å¯é…ç½®çš„é˜ˆå€¼è¦†ç›–é»˜è®¤ 7.5MBï¼ˆä¸º base64 å¢é•¿é¢„ç•™ï¼‰
            try:
                max_original_size = TARGET_ORIGINAL_MB * 1024 * 1024
            except Exception:
                pass
            if video_size > max_original_size:
                raise ValueError(
                    f"è§†é¢‘æ–‡ä»¶å¤ªå¤§ï¼ˆ{video_size_mb:.2f} MBï¼‰ï¼\n"
                    f"DashScope API é™åˆ¶ base64 ç¼–ç åçš„è§†é¢‘ä¸èƒ½è¶…è¿‡ 10MBã€‚\n"
                    f"å»ºè®®ï¼š\n"
                    f"1. ä½¿ç”¨è§†é¢‘å‹ç¼©å·¥å…·å‹ç¼©è§†é¢‘\n"
                    f"2. æˆªå–è¾ƒçŸ­çš„è§†é¢‘ç‰‡æ®µï¼ˆå»ºè®® < 7MBï¼‰\n"
                    f"3. é™ä½è§†é¢‘åˆ†è¾¨ç‡æˆ–å¸§ç‡"
                )

            # ç¼–ç è§†é¢‘ä¸º base64
            print("æ­£åœ¨ç¼–ç è§†é¢‘...")
            send_progress(10, 'æ­£åœ¨ç¼–ç è§†é¢‘...')
            base64_video = encode_video_to_base64(video_path)
            base64_size_mb = len(base64_video) / (1024 * 1024)
            print(f"è§†é¢‘ç¼–ç å®Œæˆï¼Œbase64 å¤§å°: {base64_size_mb:.2f} MB")
            send_progress(30, f'è§†é¢‘ç¼–ç å®Œæˆ ({base64_size_mb:.2f}MB)')

            # å†æ¬¡æ£€æŸ¥ç¼–ç åçš„å¤§å°
            if len(base64_video) > 10 * 1024 * 1024:
                raise ValueError(
                    f"ç¼–ç åè§†é¢‘å¤ªå¤§ï¼ˆ{base64_size_mb:.2f} MBï¼‰ï¼Œè¶…è¿‡ API é™åˆ¶ï¼ˆ10MBï¼‰ï¼\n"
                    f"è¯·å‹ç¼©è§†é¢‘æˆ–ä½¿ç”¨æ›´çŸ­çš„ç‰‡æ®µã€‚"
                )

            # æ„å»ºè¯·æ±‚æ¶ˆæ¯ - base64æ–¹å¼
            messages = [
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "video_url",
                            "video_url": {
                                "url": f"data:video/mp4;base64,{base64_video}"
                            },
                        },
                        {
                            "type": "text",
                            "text": prompt
                        },
                    ]
                }
            ]

        # åˆ›å»º OpenAI å®¢æˆ·ç«¯ï¼ˆå…¼å®¹æ¨¡å¼ï¼‰
        client = OpenAI(
            api_key=DASHSCOPE_API_KEY,
            base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
        )

        # è°ƒç”¨ API
        print("æ­£åœ¨è°ƒç”¨ DashScope API...")
        send_progress(40, 'æ­£åœ¨ä¸Šä¼ åˆ°AIæ¨¡å‹...')

        completion = client.chat.completions.create(
            model=remote_model,
            messages=messages,
        )

        send_progress(90, 'AIæ­£åœ¨åˆ†æè§†é¢‘...')

        # è·å–ç»“æœ
        result = completion.choices[0].message.content
        print("åˆ†æå®Œæˆï¼")
        send_progress(100, 'åˆ†æå®Œæˆï¼')

        return result

    except Exception as e:
        import traceback
        error_msg = f"API è°ƒç”¨å¤±è´¥: {str(e)}"
        print(error_msg)
        print("è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
        print(traceback.format_exc())
        raise Exception(error_msg)


def analyze_images_with_api(base64_images, prompt='è¯·åˆ†æè¿™äº›å›¾ç‰‡ã€‚', model='qwen-vl-plus', session_id=None):
    """
    ä½¿ç”¨é˜¿é‡Œäº‘ DashScope API åˆ†æå¤šå¼ å›¾ç‰‡

    Args:
        base64_images: base64ç¼–ç çš„å›¾ç‰‡URLåˆ—è¡¨
        prompt: ç”¨æˆ·æé—®
        model: ä½¿ç”¨çš„æ¨¡å‹åç§°
        session_id: ä¼šè¯ID

    Returns:
        str: æ¨¡å‹åˆ†æç»“æœ
    """
    try:
        def send_progress(percent, message):
            if session_id and session_id in progress_queues:
                progress_queues[session_id].put({
                    'type': 'upload',
                    'progress': percent,
                    'message': message
                })

        send_progress(0, 'å‡†å¤‡å‘é€å›¾ç‰‡åˆ°AIæ¨¡å‹...')

        # æ£€æŸ¥ API Key
        if not DASHSCOPE_API_KEY:
            raise ValueError("æœªè®¾ç½® DASHSCOPE_API_KEYï¼")

        remote_model = get_remote_model_id(model)
        print(f"ä½¿ç”¨æ¨¡å‹: {model} -> {remote_model}")
        print(f"åˆ†æå›¾ç‰‡æ•°é‡: {len(base64_images)}")

        # æ„å»ºæ¶ˆæ¯å†…å®¹ï¼ˆå¤šå›¾ï¼‰
        content = []
        for img_url in base64_images:
            content.append({
                "type": "image_url",
                "image_url": {"url": img_url}
            })

        # æ·»åŠ æ–‡æœ¬æé—®
        content.append({
            "type": "text",
            "text": prompt
        })

        messages = [
            {
                "role": "user",
                "content": content
            }
        ]

        # åˆ›å»º OpenAI å®¢æˆ·ç«¯
        client = OpenAI(
            api_key=DASHSCOPE_API_KEY,
            base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
        )

        send_progress(40, f'ä¸Šä¼ {len(base64_images)}å¼ å›¾ç‰‡åˆ°AIæ¨¡å‹...')

        # è°ƒç”¨ API
        completion = client.chat.completions.create(
            model=remote_model,
            messages=messages,
        )

        send_progress(90, 'AIæ­£åœ¨åˆ†æå›¾ç‰‡...')

        # è·å–ç»“æœ
        result = completion.choices[0].message.content
        print("å¤šå›¾åˆ†æå®Œæˆï¼")
        send_progress(100, 'åˆ†æå®Œæˆï¼')

        return result

    except Exception as e:
        import traceback
        error_msg = f"å¤šå›¾APIè°ƒç”¨å¤±è´¥: {str(e)}"
        print(error_msg)
        print(traceback.format_exc())
        raise Exception(error_msg)


@app.route('/')
def index():
    """ä¸»é¡µ"""
    return render_template('index.html', models=AVAILABLE_MODELS)

@app.route('/progress/<session_id>')
def progress(session_id):
    """SSE è¿›åº¦æ¨é€ç«¯ç‚¹"""
    def generate():
        # åˆ›å»ºè¯¥ä¼šè¯çš„è¿›åº¦é˜Ÿåˆ—
        if session_id not in progress_queues:
            progress_queues[session_id] = Queue()

        q = progress_queues[session_id]

        # å‘é€åˆå§‹è¿æ¥æ¶ˆæ¯
        yield f"data: {json.dumps({'type': 'connected', 'message': 'å·²è¿æ¥'})}\n\n"

        try:
            while True:
                try:
                    # ä»é˜Ÿåˆ—è·å–è¿›åº¦æ›´æ–°ï¼Œè®¾ç½®è¾ƒçŸ­çš„è¶…æ—¶ä»¥ä¾¿å‘é€å¿ƒè·³
                    data = q.get(timeout=5)  # 5ç§’è¶…æ—¶

                    # å‘é€ SSE æ•°æ®
                    yield f"data: {json.dumps(data)}\n\n"

                    # å¦‚æœä»»åŠ¡å®Œæˆæˆ–å¤±è´¥ï¼Œç»“æŸæµ
                    if data.get('type') == 'complete' or data.get('type') == 'error':
                        break

                except:
                    # é˜Ÿåˆ—è¶…æ—¶ï¼Œå‘é€å¿ƒè·³ä¿æŒè¿æ¥
                    yield f": heartbeat\n\n"
                    continue

        except GeneratorExit:
            # å®¢æˆ·ç«¯æ–­å¼€è¿æ¥
            pass
        finally:
            # æ¸…ç†é˜Ÿåˆ—
            if session_id in progress_queues:
                del progress_queues[session_id]

    return Response(stream_with_context(generate()),
                   mimetype='text/event-stream',
                   headers={
                       'Cache-Control': 'no-cache',
                       'X-Accel-Buffering': 'no',
                       'Connection': 'keep-alive'
                   })

@app.route('/analyze', methods=['POST'])
def analyze():
    """å¤„ç†è§†é¢‘åˆ†æè¯·æ±‚ - ç«‹å³è¿”å›session_idï¼Œåå°å¤„ç†"""
    try:
        # è·å–è¾“å…¥æ–¹å¼
        input_method = request.form.get('input_method', 'upload')  # 'upload' æˆ– 'url'

        # è·å–ç”¨æˆ·æé—®å’Œæ¨¡å‹é€‰æ‹©
        prompt = request.form.get('prompt', 'è¯·è¯¦ç»†æè¿°è¿™ä¸ªè§†é¢‘ä¸­å‘ç”Ÿäº†ä»€ä¹ˆã€‚')
        model = request.form.get('model', 'qwen-vl-plus')
        analysis_mode = request.form.get('analysis_mode', 'traffic_vlm')
        event_query = request.form.get('event_query', '').strip()
        camera_id = request.form.get('camera_id', 'camera-1').strip() or 'camera-1'

        # æ ¹æ®è¾“å…¥æ–¹å¼å¤„ç†
        video_url = None
        filepath = None
        filename = None
        auto_compress = False

        if input_method == 'url':
            # URLæ–¹å¼
            video_url = request.form.get('video_url', '').strip()
            if not video_url:
                return jsonify({'error': 'è¯·æä¾›è§†é¢‘URL'}), 400

            # éªŒè¯URLæ ¼å¼
            if not video_url.startswith(('http://', 'https://')):
                return jsonify({'error': 'è¯·æä¾›æœ‰æ•ˆçš„HTTP/HTTPSè§†é¢‘URL'}), 400

            print(f"æ”¶åˆ°URLæ–¹å¼è¯·æ±‚: {video_url}")

        else:
            # ä¸Šä¼ æ–‡ä»¶æ–¹å¼
            # æ£€æŸ¥æ˜¯å¦æœ‰æ–‡ä»¶
            if 'video' not in request.files:
                return jsonify({'error': 'æœªæ‰¾åˆ°è§†é¢‘æ–‡ä»¶'}), 400

            file = request.files['video']

            # æ£€æŸ¥æ–‡ä»¶å
            if file.filename == '':
                return jsonify({'error': 'æœªé€‰æ‹©æ–‡ä»¶'}), 400

            # æ£€æŸ¥æ–‡ä»¶ç±»å‹
            if not allowed_file(file.filename):
                return jsonify({'error': f'ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼Œè¯·ä¸Šä¼ : {", ".join(ALLOWED_EXTENSIONS)}'}), 400

            auto_compress = request.form.get('auto_compress', 'true').lower() == 'true'

            # ä¿å­˜æ–‡ä»¶
            filename = file.filename
            filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
            file.save(filepath)

        # éªŒè¯æ¨¡å‹é€‰æ‹©
        if model not in AVAILABLE_MODELS:
            # å…è®¸é¢å¤–çš„æ¨¡å‹é”®ï¼ˆæœªåœ¨ AVAILABLE_MODELS ä¸­å±•ç¤ºï¼‰
            extra_allowed = {'qwen3-vl-235b-a22b-thinking', 'qwen-vlmax-20250813', 'qwen3-vl-32b-instruct', 'qwen3-vl-32b-thinking'}
            if model not in extra_allowed:
                model = 'qwen-vl-plus'

        # ========== æå‰è·å–æ‰€æœ‰è¯·æ±‚å‚æ•°ï¼ˆé¿å…åœ¨çº¿ç¨‹ä¸­è®¿é—®requestï¼‰ ==========
        # è·å–æŠ½å¸§ç­–ç•¥ç›¸å…³å‚æ•°
        sampling_strategy = request.form.get('sampling_strategy', 'full_video')
        uniform_fps = float(request.form.get('uniform_fps', 1.0)) if sampling_strategy == 'uniform_fps' else 1.0
        keyframe_count = int(request.form.get('keyframe_count', 16)) if sampling_strategy == 'keyframe_only' else 16

        # äº¤é€šäº‹æ•…åˆ†æé…ç½®
        accident_config = None
        if sampling_strategy == 'accident_analysis':
            accident_config = {
                'detect_accident_time': request.form.get('detect_accident_time', 'true').lower() == 'true',
                'track_trajectory': request.form.get('track_trajectory', 'true').lower() == 'true',
                'analyze_environment': request.form.get('analyze_environment', 'true').lower() == 'true'
            }

        # ç”Ÿæˆå”¯ä¸€çš„ä¼šè¯ID
        session_id = f"{int(time.time() * 1000)}_{os.getpid()}"

        # åˆ›å»ºè¿›åº¦é˜Ÿåˆ—
        progress_queues[session_id] = Queue()

        # åœ¨åå°çº¿ç¨‹ä¸­å¤„ç†ä»»åŠ¡
        def process_video():
            compressed_path = None
            final_video_path = filepath
            try:
                # æ£€æŸ¥æ˜¯å¦å·²è¢«åœæ­¢
                if is_stopped(session_id):
                    print(f"[Session {session_id}] ä»»åŠ¡å·²è¢«åœæ­¢ï¼ˆå¯åŠ¨å‰ï¼‰")
                    return

                user_intent = event_query or prompt
                video_source_path = video_url if video_url else filepath

                def pipeline_progress(percent, message):
                    # æ£€æŸ¥æ˜¯å¦å·²è¢«åœæ­¢
                    if is_stopped(session_id):
                        raise InterruptedError("åˆ†æå·²è¢«ç”¨æˆ·åœæ­¢")
                    progress_queues[session_id].put({
                        'type': 'analysis',
                        'progress': int(percent),
                        'message': message
                    })

                def format_pipeline_summary(res):
                    lines = []
                    lines.append(f"Keyframes: {len(res.get('keyframes', []))}")
                    lines.append(f"Candidate clips: {len(res.get('clips', []))}")
                    for item in res.get('results', []):
                        clip = item.get('clip', {})
                        vlm_out = item.get('vlm_output', {}) or {}
                        vio = vlm_out.get('violations') or []
                        vio_text = '; '.join([f"{v.get('type')}({v.get('confidence', 0):.2f})" for v in vio]) if vio else 'No high-confidence violations'
                        lines.append(f"- {clip.get('clip_id', '')} [{clip.get('start_time', 0):.1f}-{clip.get('end_time', 0):.1f}s] score {clip.get('clip_score', 0):.3f} | {vio_text}")
                    return "\n".join(lines)

                def extract_detailed_analysis(res):
                    """æå–è¯¦ç»†çš„åˆ†æç»“æœï¼ˆåŒ…å«å¤§æ¨¡å‹çš„æ–‡æœ¬æè¿°ï¼‰"""
                    results = res.get('results', [])
                    if not results:
                        return "æœªæ£€æµ‹åˆ°ç›¸å…³å†…å®¹"

                    analysis_parts = []
                    for i, item in enumerate(results, 1):
                        vlm_out = item.get('vlm_output', {}) or {}
                        text_summary = vlm_out.get('text_summary', 'æ— æè¿°')
                        has_violation = vlm_out.get('has_violation', False)
                        violations = vlm_out.get('violations', [])

                        # æ·»åŠ ç‰‡æ®µä¿¡æ¯
                        clip = item.get('clip', {})
                        start_time = clip.get('start_time', 0)
                        end_time = clip.get('end_time', 0)

                        analysis_parts.append(f"ã€ç‰‡æ®µ {i}ã€‘æ—¶é—´: {start_time:.1f}s - {end_time:.1f}s")
                        analysis_parts.append(f"åˆ†æç»“æœ: {text_summary}")

                        # æ·»åŠ è¿æ³•ä¿¡æ¯
                        if violations:
                            analysis_parts.append("æ£€æµ‹åˆ°çš„è¿æ³•è¡Œä¸º:")
                            for v in violations:
                                vtype = v.get('type', '')
                                confidence = v.get('confidence', 0)
                                evidence = v.get('evidence', '')
                                analysis_parts.append(f"  - {vtype} (ç½®ä¿¡åº¦: {confidence:.2f})")
                                if evidence:
                                    analysis_parts.append(f"    ä¾æ®: {evidence}")
                        elif has_violation:
                            analysis_parts.append("æ£€æµ‹åˆ°è¿æ³•è¡Œä¸ºï¼Œä½†æœªèƒ½è¯†åˆ«å…·ä½“ç±»å‹")
                        else:
                            analysis_parts.append("æœªæ£€æµ‹åˆ°è¿æ³•è¡Œä¸º")

                        analysis_parts.append("")  # ç©ºè¡Œåˆ†éš”

                    return "\n".join(analysis_parts)

                if analysis_mode == 'traffic_vlm':
                    # æ£€æŸ¥æ˜¯å¦å·²è¢«åœæ­¢
                    if is_stopped(session_id):
                        print(f"[Session {session_id}] ä»»åŠ¡å·²è¢«åœæ­¢ï¼ˆpipelineå¯åŠ¨å‰ï¼‰")
                        return

                    print(f"\n{'='*60}")
                    print(f"TrafficVLM pipeline start (Session: {session_id})")
                    print(f"Source: {video_source_path}")
                    print(f"Camera ID: {camera_id}")
                    print(f"Query: {user_intent}")
                    print(f"{'='*60}\n")

                    try:
                        pipeline = TrafficVLMPipeline(config=TrafficVLMConfig(), progress_cb=pipeline_progress)
                        pipeline_result = pipeline.run(video_source_path, user_intent, camera_id=camera_id, mode="violation")

                        # è¿”å›è¯¦ç»†çš„åˆ†æç»“æœï¼Œè€Œä¸æ˜¯æ‘˜è¦
                        detailed_analysis = extract_detailed_analysis(pipeline_result)

                        response_data = {
                            'type': 'complete',
                            'success': True,
                            'result': detailed_analysis,
                            'analysis_mode': 'traffic_vlm',
                            'video_source': video_source_path,
                            'model': model,
                            'pipeline': pipeline_result
                        }
                        progress_queues[session_id].put(response_data)
                    except InterruptedError as e:
                        print(f"[Session {session_id}] TrafficVLM pipeline è¢«ç”¨æˆ·åœæ­¢")
                        # ä¸å‘é€é”™è¯¯æ¶ˆæ¯ï¼Œåœæ­¢æ¶ˆæ¯å·²é€šè¿‡ /stop ç«¯ç‚¹å‘é€
                    except Exception as e:
                        progress_queues[session_id].put({
                            'type': 'error',
                            'message': f'TrafficVLM pipeline failed: {str(e)}'
                        })
                    return

                if analysis_mode == 'accident_search':
                    # æ£€æŸ¥æ˜¯å¦å·²è¢«åœæ­¢
                    if is_stopped(session_id):
                        print(f"[Session {session_id}] ä»»åŠ¡å·²è¢«åœæ­¢ï¼ˆaccident pipelineå¯åŠ¨å‰ï¼‰")
                        return

                    print(f"\n{'='*60}")
                    print(f"Accident Search pipeline start (Session: {session_id})")
                    print(f"Source: {video_source_path}")
                    print(f"Camera ID: {camera_id}")
                    print(f"Query: {user_intent}")
                    print(f"{'='*60}\n")

                    try:
                        pipeline = TrafficVLMPipeline(config=TrafficVLMConfig(), progress_cb=pipeline_progress)
                        pipeline_result = pipeline.run(video_source_path, user_intent, camera_id=camera_id, mode="accident")

                        # è¿”å›è¯¦ç»†çš„åˆ†æç»“æœ
                        detailed_analysis = extract_detailed_analysis(pipeline_result)

                        response_data = {
                            'type': 'complete',
                            'success': True,
                            'result': detailed_analysis,
                            'analysis_mode': 'accident_search',
                            'video_source': video_source_path,
                            'model': model,
                            'pipeline': pipeline_result
                        }
                        progress_queues[session_id].put(response_data)
                    except InterruptedError as e:
                        print(f"[Session {session_id}] Accident Search pipeline è¢«ç”¨æˆ·åœæ­¢")
                        # ä¸å‘é€é”™è¯¯æ¶ˆæ¯ï¼Œåœæ­¢æ¶ˆæ¯å·²é€šè¿‡ /stop ç«¯ç‚¹å‘é€
                    except Exception as e:
                        progress_queues[session_id].put({
                            'type': 'error',
                            'message': f'Accident Search pipeline failed: {str(e)}'
                        })
                    return

                if video_url:
                    print(f"\n{'='*60}")
                    print(f"Received video analysis request (Session: {session_id})")
                    print(f"Video URL: {video_url}")
                    print(f"Input method: URL (max 10GB)")
                    print(f"{'='*60}\n")

                    result = analyze_video_with_api(video_url=video_url, prompt=prompt, model=model, session_id=session_id)

                    response_data = {
                        'type': 'complete',
                        'success': True,
                        'result': result,
                        'video_source': video_url,
                        'model': model,
                        'input_method': 'url'
                    }

                    progress_queues[session_id].put(response_data)

                else:
                    file_size_mb = os.path.getsize(filepath) / (1024*1024)

                    print(f"\n{'='*60}")
                    print(f"Received video analysis request (Session: {session_id})")
                    print(f"Video file: {filename}")
                    print(f"Path: {filepath}")
                    print(f"Size: {file_size_mb:.2f} MB")
                    print(f"Auto compress: {auto_compress}")
                    print(f"Sampling: {sampling_strategy}")
                    print(f"{'='*60}\n")

                    final_video_path = filepath
                    compressed_filename = None

                    if auto_compress and file_size_mb > 7.0 and sampling_strategy == 'full_video':
                        print("Large file, start auto compression...")

                        if not check_ffmpeg():
                            progress_queues[session_id].put({
                                'type': 'error',
                                'message': 'FFmpeg not installed, cannot compress.'
                            })
                            return

                        name, ext = os.path.splitext(filename)
                        compressed_filename = f"{name}_compressed{ext}"
                        compressed_path = os.path.join(app.config['UPLOAD_FOLDER'], compressed_filename)

                        target_size_mb = 6.5
                        success = compress_video(filepath, compressed_path, target_size_mb=target_size_mb, session_id=session_id)

                        if success:
                            print(f"Use compressed video: {compressed_filename}")
                            final_video_path = compressed_path
                            try:
                                current_size_mb = os.path.getsize(compressed_path) / (1024 * 1024)
                            except Exception:
                                current_size_mb = None

                            retry = 0
                            while current_size_mb is not None and current_size_mb > TARGET_ORIGINAL_MB and retry < MAX_COMPRESS_RETRY:
                                retry += 1
                                ratio = TARGET_ORIGINAL_MB / max(current_size_mb, 0.01)
                                new_target = max(1.0, target_size_mb * ratio * 0.9)

                                print(f"Compressed still {current_size_mb:.2f} MB, retry {retry}, target {new_target:.2f} MB")
                                progress_queues[session_id].put({
                                    'type': 'compress',
                                    'progress': 15,
                                    'message': f'Re-compress #{retry}, target {new_target:.2f}MB'
                                })

                                target_size_mb = new_target
                                success = compress_video(filepath, compressed_path, target_size_mb=target_size_mb, session_id=session_id)
                                if not success:
                                    print("Adaptive compression failed, keep last result")
                                    break

                                try:
                                    current_size_mb = os.path.getsize(compressed_path) / (1024 * 1024)
                                except Exception:
                                    current_size_mb = None

                            if current_size_mb is not None and current_size_mb > TARGET_ORIGINAL_MB:
                                progress_queues[session_id].put({
                                    'type': 'compress',
                                    'progress': 95,
                                    'message': f'Still above threshold ({current_size_mb:.2f}MB>{TARGET_ORIGINAL_MB:.2f}MB), may fail upload'
                                })
                        else:
                            print("Compression failed, use original video")

                    if sampling_strategy != 'full_video':
                        print(f"\nSampling strategy: {sampling_strategy}")

                        if sampling_strategy == 'uniform_fps':
                            frames, metadata = extract_frames_uniform(final_video_path, fps=uniform_fps, session_id=session_id)
                        elif sampling_strategy == 'keyframe_only':
                            frames, metadata = extract_frames_keyframes(final_video_path, num_keyframes=keyframe_count, session_id=session_id)
                        elif sampling_strategy == 'accident_analysis':
                            frames, metadata = extract_frames_accident_analysis(final_video_path, accident_config, session_id=session_id)
                        else:
                            frames, metadata = extract_frames_uniform(final_video_path, fps=1.0, session_id=session_id)

                        try:
                            save_frames_to_folder(frames, sampling_strategy, filename)
                        except Exception as e:
                            print(f"Save frames failed: {str(e)}")

                        base64_images = frames_to_base64_images(frames, max_tokens=250000)
                        result = analyze_images_with_api(base64_images, prompt=prompt, model=model, session_id=session_id)

                        response_data = {
                            'type': 'complete',
                            'success': True,
                            'result': result,
                            'video_name': filename,
                            'model': model,
                            'input_method': 'upload',
                            'sampling_strategy': sampling_strategy,
                            'frames_extracted': len(frames),
                            'metadata': metadata
                        }

                    else:
                        result = analyze_video_with_api(video_path=final_video_path, prompt=prompt, model=model, session_id=session_id)

                        response_data = {
                            'type': 'complete',
                            'success': True,
                            'result': result,
                            'video_name': filename,
                            'model': model,
                            'input_method': 'upload'
                        }

                    if compressed_filename and os.path.exists(compressed_path):
                        response_data['compressed_video'] = compressed_filename
                        response_data['compressed_size'] = f"{os.path.getsize(compressed_path) / (1024*1024):.2f} MB"
                        response_data['original_size'] = f"{file_size_mb:.2f} MB"

                    progress_queues[session_id].put(response_data)

            except InterruptedError as e:
                # ç”¨æˆ·ä¸»åŠ¨åœæ­¢åˆ†æ
                print(f"\n[Session {session_id}] åˆ†æè¢«ç”¨æˆ·åœæ­¢: {str(e)}\n")
                if compressed_path and os.path.exists(compressed_path):
                    try:
                        os.remove(compressed_path)
                    except:
                        pass
                # ä¸å‘é€é”™è¯¯æ¶ˆæ¯ï¼Œåœæ­¢æ¶ˆæ¯å·²é€šè¿‡ /stop ç«¯ç‚¹å‘é€
            except Exception as e:
                print(f"\nError: {str(e)}\n")
                if compressed_path and os.path.exists(compressed_path):
                    try:
                        os.remove(compressed_path)
                    except:
                        pass

                progress_queues[session_id].put({
                    'type': 'error',
                    'message': str(e)
                })
            finally:
                # æ¸…ç†ä¼šè¯èµ„æº
                if session_id in stop_flags:
                    del stop_flags[session_id]

        # å¯åŠ¨åå°çº¿ç¨‹
        thread = threading.Thread(target=process_video)
        thread.daemon = True
        thread.start()

        # ç«‹å³è¿”å›session_id
        return jsonify({
            'success': True,
            'session_id': session_id
        })

    except Exception as e:
        print(f"\né”™è¯¯: {str(e)}\n")
        return jsonify({'error': str(e)}), 500

@app.route('/download/<filename>')
def download(filename):
    """ä¸‹è½½å‹ç¼©åçš„è§†é¢‘æ–‡ä»¶"""
    try:
        filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
        if os.path.exists(filepath):
            return send_file(filepath, as_attachment=True, download_name=filename)
        else:
            return jsonify({'error': 'æ–‡ä»¶ä¸å­˜åœ¨'}), 404
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/stop/<session_id>', methods=['POST'])
def stop_analysis(session_id):
    """åœæ­¢æŒ‡å®šä¼šè¯çš„åˆ†æä»»åŠ¡"""
    try:
        print(f"\n{'='*60}")
        print(f"æ”¶åˆ°åœæ­¢è¯·æ±‚ (Session: {session_id})")
        print(f"{'='*60}\n")

        # è®¾ç½®åœæ­¢æ ‡å¿—
        stop_flags[session_id] = True

        # å‘é˜Ÿåˆ—å‘é€åœæ­¢æ¶ˆæ¯
        if session_id in progress_queues:
            progress_queues[session_id].put({
                'type': 'stopped',
                'message': 'åˆ†æå·²åœæ­¢'
            })

        return jsonify({
            'success': True,
            'message': 'åœæ­¢è¯·æ±‚å·²å‘é€',
            'session_id': session_id
        })

    except Exception as e:
        print(f"åœæ­¢åˆ†æé”™è¯¯: {str(e)}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/health', methods=['GET'])
def health():
    """å¥åº·æ£€æŸ¥æ¥å£"""
    has_api_key = bool(DASHSCOPE_API_KEY)
    has_ffmpeg = check_ffmpeg()
    return jsonify({
        'status': 'ok',
        'api_configured': has_api_key,
        'ffmpeg_installed': has_ffmpeg,
        'available_models': list(AVAILABLE_MODELS.keys())
    })

@app.route('/config', methods=['GET'])
def config_info():
    """è·å–é…ç½®ä¿¡æ¯"""
    return jsonify({
        'api_key_configured': bool(DASHSCOPE_API_KEY),
        'available_models': AVAILABLE_MODELS,
        'max_video_size_mb': MAX_VIDEO_SIZE / (1024 * 1024),
        'allowed_extensions': list(ALLOWED_EXTENSIONS)
    })

if __name__ == '__main__':
    print("=" * 60)
    print("Qwen3-VL è§†é¢‘åˆ†ææœåŠ¡ (DashScope API)")
    print("=" * 60)
    print()

    # æ£€æŸ¥ API Key
    if DASHSCOPE_API_KEY:
        print("âœ“ DashScope API Key å·²é…ç½®")
        print(f"  API Key: {DASHSCOPE_API_KEY[:8]}...")
    else:
        print("âœ— è­¦å‘Š: æœªé…ç½® DashScope API Key")
        print("  è¯·è®¾ç½®ç¯å¢ƒå˜é‡:")
        print("    Windows: set DASHSCOPE_API_KEY=your_api_key")
        print("    Linux/Mac: export DASHSCOPE_API_KEY=your_api_key")
        print("  æˆ–åœ¨ app.py ä¸­ç›´æ¥è®¾ç½® DASHSCOPE_API_KEY å˜é‡")
        print()
        print("  è·å– API Key: https://dashscope.console.aliyun.com/apiKey")

    print()
    print(f"å¯ç”¨æ¨¡å‹: {len(AVAILABLE_MODELS)} ä¸ª")
    for model_id, model_name in AVAILABLE_MODELS.items():
        print(f"  - {model_id}: {model_name}")

    # æ£€æŸ¥ GPU åŠ é€Ÿæ”¯æŒ
    print()
    if check_nvenc_support():
        print("âœ“ NVIDIA GPU ç¡¬ä»¶åŠ é€Ÿå·²å¯ç”¨")
        print("  è§†é¢‘å‹ç¼©å°†ä½¿ç”¨ NVENC åŠ é€Ÿ (æ¯”CPUå¿«3-10å€)")
    else:
        print("âœ— æœªæ£€æµ‹åˆ° NVIDIA GPU æ”¯æŒ")
        print("  è§†é¢‘å‹ç¼©å°†ä½¿ç”¨ CPU ç¼–ç  (è¾ƒæ…¢)")

    print()
    print("=" * 60)
    print("æœåŠ¡å¯åŠ¨åœ¨: http://localhost:5000")
    print("=" * 60)
    print()

    # å¯åŠ¨ Flask åº”ç”¨
    app.run(host='0.0.0.0', port=5000, debug=True)
