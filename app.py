"""
Qwen3-VL è§†é¢‘åˆ†æ Web åº”ç”¨
é€šè¿‡é˜¿é‡Œäº‘ DashScope API è°ƒç”¨ Qwen3-VL æ¨¡å‹è¿›è¡Œè§†é¢‘åˆ†æ
"""

import atexit
import signal
import sys
import io
import os

# è®¾ç½®æ ‡å‡†è¾“å‡ºä¸º UTF-8 ç¼–ç ï¼ˆWindows å…¼å®¹ï¼‰
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

# è®¾ç½® HuggingFace æ¨¡å‹ç¼“å­˜ç›®å½•ï¼Œé¿å…é‡å¤ä¸‹è½½
HF_CACHE_DIR = os.path.join(os.path.dirname(__file__), "models", "huggingface")
os.makedirs(HF_CACHE_DIR, exist_ok=True)
os.environ["HF_HOME"] = HF_CACHE_DIR
os.environ["TRANSFORMERS_CACHE"] = HF_CACHE_DIR

# æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²ç¼“å­˜ï¼Œå¦‚æœå·²ç¼“å­˜åˆ™å¯ç”¨ç¦»çº¿æ¨¡å¼
_siglip_cache_path = os.path.join(HF_CACHE_DIR, "hub", "models--google--siglip-base-patch16-384")
if os.path.exists(_siglip_cache_path):
    os.environ["HF_HUB_OFFLINE"] = "1"  # å¼ºåˆ¶ç¦»çº¿æ¨¡å¼ï¼Œä¸è”ç½‘æ£€æŸ¥æ›´æ–°
    print(f"[HuggingFace] âœ“ æ£€æµ‹åˆ°æœ¬åœ°ç¼“å­˜ï¼Œå¯ç”¨ç¦»çº¿æ¨¡å¼")
else:
    # ä½¿ç”¨å›½å†…é•œåƒåŠ é€Ÿä¸‹è½½
    os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"
    print(f"[HuggingFace] æœ¬åœ°ç¼“å­˜ä¸å­˜åœ¨ï¼Œä½¿ç”¨é•œåƒç«™ä¸‹è½½æ¨¡å‹...")
print(f"[HuggingFace] æ¨¡å‹ç¼“å­˜ç›®å½•: {HF_CACHE_DIR}")

from flask import Flask, render_template, request, jsonify, send_file, Response, stream_with_context
import os
import base64
import subprocess
import math
import re
import json
import time
import threading
from queue import Queue, Empty
from openai import OpenAI

# æ–°å¢ï¼šè§†é¢‘æŠ½å¸§ç›¸å…³å¯¼å…¥
import cv2
import numpy as np
from PIL import Image
import tempfile
import shutil
from datetime import datetime, timedelta

# TrafficVLM æ¨¡å—
from traffic_vlm.pipeline import TrafficVLMPipeline
from traffic_vlm.config import TrafficVLMConfig
from traffic_vlm.embedding_indexer import cleanup_embedding_service

# å¯é€‰ï¼šé«˜çº§æŠ½å¸§åº“
try:
    import decord
    HAS_DECORD = True
except ImportError:
    HAS_DECORD = False
    print("è­¦å‘Š: æœªå®‰è£…decordï¼Œå°†ä½¿ç”¨OpenCVæå–å¸§ï¼ˆé€Ÿåº¦è¾ƒæ…¢ï¼‰")

try:
    from scenedetect import detect, ContentDetector
    HAS_SCENEDETECT = True
except ImportError:
    HAS_SCENEDETECT = False
    print("è­¦å‘Š: æœªå®‰è£…scenedetectï¼Œåœºæ™¯æ£€æµ‹åŠŸèƒ½å°†ä¸å¯ç”¨")

app = Flask(__name__)

# é…ç½®
UPLOAD_FOLDER = 'uploads'
ALLOWED_EXTENSIONS = {'mp4', 'avi', 'mkv', 'mov', 'flv', 'wmv'}
MAX_VIDEO_SIZE = 500 * 1024 * 1024  # 500MB

app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER
app.config['MAX_CONTENT_LENGTH'] = MAX_VIDEO_SIZE

# ä¸Šä¼ åˆ° API çš„åŸå§‹è§†é¢‘ç›®æ ‡å¤§å°ï¼ˆä¸º base64 å¢é•¿é¢„ç•™è£•é‡ï¼‰
TARGET_ORIGINAL_MB = float(os.getenv('TARGET_ORIGINAL_MB', '7.2'))
# è‡ªé€‚åº”å‹ç¼©æœ€å¤§é‡è¯•æ¬¡æ•°
MAX_COMPRESS_RETRY = int(os.getenv('MAX_COMPRESS_RETRY', '3'))

# åˆ›å»ºä¸Šä¼ æ–‡ä»¶å¤¹
os.makedirs(UPLOAD_FOLDER, exist_ok=True)

# å…¨å±€è¿›åº¦é˜Ÿåˆ—ï¼ˆç”¨äºSSEæ¨é€ï¼‰
progress_queues = {}

# å…¨å±€åœæ­¢æ ‡å¿—ï¼ˆç”¨äºä¸­æ–­åˆ†æï¼‰
stop_flags = {}


def is_stopped(session_id: str) -> bool:
    """æ£€æŸ¥ä¼šè¯æ˜¯å¦å·²è¢«è¯·æ±‚åœæ­¢"""
    return stop_flags.get(session_id, False)

# é˜¿é‡Œäº‘ DashScope API é…ç½®
# ä»ç¯å¢ƒå˜é‡è·å– API Keyï¼Œæˆ–è€…ç›´æ¥åœ¨è¿™é‡Œè®¾ç½®
DASHSCOPE_API_KEY = os.getenv('DASHSCOPE_API_KEY', 'sk-5175677ff9b4459aa45ce7ec28037515')

# å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨
AVAILABLE_MODELS = {
    'qwen-vl-max': 'Qwen-VL-Maxï¼ˆæœ€å¼ºè§†è§‰ç†è§£èƒ½åŠ›ï¼‰',
    'qwen-vl-plus': 'Qwen-VL-Plusï¼ˆæ¨èï¼Œæ€§ä»·æ¯”é«˜ï¼‰',
    'qwen3-vl-plus': 'Qwen3-VL-Plusï¼ˆæœ€æ–°ç‰ˆæœ¬ï¼‰',
    'qwen3-vl-32b-instruct': 'Qwen3-VL-32B-Instructï¼ˆé˜¿é‡Œäº‘éƒ¨ç½²ï¼‰',
    'qwen3-vl-32b-thinking': 'Qwen3-VL-32B-Thinkingï¼ˆé˜¿é‡Œäº‘éƒ¨ç½²ï¼Œæ€ç»´é“¾æ¨¡å¼ï¼‰',
    'qwen3-vl-235b-a22b-instruct': 'Qwen3-VL-235B-A22B-Instructï¼ˆé˜¿é‡Œäº‘éƒ¨ç½²ï¼‰',
    'qwen3-vl-235b-a22b-thinking': 'Qwen3-VL-235B-A22B-Thinkingï¼ˆé˜¿é‡Œäº‘éƒ¨ç½²ï¼‰'
}

def allowed_file(filename):
    """æ£€æŸ¥æ–‡ä»¶æ‰©å±•åæ˜¯å¦å…è®¸"""
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

def get_remote_model_id(model_key: str) -> str:
    """æ ¹æ®æœ¬åœ°æ¨¡å‹é”®è·å–è¿œç«¯æ¨¡å‹ IDï¼Œå¯ç”¨ç¯å¢ƒå˜é‡è¦†ç›–ã€‚
    ç¯å¢ƒå˜é‡å‘½åï¼šMODEL_ID_{KEY_UPPER_UNDERSCORE}
    ä¾‹å¦‚ï¼šMODEL_ID_QWEN3_VL_235B_A22B_THINKING / MODEL_ID_QWEN_VLMAX_20250813
    æœªè®¾ç½®åˆ™è¿”å›åŸå§‹é”®å€¼ã€‚
    """
    try:
        env_key = 'MODEL_ID_' + re.sub(r'[^A-Z0-9_]', '_', model_key.upper())
        return os.getenv(env_key, model_key)
    except Exception:
        return model_key

def encode_video_to_base64(video_path):
    """
    å°†è§†é¢‘æ–‡ä»¶ç¼–ç ä¸º base64 å­—ç¬¦ä¸²

    Args:
        video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„

    Returns:
        str: base64 ç¼–ç çš„è§†é¢‘å­—ç¬¦ä¸²
    """
    with open(video_path, "rb") as video_file:
        return base64.b64encode(video_file.read()).decode("utf-8")

def check_ffmpeg():
    """æ£€æŸ¥ FFmpeg æ˜¯å¦å®‰è£…"""
    try:
        # Windows ç³»ç»Ÿä¸Šéœ€è¦ä½¿ç”¨ shell=True æˆ–è€…å®Œæ•´è·¯å¾„
        if sys.platform == 'win32':
            result = subprocess.run(['ffmpeg', '-version'],
                                  capture_output=True,
                                  text=True,
                                  timeout=5,
                                  shell=True)
        else:
            result = subprocess.run(['ffmpeg', '-version'],
                                  capture_output=True,
                                  text=True,
                                  timeout=5)
        return result.returncode == 0
    except Exception as e:
        print(f"FFmpeg æ£€æµ‹é”™è¯¯: {str(e)}")
        return False

def check_nvenc_support():
    """æ£€æŸ¥ FFmpeg æ˜¯å¦æ”¯æŒ NVIDIA NVENC ç¡¬ä»¶åŠ é€Ÿ"""
    try:
        if sys.platform == 'win32':
            result = subprocess.run(['ffmpeg', '-encoders'],
                                  capture_output=True,
                                  text=True,
                                  timeout=5,
                                  shell=True)
        else:
            result = subprocess.run(['ffmpeg', '-encoders'],
                                  capture_output=True,
                                  text=True,
                                  timeout=5)

        # æ£€æŸ¥æ˜¯å¦æ”¯æŒ h264_nvenc
        return 'h264_nvenc' in result.stdout
    except Exception as e:
        print(f"NVENC æ£€æµ‹é”™è¯¯: {str(e)}")
        return False

def compress_video(input_path, output_path, target_size_mb=6.5, session_id=None):
    """
    ä½¿ç”¨ FFmpeg å‹ç¼©è§†é¢‘åˆ°ç›®æ ‡å¤§å°ï¼Œå¹¶å®æ—¶æŠ¥å‘Šè¿›åº¦

    Args:
        input_path: è¾“å…¥è§†é¢‘è·¯å¾„
        output_path: è¾“å‡ºè§†é¢‘è·¯å¾„
        target_size_mb: ç›®æ ‡æ–‡ä»¶å¤§å°ï¼ˆMBï¼‰
        session_id: ä¼šè¯IDï¼Œç”¨äºè¿›åº¦æ¨é€

    Returns:
        bool: æ˜¯å¦æˆåŠŸ
    """
    try:
        # å‘é€è¿›åº¦æ›´æ–°
        def send_progress(percent, message):
            if session_id and session_id in progress_queues:
                progress_queues[session_id].put({
                    'type': 'compress',
                    'progress': percent,
                    'message': message
                })

        send_progress(0, 'æ­£åœ¨åˆ†æè§†é¢‘...')

        # è·å–è§†é¢‘æ—¶é•¿
        probe_cmd = [
            'ffprobe',
            '-v', 'error',
            '-show_entries', 'format=duration',
            '-of', 'default=noprint_wrappers=1:nokey=1',
            input_path
        ]

        # Windows éœ€è¦ shell=True
        if sys.platform == 'win32':
            result = subprocess.run(probe_cmd, capture_output=True, text=True, timeout=30, shell=True)
        else:
            result = subprocess.run(probe_cmd, capture_output=True, text=True, timeout=30)
        duration = float(result.stdout.strip())

        print(f"è§†é¢‘æ—¶é•¿: {duration:.2f} ç§’")
        send_progress(10, f'è§†é¢‘æ—¶é•¿: {duration:.2f}ç§’')

        # è®¡ç®—ç›®æ ‡ç ç‡ï¼ˆè€ƒè™‘éŸ³é¢‘ç ç‡çº¦128kbpsï¼‰
        target_bitrate = int((target_size_mb * 8 * 1024) / duration - 128)
        if target_bitrate < 100:
            target_bitrate = 100  # æœ€ä½100kbps

        print(f"ç›®æ ‡è§†é¢‘ç ç‡: {target_bitrate} kbps")
        send_progress(15, 'å¼€å§‹å‹ç¼©è§†é¢‘...')

        # æ¨¡æ‹Ÿè¿›åº¦æ›´æ–°
        import threading

        # è·å–è¾“å…¥æ–‡ä»¶å¤§å°ï¼Œç”¨äºæ›´å‡†ç¡®çš„è¿›åº¦ä¼°ç®—
        input_size_mb = os.path.getsize(input_path) / (1024 * 1024)

        # åŠ¨æ€è®¾å®šåˆ†è¾¨ç‡/å¸§ç‡ç­–ç•¥ï¼ˆéšç›®æ ‡ç ç‡é™ä½ï¼‰
        # æœ€å°å®½åº¦854ï¼Œé¿å…è¿‡åº¦å‹ç¼©æŸå¤±ç»†èŠ‚
        scale_width = None
        output_fps = None
        if target_bitrate < 220:
            scale_width = 854  # æœ€å°å®½åº¦854
            output_fps = 15
        elif target_bitrate < 350:
            scale_width = 854  # æœ€å°å®½åº¦854
            output_fps = 20
        elif target_bitrate < 600:
            scale_width = 854
        elif target_bitrate < 1000:
            scale_width = 1280

        # æ£€æµ‹æ˜¯å¦æ”¯æŒ NVIDIA GPU åŠ é€Ÿ
        use_gpu = check_nvenc_support()

        if use_gpu:
            print("âœ“ æ£€æµ‹åˆ° NVIDIA GPU æ”¯æŒï¼Œä½¿ç”¨ç¡¬ä»¶åŠ é€Ÿ")
            send_progress(15, 'ä½¿ç”¨ GPU ç¡¬ä»¶åŠ é€Ÿå‹ç¼©...')

            # GPU åŠ é€Ÿå‘½ä»¤ï¼ˆä½¿ç”¨ NVENCï¼‰
            compress_cmd = [
                'ffmpeg',
                '-hwaccel', 'cuda',                    # ç¡¬ä»¶åŠ é€Ÿ
                '-hwaccel_output_format', 'cuda',      # ä¿æŒæ•°æ®åœ¨GPUæ˜¾å­˜
                '-i', input_path,
                '-c:v', 'h264_nvenc',                  # NVIDIA H.264 ç¼–ç å™¨
                '-b:v', f'{target_bitrate}k',
                '-maxrate', f'{target_bitrate}k',
                '-bufsize', f'{target_bitrate * 2}k',
                '-preset', 'p4',                       # p4 = medium (p1æœ€å¿«/è´¨é‡æœ€ä½, p7æœ€æ…¢/è´¨é‡æœ€é«˜)
                '-rc', 'vbr',                          # å¯å˜ç ç‡
                '-vf', 'scale_cuda=trunc(iw/2)*2:trunc(ih/2)*2',  # GPUç¼©æ”¾æ»¤é•œ
                '-c:a', 'aac',                         # éŸ³é¢‘ç¼–ç 
                '-b:a', '128k',
                '-y',
                output_path
            ]
            # åŠ¨æ€è¿‡æ»¤å™¨ï¼ˆè¦†ç›–é»˜è®¤ -vfï¼‰ï¼Œåœ¨ GPU è·¯å¾„ä¸‹ä¹Ÿå…è®¸ä½¿ç”¨ CPU è¿‡æ»¤å™¨ä»¥è¾¾åˆ°æ›´å°ä½“ç§¯
            if 'compress_cmd' in locals():
                if scale_width or output_fps:
                    _filters = []
                    if scale_width:
                        _filters.append(f'scale={scale_width}:-2')
                    if output_fps:
                        _filters.append(f'fps={output_fps}')
                    try:
                        compress_cmd.insert(-1, '-filter:v')
                        compress_cmd.insert(-1, ','.join(_filters))
                    except Exception:
                        pass

            # GPU åŠ é€Ÿå¤§çº¦æ¯ç§’å¤„ç† 2-5 ç§’çš„è§†é¢‘å†…å®¹ï¼ˆæ¯”CPUå¿«3-10å€ï¼‰
            estimated_time = duration / 2.0  # ç§’
        else:
            print("âœ— æœªæ£€æµ‹åˆ° NVIDIA GPU æ”¯æŒï¼Œä½¿ç”¨ CPU ç¼–ç ")
            send_progress(15, 'ä½¿ç”¨ CPU å‹ç¼©ï¼ˆè¾ƒæ…¢ï¼‰...')

            # CPU ç¼–ç å‘½ä»¤
            compress_cmd = [
                'ffmpeg',
                '-i', input_path,
                '-c:v', 'libx264',                     # CPU H.264 ç¼–ç å™¨
                '-b:v', f'{target_bitrate}k',
                '-maxrate', f'{target_bitrate}k',
                '-bufsize', f'{target_bitrate * 2}k',
                '-preset', 'medium',                   # CPU preset
                '-vf', 'scale=trunc(iw/2)*2:trunc(ih/2)*2',
                '-c:a', 'aac',
                '-b:a', '128k',
                '-y',
                output_path
            ]
            # åŠ¨æ€è¿‡æ»¤å™¨ï¼ˆè¦†ç›–é»˜è®¤ -vfï¼‰
            if 'compress_cmd' in locals():
                if scale_width or output_fps:
                    _filters = []
                    if scale_width:
                        _filters.append(f'scale={scale_width}:-2')
                    if output_fps:
                        _filters.append(f'fps={output_fps}')
                    try:
                        compress_cmd.insert(-1, '-filter:v')
                        compress_cmd.insert(-1, ','.join(_filters))
                    except Exception:
                        pass

            # CPU å¤§çº¦æ¯ç§’å¤„ç† 0.3 ç§’çš„è§†é¢‘å†…å®¹
            estimated_time = duration / 0.3  # ç§’

        print(f"é¢„ä¼°å‹ç¼©æ—¶é—´: {estimated_time:.1f} ç§’ ({estimated_time/60:.1f} åˆ†é’Ÿ)")
        print(f"æ‰§è¡Œå‹ç¼©å‘½ä»¤: {' '.join(compress_cmd)}")

        # å¯åŠ¨å‹ç¼©è¿›ç¨‹ - å…³é”®ä¿®å¤ï¼šstderr é‡å®šå‘åˆ° DEVNULL é¿å…ç¼“å†²åŒºé˜»å¡
        if sys.platform == 'win32':
            process = subprocess.Popen(compress_cmd,
                                      stdout=subprocess.DEVNULL,
                                      stderr=subprocess.DEVNULL,  # é¿å… stderr ç¼“å†²åŒºé˜»å¡
                                      shell=True)
        else:
            process = subprocess.Popen(compress_cmd,
                                      stdout=subprocess.DEVNULL,
                                      stderr=subprocess.DEVNULL)

        # æ¨¡æ‹Ÿè¿›åº¦æ›´æ–°çº¿ç¨‹ - ä½¿ç”¨æ›´å‡†ç¡®çš„ä¼°ç®—
        def simulate_progress():
            start_time = time.time()
            last_progress = 15

            while process.poll() is None:  # è¿›ç¨‹è¿˜åœ¨è¿è¡Œ
                elapsed = time.time() - start_time

                # åŸºäºé¢„ä¼°æ—¶é—´è®¡ç®—è¿›åº¦ï¼ˆ15% -> 95%ï¼‰
                if estimated_time > 0:
                    progress_ratio = elapsed / estimated_time
                    estimated_progress = min(95, 15 + int(progress_ratio * 80))
                else:
                    # é™çº§æ–¹æ¡ˆï¼šåŸºäºè§†é¢‘æ—¶é•¿
                    estimated_progress = min(95, 15 + int((elapsed / (duration * 0.5)) * 80))

                # ç¡®ä¿è¿›åº¦åªå¢ä¸å‡
                estimated_progress = max(last_progress, estimated_progress)
                last_progress = estimated_progress

                # æ ¼å¼åŒ–æ¶ˆæ¯
                if elapsed < 60:
                    time_msg = f'å‹ç¼©ä¸­... {int(elapsed)}s'
                else:
                    minutes = int(elapsed / 60)
                    seconds = int(elapsed % 60)
                    time_msg = f'å‹ç¼©ä¸­... {minutes}m {seconds}s'

                # å¦‚æœè¶…è¿‡é¢„ä¼°æ—¶é—´ï¼Œæ˜¾ç¤ºæç¤º
                if elapsed > estimated_time * 1.2:
                    time_msg += ' (å³å°†å®Œæˆ...)'

                send_progress(estimated_progress, time_msg)
                time.sleep(2)  # æ¯2ç§’æ›´æ–°ä¸€æ¬¡

        progress_thread = threading.Thread(target=simulate_progress)
        progress_thread.daemon = True
        progress_thread.start()

        # ç­‰å¾…è¿›ç¨‹å®Œæˆ
        returncode = process.wait()

        # ç­‰å¾…è¿›åº¦çº¿ç¨‹ç»“æŸ
        progress_thread.join(timeout=1)

        # æ£€æŸ¥ç»“æœ
        if returncode == 0 and os.path.exists(output_path):
            output_size = os.path.getsize(output_path) / (1024 * 1024)
            print(f"å‹ç¼©æˆåŠŸï¼è¾“å‡ºæ–‡ä»¶å¤§å°: {output_size:.2f} MB")
            if use_gpu:
                send_progress(100, f'GPUåŠ é€Ÿå‹ç¼©å®Œæˆï¼æ–‡ä»¶å¤§å°: {output_size:.2f}MB')
            else:
                send_progress(100, f'å‹ç¼©å®Œæˆï¼æ–‡ä»¶å¤§å°: {output_size:.2f}MB')
            return True
        else:
            print(f"FFmpeg è¿”å›ç : {returncode}")

            # å¦‚æœ GPU åŠ é€Ÿå¤±è´¥ï¼Œè‡ªåŠ¨é™çº§åˆ° CPU ç¼–ç 
            if use_gpu and returncode != 0:
                print("âš  GPU åŠ é€Ÿå¤±è´¥ï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ° CPU ç¼–ç ...")
                send_progress(15, 'GPUå¤±è´¥ï¼Œåˆ‡æ¢åˆ°CPUç¼–ç ...')

                # CPU ç¼–ç å‘½ä»¤
                cpu_compress_cmd = [
                    'ffmpeg',
                    '-i', input_path,
                    '-c:v', 'libx264',
                    '-b:v', f'{target_bitrate}k',
                    '-maxrate', f'{target_bitrate}k',
                    '-bufsize', f'{target_bitrate * 2}k',
                    '-preset', 'medium',
                    '-vf', 'scale=trunc(iw/2)*2:trunc(ih/2)*2',
                    '-c:a', 'aac',
                    '-b:a', '128k',
                    '-y',
                    output_path
                ]

                print(f"ä½¿ç”¨ CPU ç¼–ç é‡è¯•...")
                print(f"æ‰§è¡Œå‘½ä»¤: {' '.join(cpu_compress_cmd)}")

                # é‡æ–°ä¼°ç®—æ—¶é—´ï¼ˆCPU è¾ƒæ…¢ï¼‰
                estimated_time = duration / 0.3

                # å¯åŠ¨ CPU ç¼–ç è¿›ç¨‹
                if sys.platform == 'win32':
                    cpu_process = subprocess.Popen(cpu_compress_cmd,
                                                   stdout=subprocess.DEVNULL,
                                                   stderr=subprocess.DEVNULL,
                                                   shell=True)
                else:
                    cpu_process = subprocess.Popen(cpu_compress_cmd,
                                                   stdout=subprocess.DEVNULL,
                                                   stderr=subprocess.DEVNULL)

                # é‡æ–°å¯åŠ¨è¿›åº¦çº¿ç¨‹
                def simulate_cpu_progress():
                    start_time = time.time()
                    last_progress = 15

                    while cpu_process.poll() is None:
                        elapsed = time.time() - start_time

                        if estimated_time > 0:
                            progress_ratio = elapsed / estimated_time
                            estimated_progress = min(95, 15 + int(progress_ratio * 80))
                        else:
                            estimated_progress = min(95, 15 + int((elapsed / (duration * 0.5)) * 80))

                        estimated_progress = max(last_progress, estimated_progress)
                        last_progress = estimated_progress

                        if elapsed < 60:
                            time_msg = f'CPUå‹ç¼©ä¸­... {int(elapsed)}s'
                        else:
                            minutes = int(elapsed / 60)
                            seconds = int(elapsed % 60)
                            time_msg = f'CPUå‹ç¼©ä¸­... {minutes}m {seconds}s'

                        if elapsed > estimated_time * 1.2:
                            time_msg += ' (å³å°†å®Œæˆ...)'

                        send_progress(estimated_progress, time_msg)
                        time.sleep(2)

                cpu_progress_thread = threading.Thread(target=simulate_cpu_progress)
                cpu_progress_thread.daemon = True
                cpu_progress_thread.start()

                # ç­‰å¾… CPU ç¼–ç å®Œæˆ
                cpu_returncode = cpu_process.wait()
                cpu_progress_thread.join(timeout=1)

                if cpu_returncode == 0 and os.path.exists(output_path):
                    output_size = os.path.getsize(output_path) / (1024 * 1024)
                    print(f"CPU ç¼–ç æˆåŠŸï¼è¾“å‡ºæ–‡ä»¶å¤§å°: {output_size:.2f} MB")
                    send_progress(100, f'CPUç¼–ç å®Œæˆï¼æ–‡ä»¶å¤§å°: {output_size:.2f}MB')
                    return True
                else:
                    print(f"CPU ç¼–ç ä¹Ÿå¤±è´¥äº†ï¼Œè¿”å›ç : {cpu_returncode}")
                    if not os.path.exists(output_path):
                        print("é”™è¯¯ï¼šè¾“å‡ºæ–‡ä»¶ä¸å­˜åœ¨")
                    send_progress(0, 'å‹ç¼©å¤±è´¥')
                    return False
            else:
                if not os.path.exists(output_path):
                    print("é”™è¯¯ï¼šè¾“å‡ºæ–‡ä»¶ä¸å­˜åœ¨")
                send_progress(0, 'å‹ç¼©å¤±è´¥')
                return False

    except Exception as e:
        print(f"å‹ç¼©è§†é¢‘æ—¶å‡ºé”™: {str(e)}")
        if session_id and session_id in progress_queues:
            progress_queues[session_id].put({
                'type': 'compress',
                'progress': 0,
                'message': f'å‹ç¼©å¤±è´¥: {str(e)}'
            })
        return False

# ============================================================
# è§†é¢‘æŠ½å¸§æ¨¡å—
# ============================================================

def extract_frames_uniform(video_path, fps=1.0, max_frames=None, session_id=None):
    """
    å‡åŒ€é‡‡æ ·ï¼šæŒ‰å›ºå®šFPSæå–å¸§

    Args:
        video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
        fps: é‡‡æ ·å¸§ç‡ï¼ˆæ¯ç§’æå–å‡ å¸§ï¼‰
        max_frames: æœ€å¤§å¸§æ•°é™åˆ¶
        session_id: ä¼šè¯IDï¼Œç”¨äºè¿›åº¦æ¨é€

    Returns:
        list: æå–çš„å¸§åˆ—è¡¨ï¼ˆPIL Imageå¯¹è±¡ï¼‰
        dict: å…ƒæ•°æ®ï¼ˆæ—¶é—´æˆ³ã€å¸§å·ç­‰ï¼‰
    """
    def send_progress(percent, message):
        if session_id and session_id in progress_queues:
            progress_queues[session_id].put({
                'type': 'sampling',
                'progress': percent,
                'message': message
            })

    try:
        send_progress(0, 'å¼€å§‹æå–å¸§...')

        # ä½¿ç”¨OpenCVæ‰“å¼€è§†é¢‘
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            raise ValueError("æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶")

        # è·å–è§†é¢‘ä¿¡æ¯
        video_fps = cap.get(cv2.CAP_PROP_FPS)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        duration = total_frames / video_fps

        print(f"è§†é¢‘ä¿¡æ¯: FPS={video_fps}, æ€»å¸§æ•°={total_frames}, æ—¶é•¿={duration:.2f}ç§’")
        send_progress(10, f'è§†é¢‘æ—¶é•¿{duration:.2f}ç§’ï¼Œå¼€å§‹æå–...')

        # è®¡ç®—é‡‡æ ·é—´éš”
        frame_interval = int(video_fps / fps)

        frames = []
        metadata = {
            'timestamps': [],
            'frame_indices': [],
            'video_fps': video_fps,
            'total_frames': total_frames,
            'duration': duration
        }

        frame_count = 0
        extracted_count = 0

        while True:
            ret, frame = cap.read()
            if not ret:
                break

            # æŒ‰é—´éš”æå–å¸§
            if frame_count % frame_interval == 0:
                # è½¬æ¢BGRåˆ°RGB
                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                pil_image = Image.fromarray(frame_rgb)

                frames.append(pil_image)
                metadata['timestamps'].append(frame_count / video_fps)
                metadata['frame_indices'].append(frame_count)

                extracted_count += 1

                # æ›´æ–°è¿›åº¦
                progress = int(10 + (frame_count / total_frames) * 80)
                send_progress(progress, f'å·²æå– {extracted_count} å¸§...')

                # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æœ€å¤§å¸§æ•°
                if max_frames and extracted_count >= max_frames:
                    break

            frame_count += 1

        cap.release()

        print(f"æå–å®Œæˆï¼šå…±æå– {len(frames)} å¸§")
        send_progress(100, f'æå–å®Œæˆï¼Œå…±{len(frames)}å¸§')

        return frames, metadata

    except Exception as e:
        print(f"æå–å¸§å¤±è´¥: {str(e)}")
        send_progress(0, f'æå–å¤±è´¥: {str(e)}')
        raise


def extract_frames_keyframes(video_path, num_keyframes=16, session_id=None):
    """
    å…³é”®å¸§æå–ï¼šå‡åŒ€æå–Nä¸ªå…³é”®å¸§

    Args:
        video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
        num_keyframes: æå–çš„å…³é”®å¸§æ•°é‡
        session_id: ä¼šè¯ID

    Returns:
        list: æå–çš„å¸§åˆ—è¡¨
        dict: å…ƒæ•°æ®
    """
    def send_progress(percent, message):
        if session_id and session_id in progress_queues:
            progress_queues[session_id].put({
                'type': 'sampling',
                'progress': percent,
                'message': message
            })

    try:
        send_progress(0, 'å¼€å§‹æå–å…³é”®å¸§...')

        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            raise ValueError("æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶")

        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        video_fps = cap.get(cv2.CAP_PROP_FPS)

        # è®¡ç®—å‡åŒ€é—´éš”
        indices = np.linspace(0, total_frames - 1, num_keyframes, dtype=int)

        frames = []
        metadata = {
            'timestamps': [],
            'frame_indices': [],
            'video_fps': video_fps,
            'total_frames': total_frames
        }

        for i, frame_idx in enumerate(indices):
            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
            ret, frame = cap.read()

            if ret:
                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                pil_image = Image.fromarray(frame_rgb)

                frames.append(pil_image)
                metadata['timestamps'].append(frame_idx / video_fps)
                metadata['frame_indices'].append(int(frame_idx))

                progress = int(10 + (i / len(indices)) * 90)
                send_progress(progress, f'æå–å…³é”®å¸§ {i+1}/{num_keyframes}...')

        cap.release()

        print(f"å…³é”®å¸§æå–å®Œæˆï¼š{len(frames)} å¸§")
        send_progress(100, f'æå–å®Œæˆï¼Œå…±{len(frames)}ä¸ªå…³é”®å¸§')

        return frames, metadata

    except Exception as e:
        print(f"æå–å…³é”®å¸§å¤±è´¥: {str(e)}")
        send_progress(0, f'æå–å¤±è´¥: {str(e)}')
        raise


def extract_frames_accident_analysis(video_path, config, session_id=None):
    """
    äº¤é€šäº‹æ•…åˆ†æä¸“ç”¨æŠ½å¸§ç­–ç•¥
    å®ç°å››é˜¶æ®µé‡‡æ ·ï¼ˆç®€åŒ–ç‰ˆï¼‰

    Args:
        video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
        config: é…ç½®å­—å…¸
        session_id: ä¼šè¯ID

    Returns:
        list: æå–çš„å¸§åˆ—è¡¨ï¼ˆæŒ‰é˜¶æ®µåˆ†ç»„ï¼‰
        dict: å…ƒæ•°æ®ï¼ˆåŒ…å«å„é˜¶æ®µä¿¡æ¯ï¼‰
    """
    def send_progress(percent, message):
        if session_id and session_id in progress_queues:
            progress_queues[session_id].put({
                'type': 'sampling',
                'progress': percent,
                'message': message
            })

    try:
        send_progress(0, 'äº¤é€šäº‹æ•…åˆ†æï¼šé˜¶æ®µ1 - ç²—æ‰«æ...')

        # é˜¶æ®µ1ï¼šç²—ç²’åº¦æ‰«æï¼ˆ1 FPSï¼‰
        frames_stage1, meta1 = extract_frames_uniform(
            video_path,
            fps=1.0,
            max_frames=600,  # æœ€å¤š10åˆ†é’Ÿ
            session_id=None  # ä¸é‡å¤æ¨é€è¿›åº¦
        )

        send_progress(25, f'é˜¶æ®µ1å®Œæˆï¼šæ‰«æ{len(frames_stage1)}å¸§')

        # é˜¶æ®µ2ï¼šé€‰æ‹©å…³é”®æ—¶é—´æ®µçš„å¸§ï¼ˆæ¨¡æ‹Ÿäº‹æ•…æ—¶åˆ»æ£€æµ‹ï¼‰
        # è¿™é‡Œç®€åŒ–ä¸ºé€‰æ‹©è§†é¢‘ä¸­æ®µçš„é«˜å¯†åº¦é‡‡æ ·
        duration = meta1['duration']
        accident_time = duration / 2  # å‡è®¾äº‹æ•…åœ¨ä¸­é—´

        send_progress(50, 'é˜¶æ®µ2ï¼šç²¾ç¡®å®šä½äº‹æ•…æ—¶åˆ»...')

        # æå–äº‹æ•…æ—¶åˆ»é™„è¿‘çš„å¯†é›†å¸§ï¼ˆÂ±10ç§’ï¼‰
        frames_stage2 = []
        for i, ts in enumerate(meta1['timestamps']):
            if abs(ts - accident_time) <= 10:  # äº‹æ•…å‰å10ç§’
                frames_stage2.append(frames_stage1[i])

        send_progress(75, f'é˜¶æ®µ2å®Œæˆï¼šå®šä½åˆ°{len(frames_stage2)}å¸§')

        # é˜¶æ®µ3ï¼šç¯å¢ƒåˆ†æå…³é”®å¸§ï¼ˆé€‰æ‹©5ä¸ªä»£è¡¨å¸§ï¼‰
        num_env_frames = min(5, len(frames_stage1))
        env_indices = np.linspace(0, len(frames_stage1)-1, num_env_frames, dtype=int)
        frames_stage3 = [frames_stage1[i] for i in env_indices]

        send_progress(90, 'é˜¶æ®µ3ï¼šæå–ç¯å¢ƒåˆ†æå¸§...')

        # åˆå¹¶æ‰€æœ‰å¸§ï¼ˆç®€å•åˆå¹¶ï¼Œä¸å»é‡ï¼Œå› ä¸ºPIL Imageå¯¹è±¡ä¸å¯å“ˆå¸Œï¼‰
        # ç”±äºframes_stage2å’Œframes_stage3æ˜¯ä»frames_stage1ä¸­é€‰å–çš„ï¼Œé‡å¤å½±å“ä¸å¤§
        all_frames = frames_stage1 + frames_stage2 + frames_stage3

        metadata = {
            'strategy': 'accident_analysis',
            'total_frames': len(all_frames),
            'stage1_frames': len(frames_stage1),
            'stage2_frames': len(frames_stage2),
            'stage3_frames': len(frames_stage3),
            'video_duration': duration,
            'estimated_accident_time': accident_time,
            'config': config
        }

        send_progress(100, f'äº‹æ•…åˆ†æå®Œæˆï¼šå…±{len(all_frames)}å¸§')

        return all_frames, metadata

    except Exception as e:
        print(f"äº‹æ•…åˆ†ææŠ½å¸§å¤±è´¥: {str(e)}")
        send_progress(0, f'æŠ½å¸§å¤±è´¥: {str(e)}')
        raise


def save_frames_to_folder(frames, strategy_name, video_name=None):
    """
    ä¿å­˜æŠ½å–çš„å¸§åˆ°æ–‡ä»¶å¤¹ï¼ˆç”¨äºè°ƒè¯•ï¼‰

    Args:
        frames: PIL Imageåˆ—è¡¨
        strategy_name: æŠ½å¸§ç­–ç•¥åç§°
        video_name: è§†é¢‘æ–‡ä»¶åï¼ˆå¯é€‰ï¼‰

    Returns:
        str: ä¿å­˜çš„æ–‡ä»¶å¤¹è·¯å¾„
    """
    from datetime import datetime

    # åˆ›å»ºæ—¶é—´æˆ³
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')

    # åˆ›å»ºæ–‡ä»¶å¤¹åç§°ï¼šç­–ç•¥å_æ—¶é—´æˆ³
    folder_name = f"{strategy_name}_{timestamp}"
    if video_name:
        # ç§»é™¤æ–‡ä»¶æ‰©å±•å
        video_base = os.path.splitext(video_name)[0]
        folder_name = f"{video_base}_{strategy_name}_{timestamp}"

    # åˆ›å»ºä¿å­˜è·¯å¾„
    debug_folder = os.path.join(app.config['UPLOAD_FOLDER'], 'debug_frames')
    os.makedirs(debug_folder, exist_ok=True)

    save_path = os.path.join(debug_folder, folder_name)
    os.makedirs(save_path, exist_ok=True)

    # ä¿å­˜æ‰€æœ‰å¸§
    print(f"\nğŸ’¾ ä¿å­˜æŠ½å¸§å›¾ç‰‡åˆ°: {save_path}")
    for i, frame in enumerate(frames):
        frame_path = os.path.join(save_path, f"frame_{i:04d}.jpg")
        frame.save(frame_path, format='JPEG', quality=95)

    print(f"âœ… å·²ä¿å­˜ {len(frames)} å¸§åˆ°æ–‡ä»¶å¤¹: {folder_name}\n")
    return save_path


def calculate_image_tokens(width, height):
    """
    è®¡ç®—å›¾ç‰‡çš„Tokenæ•°é‡ï¼ˆQwen3-VLè§„åˆ™ï¼šæ¯32x32åƒç´ =1 Tokenï¼‰

    Args:
        width: å›¾ç‰‡å®½åº¦
        height: å›¾ç‰‡é«˜åº¦

    Returns:
        int: Tokenæ•°é‡
    """
    import math
    # Qwen3-VL: æ¯32x32åƒç´ å¯¹åº”1ä¸ªToken
    tokens = math.ceil(width / 32) * math.ceil(height / 32)
    # æœ€å°‘4ä¸ªTokenï¼Œæœ€å¤š16384ä¸ªToken
    return max(4, min(tokens, 16384))


def frames_to_base64_images(frames, max_tokens=250000):
    """
    å°†å¸§åˆ—è¡¨è½¬æ¢ä¸ºbase64ç¼–ç çš„å›¾ç‰‡åˆ—è¡¨ï¼ˆç”¨äºAPIè°ƒç”¨ï¼‰
    ä½¿ç”¨Tokené™åˆ¶è€Œéæ–‡ä»¶å¤§å°é™åˆ¶ï¼Œç¡®ä¿ç¬¦åˆQwen-VL APIè¦æ±‚

    Args:
        frames: PIL Imageåˆ—è¡¨
        max_tokens: æœ€å¤§Tokenæ•°ï¼ˆé»˜è®¤250000ï¼Œä¸º258048ç•™ä½™é‡ï¼‰

    Returns:
        list: base64ç¼–ç çš„å›¾ç‰‡URLåˆ—è¡¨
    """
    import io

    base64_images = []
    total_tokens = 0
    total_size_mb = 0

    print(f"\nğŸ”¢ å¼€å§‹è½¬æ¢å¸§ï¼Œä½¿ç”¨Tokené™åˆ¶ç­–ç•¥ï¼ˆæœ€å¤§{max_tokens} tokensï¼‰")

    for i, frame in enumerate(frames):
        # å‹ç¼©å›¾ç‰‡ï¼šé™ä½åˆ†è¾¨ç‡ä»¥å‡å°‘Tokenæ¶ˆè€—
        # æœ€å¤§å®½åº¦1280pxï¼Œè¿™æ ·å¯ä»¥åœ¨ä¿æŒè´¨é‡çš„åŒæ—¶å‡å°‘Token
        max_width = 1280
        width, height = frame.size
        if width > max_width:
            ratio = max_width / width
            new_size = (max_width, int(height * ratio))
            frame = frame.resize(new_size, Image.Resampling.LANCZOS)
            width, height = new_size

        # è®¡ç®—è¿™å¼ å›¾ç‰‡éœ€è¦çš„Tokenæ•°
        frame_tokens = calculate_image_tokens(width, height)

        # æ£€æŸ¥Tokené™åˆ¶
        if total_tokens + frame_tokens > max_tokens:
            print(f"âš ï¸ å·²è¾¾åˆ°Tokené™åˆ¶ï¼ˆ{total_tokens}/{max_tokens}ï¼‰ï¼Œåœæ­¢æ·»åŠ æ›´å¤šå¸§")
            print(f"   æˆåŠŸå¤„ç† {i}/{len(frames)} å¸§")
            break

        # è½¬æ¢ä¸ºJPEGå¹¶å‹ç¼©
        buffer = io.BytesIO()
        frame.save(buffer, format='JPEG', quality=85, optimize=True)  # æé«˜è´¨é‡ï¼Œä¿ç•™æ›´å¤šç»†èŠ‚
        img_bytes = buffer.getvalue()

        # ç¼–ç ä¸ºbase64
        img_base64 = base64.b64encode(img_bytes).decode('utf-8')
        img_url = f"data:image/jpeg;base64,{img_base64}"

        # è®°å½•ç»Ÿè®¡ä¿¡æ¯
        img_size_mb = len(img_base64) / (1024 * 1024)
        total_size_mb += img_size_mb
        total_tokens += frame_tokens

        base64_images.append(img_url)

        # æ¯10å¸§æ‰“å°ä¸€æ¬¡è¿›åº¦
        if (i + 1) % 10 == 0:
            print(f"   è¿›åº¦: {i+1}/{len(frames)} å¸§ï¼ŒToken: {total_tokens}/{max_tokens}ï¼Œå¤§å°: {total_size_mb:.2f}MB")

    print(f"âœ… è½¬æ¢å®Œæˆï¼š{len(base64_images)}/{len(frames)} å¸§")
    print(f"   æ€»Tokenæ•°: {total_tokens} ({total_tokens/max_tokens*100:.1f}%)")
    print(f"   æ€»å¤§å°: {total_size_mb:.2f}MB")
    print(f"   å¹³å‡æ¯å¸§: {total_tokens/len(base64_images):.0f} tokens, {total_size_mb/len(base64_images):.2f}MB\n")

    return base64_images


def analyze_video_with_api(video_path=None, video_url=None, prompt='è¯·è¯¦ç»†æè¿°è¿™ä¸ªè§†é¢‘ä¸­å‘ç”Ÿäº†ä»€ä¹ˆã€‚', model='qwen-vl-plus', session_id=None):
    """
    ä½¿ç”¨é˜¿é‡Œäº‘ DashScope API åˆ†æè§†é¢‘å†…å®¹

    Args:
        video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„ï¼ˆæœ¬åœ°ä¸Šä¼ æ–¹å¼ï¼‰
        video_url: è§†é¢‘URLï¼ˆURLæ–¹å¼ï¼Œæ”¯æŒæœ€å¤§2GBï¼‰
        prompt: ç”¨æˆ·æé—®
        model: ä½¿ç”¨çš„æ¨¡å‹åç§°
        session_id: ä¼šè¯IDï¼Œç”¨äºè¿›åº¦æ¨é€

    Returns:
        str: æ¨¡å‹åˆ†æç»“æœ
    """
    try:
        # å‘é€è¿›åº¦æ›´æ–°
        def send_progress(percent, message):
            if session_id and session_id in progress_queues:
                progress_queues[session_id].put({
                    'type': 'upload',
                    'progress': percent,
                    'message': message
                })
        # æ£€æŸ¥ API Key
        if not DASHSCOPE_API_KEY:
            raise ValueError(
                "æœªè®¾ç½® DASHSCOPE_API_KEYï¼\n"
                "è¯·åœ¨ç¯å¢ƒå˜é‡ä¸­è®¾ç½® API Keyï¼Œæˆ–åœ¨ app.py ä¸­ç›´æ¥é…ç½®ã€‚\n"
                "è·å– API Key: https://dashscope.console.aliyun.com/apiKey"
            )

        send_progress(0, 'å¼€å§‹åˆ†æè§†é¢‘...')

        remote_model = get_remote_model_id(model)
        print(f"ä½¿ç”¨æ¨¡å‹: {model} -> {remote_model}")
        print(f"ç”¨æˆ·æé—®: {prompt}")

        # åˆ¤æ–­ä½¿ç”¨URLæ–¹å¼è¿˜æ˜¯æœ¬åœ°æ–‡ä»¶æ–¹å¼
        if video_url:
            # URLæ–¹å¼ - æ”¯æŒæœ€å¤§2GBè§†é¢‘
            print(f"ä½¿ç”¨URLæ–¹å¼åˆ†æè§†é¢‘: {video_url}")
            send_progress(10, 'ä½¿ç”¨URLæ–¹å¼ï¼Œå‡†å¤‡è°ƒç”¨API...')

            # æ„å»ºè¯·æ±‚æ¶ˆæ¯ - URLæ–¹å¼
            messages = [
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "video_url",
                            "video_url": {
                                "url": video_url
                            },
                        },
                        {
                            "type": "text",
                            "text": prompt
                        },
                    ]
                }
            ]

        else:
            # æœ¬åœ°æ–‡ä»¶æ–¹å¼ - base64ç¼–ç 
            print(f"å¼€å§‹åˆ†æè§†é¢‘: {video_path}")

            # æ£€æŸ¥è§†é¢‘æ–‡ä»¶å¤§å°
            video_size = os.path.getsize(video_path)
            video_size_mb = video_size / (1024 * 1024)
            print(f"è§†é¢‘æ–‡ä»¶å¤§å°: {video_size_mb:.2f} MB")

            send_progress(5, f'å‡†å¤‡ä¸Šä¼ è§†é¢‘ ({video_size_mb:.2f}MB)...')

            # APIé™åˆ¶ï¼šbase64ç¼–ç åä¸èƒ½è¶…è¿‡10MB
            # ç”±äºbase64ç¼–ç ä¼šå¢åŠ çº¦33%çš„å¤§å°ï¼ŒåŸå§‹æ–‡ä»¶åº”è¯¥å°äº7.5MB
            max_original_size = 7.5 * 1024 * 1024  # 7.5MB
            # ä½¿ç”¨å¯é…ç½®çš„é˜ˆå€¼è¦†ç›–é»˜è®¤ 7.5MBï¼ˆä¸º base64 å¢é•¿é¢„ç•™ï¼‰
            try:
                max_original_size = TARGET_ORIGINAL_MB * 1024 * 1024
            except Exception:
                pass
            if video_size > max_original_size:
                raise ValueError(
                    f"è§†é¢‘æ–‡ä»¶å¤ªå¤§ï¼ˆ{video_size_mb:.2f} MBï¼‰ï¼\n"
                    f"DashScope API é™åˆ¶ base64 ç¼–ç åçš„è§†é¢‘ä¸èƒ½è¶…è¿‡ 10MBã€‚\n"
                    f"å»ºè®®ï¼š\n"
                    f"1. ä½¿ç”¨è§†é¢‘å‹ç¼©å·¥å…·å‹ç¼©è§†é¢‘\n"
                    f"2. æˆªå–è¾ƒçŸ­çš„è§†é¢‘ç‰‡æ®µï¼ˆå»ºè®® < 7MBï¼‰\n"
                    f"3. é™ä½è§†é¢‘åˆ†è¾¨ç‡æˆ–å¸§ç‡"
                )

            # ç¼–ç è§†é¢‘ä¸º base64
            print("æ­£åœ¨ç¼–ç è§†é¢‘...")
            send_progress(10, 'æ­£åœ¨ç¼–ç è§†é¢‘...')
            base64_video = encode_video_to_base64(video_path)
            base64_size_mb = len(base64_video) / (1024 * 1024)
            print(f"è§†é¢‘ç¼–ç å®Œæˆï¼Œbase64 å¤§å°: {base64_size_mb:.2f} MB")
            send_progress(30, f'è§†é¢‘ç¼–ç å®Œæˆ ({base64_size_mb:.2f}MB)')

            # å†æ¬¡æ£€æŸ¥ç¼–ç åçš„å¤§å°
            if len(base64_video) > 10 * 1024 * 1024:
                raise ValueError(
                    f"ç¼–ç åè§†é¢‘å¤ªå¤§ï¼ˆ{base64_size_mb:.2f} MBï¼‰ï¼Œè¶…è¿‡ API é™åˆ¶ï¼ˆ10MBï¼‰ï¼\n"
                    f"è¯·å‹ç¼©è§†é¢‘æˆ–ä½¿ç”¨æ›´çŸ­çš„ç‰‡æ®µã€‚"
                )

            # æ„å»ºè¯·æ±‚æ¶ˆæ¯ - base64æ–¹å¼
            messages = [
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "video_url",
                            "video_url": {
                                "url": f"data:video/mp4;base64,{base64_video}"
                            },
                        },
                        {
                            "type": "text",
                            "text": prompt
                        },
                    ]
                }
            ]

        # åˆ›å»º OpenAI å®¢æˆ·ç«¯ï¼ˆå…¼å®¹æ¨¡å¼ï¼‰
        client = OpenAI(
            api_key=DASHSCOPE_API_KEY,
            base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
        )

        # è°ƒç”¨ API
        print("æ­£åœ¨è°ƒç”¨ DashScope API...")
        send_progress(40, 'æ­£åœ¨ä¸Šä¼ åˆ°AIæ¨¡å‹...')

        completion = client.chat.completions.create(
            model=remote_model,
            messages=messages,
        )

        send_progress(90, 'AIæ­£åœ¨åˆ†æè§†é¢‘...')

        # è·å–ç»“æœ
        result = completion.choices[0].message.content
        print("åˆ†æå®Œæˆï¼")
        send_progress(100, 'åˆ†æå®Œæˆï¼')

        return result

    except Exception as e:
        import traceback
        error_msg = f"API è°ƒç”¨å¤±è´¥: {str(e)}"
        print(error_msg)
        print("è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
        print(traceback.format_exc())
        raise Exception(error_msg)


def analyze_images_with_api(base64_images, prompt='è¯·åˆ†æè¿™äº›å›¾ç‰‡ã€‚', model='qwen-vl-plus', session_id=None):
    """
    ä½¿ç”¨é˜¿é‡Œäº‘ DashScope API åˆ†æå¤šå¼ å›¾ç‰‡

    Args:
        base64_images: base64ç¼–ç çš„å›¾ç‰‡URLåˆ—è¡¨
        prompt: ç”¨æˆ·æé—®
        model: ä½¿ç”¨çš„æ¨¡å‹åç§°
        session_id: ä¼šè¯ID

    Returns:
        str: æ¨¡å‹åˆ†æç»“æœ
    """
    try:
        def send_progress(percent, message):
            if session_id and session_id in progress_queues:
                progress_queues[session_id].put({
                    'type': 'upload',
                    'progress': percent,
                    'message': message
                })

        send_progress(0, 'å‡†å¤‡å‘é€å›¾ç‰‡åˆ°AIæ¨¡å‹...')

        # æ£€æŸ¥ API Key
        if not DASHSCOPE_API_KEY:
            raise ValueError("æœªè®¾ç½® DASHSCOPE_API_KEYï¼")

        remote_model = get_remote_model_id(model)
        print(f"ä½¿ç”¨æ¨¡å‹: {model} -> {remote_model}")
        print(f"åˆ†æå›¾ç‰‡æ•°é‡: {len(base64_images)}")

        # æ„å»ºæ¶ˆæ¯å†…å®¹ï¼ˆå¤šå›¾ï¼‰
        content = []
        for img_url in base64_images:
            content.append({
                "type": "image_url",
                "image_url": {"url": img_url}
            })

        # æ·»åŠ æ–‡æœ¬æé—®
        content.append({
            "type": "text",
            "text": prompt
        })

        messages = [
            {
                "role": "user",
                "content": content
            }
        ]

        # åˆ›å»º OpenAI å®¢æˆ·ç«¯
        client = OpenAI(
            api_key=DASHSCOPE_API_KEY,
            base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
        )

        send_progress(40, f'ä¸Šä¼ {len(base64_images)}å¼ å›¾ç‰‡åˆ°AIæ¨¡å‹...')

        # è°ƒç”¨ API
        completion = client.chat.completions.create(
            model=remote_model,
            messages=messages,
        )

        send_progress(90, 'AIæ­£åœ¨åˆ†æå›¾ç‰‡...')

        # è·å–ç»“æœ
        result = completion.choices[0].message.content
        print("å¤šå›¾åˆ†æå®Œæˆï¼")
        send_progress(100, 'åˆ†æå®Œæˆï¼')

        return result

    except Exception as e:
        import traceback
        error_msg = f"å¤šå›¾APIè°ƒç”¨å¤±è´¥: {str(e)}"
        print(error_msg)
        print(traceback.format_exc())
        raise Exception(error_msg)


@app.route('/')
def index():
    """ä¸»é¡µ"""
    return render_template('index.html', models=AVAILABLE_MODELS)

@app.route('/progress/<session_id>')
def progress(session_id):
    """SSE è¿›åº¦æ¨é€ç«¯ç‚¹"""
    def generate():
        # åˆ›å»ºè¯¥ä¼šè¯çš„è¿›åº¦é˜Ÿåˆ—
        if session_id not in progress_queues:
            progress_queues[session_id] = Queue()

        q = progress_queues[session_id]

        # å‘é€åˆå§‹è¿æ¥æ¶ˆæ¯
        yield f"data: {json.dumps({'type': 'connected', 'message': 'å·²è¿æ¥'})}\n\n"

        try:
            while True:
                try:
                    # ä»é˜Ÿåˆ—è·å–è¿›åº¦æ›´æ–°ï¼Œè®¾ç½®è¾ƒçŸ­çš„è¶…æ—¶ä»¥ä¾¿å‘é€å¿ƒè·³
                    data = q.get(timeout=5)  # 5ç§’è¶…æ—¶

                    # å‘é€ SSE æ•°æ®
                    yield f"data: {json.dumps(data)}\n\n"

                    # å¦‚æœä»»åŠ¡å®Œæˆæˆ–å¤±è´¥ï¼Œç»“æŸæµ
                    if data.get('type') == 'complete' or data.get('type') == 'error':
                        break

                except:
                    # é˜Ÿåˆ—è¶…æ—¶ï¼Œå‘é€å¿ƒè·³ä¿æŒè¿æ¥
                    yield f": heartbeat\n\n"
                    continue

        except GeneratorExit:
            # å®¢æˆ·ç«¯æ–­å¼€è¿æ¥
            pass
        finally:
            # æ¸…ç†é˜Ÿåˆ—
            if session_id in progress_queues:
                del progress_queues[session_id]

    return Response(stream_with_context(generate()),
                   mimetype='text/event-stream',
                   headers={
                       'Cache-Control': 'no-cache',
                       'X-Accel-Buffering': 'no',
                       'Connection': 'keep-alive'
                   })

@app.route('/analyze', methods=['POST'])
def analyze():
    """å¤„ç†è§†é¢‘åˆ†æè¯·æ±‚ - ç«‹å³è¿”å›session_idï¼Œåå°å¤„ç†"""
    try:
        # è·å–è¾“å…¥æ–¹å¼
        input_method = request.form.get('input_method', 'upload')  # 'upload' æˆ– 'url'

        # è·å–ç”¨æˆ·æé—®å’Œæ¨¡å‹é€‰æ‹©
        prompt = request.form.get('prompt', 'è¯·è¯¦ç»†æè¿°è¿™ä¸ªè§†é¢‘ä¸­å‘ç”Ÿäº†ä»€ä¹ˆã€‚')
        model = request.form.get('model', 'qwen-vl-plus')
        analysis_mode = request.form.get('analysis_mode', 'traffic_vlm')
        event_query = request.form.get('event_query', '').strip()
        camera_id = request.form.get('camera_id', 'camera-1').strip() or 'camera-1'

        # æ ¹æ®è¾“å…¥æ–¹å¼å¤„ç†
        video_url = None
        filepath = None
        filename = None
        auto_compress = False

        if input_method == 'url':
            # URLæ–¹å¼
            video_url = request.form.get('video_url', '').strip()
            if not video_url:
                return jsonify({'error': 'è¯·æä¾›è§†é¢‘URL'}), 400

            # éªŒè¯URLæ ¼å¼
            if not video_url.startswith(('http://', 'https://')):
                return jsonify({'error': 'è¯·æä¾›æœ‰æ•ˆçš„HTTP/HTTPSè§†é¢‘URL'}), 400

            print(f"æ”¶åˆ°URLæ–¹å¼è¯·æ±‚: {video_url}")

        else:
            # ä¸Šä¼ æ–‡ä»¶æ–¹å¼
            # æ£€æŸ¥æ˜¯å¦æœ‰æ–‡ä»¶
            if 'video' not in request.files:
                return jsonify({'error': 'æœªæ‰¾åˆ°è§†é¢‘æ–‡ä»¶'}), 400

            file = request.files['video']

            # æ£€æŸ¥æ–‡ä»¶å
            if file.filename == '':
                return jsonify({'error': 'æœªé€‰æ‹©æ–‡ä»¶'}), 400

            # æ£€æŸ¥æ–‡ä»¶ç±»å‹
            if not allowed_file(file.filename):
                return jsonify({'error': f'ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼Œè¯·ä¸Šä¼ : {", ".join(ALLOWED_EXTENSIONS)}'}), 400

            auto_compress = request.form.get('auto_compress', 'true').lower() == 'true'

            # ä¿å­˜æ–‡ä»¶
            filename = file.filename
            filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
            file.save(filepath)

        # éªŒè¯æ¨¡å‹é€‰æ‹©
        if model not in AVAILABLE_MODELS:
            # å…è®¸é¢å¤–çš„æ¨¡å‹é”®ï¼ˆæœªåœ¨ AVAILABLE_MODELS ä¸­å±•ç¤ºï¼‰
            extra_allowed = {'qwen3-vl-235b-a22b-thinking', 'qwen-vlmax-20250813', 'qwen3-vl-32b-instruct', 'qwen3-vl-32b-thinking'}
            if model not in extra_allowed:
                model = 'qwen-vl-plus'

        # ========== æå‰è·å–æ‰€æœ‰è¯·æ±‚å‚æ•°ï¼ˆé¿å…åœ¨çº¿ç¨‹ä¸­è®¿é—®requestï¼‰ ==========
        # è·å–æŠ½å¸§ç­–ç•¥ç›¸å…³å‚æ•°
        sampling_strategy = request.form.get('sampling_strategy', 'full_video')
        uniform_fps = float(request.form.get('uniform_fps', 1.0)) if sampling_strategy == 'uniform_fps' else 1.0
        keyframe_count = int(request.form.get('keyframe_count', 16)) if sampling_strategy == 'keyframe_only' else 16

        # äº¤é€šäº‹æ•…åˆ†æé…ç½®
        accident_config = None
        if sampling_strategy == 'accident_analysis':
            accident_config = {
                'detect_accident_time': request.form.get('detect_accident_time', 'true').lower() == 'true',
                'track_trajectory': request.form.get('track_trajectory', 'true').lower() == 'true',
                'analyze_environment': request.form.get('analyze_environment', 'true').lower() == 'true'
            }

        # ç”Ÿæˆå”¯ä¸€çš„ä¼šè¯ID
        session_id = f"{int(time.time() * 1000)}_{os.getpid()}"

        # åˆ›å»ºè¿›åº¦é˜Ÿåˆ—
        progress_queues[session_id] = Queue()

        # åœ¨åå°çº¿ç¨‹ä¸­å¤„ç†ä»»åŠ¡
        def process_video():
            compressed_path = None
            final_video_path = filepath
            try:
                # æ£€æŸ¥æ˜¯å¦å·²è¢«åœæ­¢
                if is_stopped(session_id):
                    print(f"[Session {session_id}] ä»»åŠ¡å·²è¢«åœæ­¢ï¼ˆå¯åŠ¨å‰ï¼‰")
                    return

                user_intent = event_query or prompt
                video_source_path = video_url if video_url else filepath

                def pipeline_progress(percent, message):
                    # æ£€æŸ¥æ˜¯å¦å·²è¢«åœæ­¢
                    if is_stopped(session_id):
                        raise InterruptedError("åˆ†æå·²è¢«ç”¨æˆ·åœæ­¢")
                    progress_queues[session_id].put({
                        'type': 'analysis',
                        'progress': int(percent),
                        'message': message
                    })

                def format_pipeline_summary(res):
                    lines = []
                    lines.append(f"Keyframes: {len(res.get('keyframes', []))}")
                    lines.append(f"Candidate clips: {len(res.get('clips', []))}")
                    for item in res.get('results', []):
                        clip = item.get('clip', {})
                        vlm_out = item.get('vlm_output', {}) or {}
                        vio = vlm_out.get('violations') or []
                        vio_text = '; '.join([f"{v.get('type')}({v.get('confidence', 0):.2f})" for v in vio]) if vio else 'No high-confidence violations'
                        lines.append(f"- {clip.get('clip_id', '')} [{clip.get('start_time', 0):.1f}-{clip.get('end_time', 0):.1f}s] score {clip.get('clip_score', 0):.3f} | {vio_text}")
                    return "\n".join(lines)

                def extract_detailed_analysis(res):
                    """æå–è¯¦ç»†çš„åˆ†æç»“æœï¼ˆåŒ…å«å¤§æ¨¡å‹çš„æ–‡æœ¬æè¿°ï¼‰"""
                    results = res.get('results', [])
                    if not results:
                        return "æœªæ£€æµ‹åˆ°ç›¸å…³å†…å®¹"

                    analysis_parts = []
                    for i, item in enumerate(results, 1):
                        vlm_out = item.get('vlm_output', {}) or {}
                        text_summary = vlm_out.get('text_summary', 'æ— æè¿°')
                        has_violation = vlm_out.get('has_violation', False)
                        violations = vlm_out.get('violations', [])

                        # æ·»åŠ ç‰‡æ®µä¿¡æ¯
                        clip = item.get('clip', {})
                        start_time = clip.get('start_time', 0)
                        end_time = clip.get('end_time', 0)

                        analysis_parts.append(f"ã€ç‰‡æ®µ {i}ã€‘æ—¶é—´: {start_time:.1f}s - {end_time:.1f}s")
                        analysis_parts.append(f"åˆ†æç»“æœ: {text_summary}")

                        # æ·»åŠ è¿æ³•ä¿¡æ¯
                        if violations:
                            analysis_parts.append("æ£€æµ‹åˆ°çš„è¿æ³•è¡Œä¸º:")
                            for v in violations:
                                vtype = v.get('type', '')
                                confidence = v.get('confidence', 0)
                                evidence = v.get('evidence', '')
                                analysis_parts.append(f"  - {vtype} (ç½®ä¿¡åº¦: {confidence:.2f})")
                                if evidence:
                                    analysis_parts.append(f"    ä¾æ®: {evidence}")
                        elif has_violation:
                            analysis_parts.append("æ£€æµ‹åˆ°è¿æ³•è¡Œä¸ºï¼Œä½†æœªèƒ½è¯†åˆ«å…·ä½“ç±»å‹")
                        else:
                            analysis_parts.append("æœªæ£€æµ‹åˆ°è¿æ³•è¡Œä¸º")

                        analysis_parts.append("")  # ç©ºè¡Œåˆ†éš”

                    return "\n".join(analysis_parts)

                if analysis_mode == 'traffic_vlm':
                    # æ£€æŸ¥æ˜¯å¦å·²è¢«åœæ­¢
                    if is_stopped(session_id):
                        print(f"[Session {session_id}] ä»»åŠ¡å·²è¢«åœæ­¢ï¼ˆpipelineå¯åŠ¨å‰ï¼‰")
                        return

                    print(f"\n{'='*60}")
                    print(f"TrafficVLM pipeline start (Session: {session_id})")
                    print(f"Source: {video_source_path}")
                    print(f"Camera ID: {camera_id}")
                    print(f"Query: {user_intent}")
                    print(f"{'='*60}\n")

                    try:
                        pipeline = TrafficVLMPipeline(config=TrafficVLMConfig(), progress_cb=pipeline_progress)
                        pipeline_result = pipeline.run(video_source_path, user_intent, camera_id=camera_id, mode="violation")

                        # è¿”å›è¯¦ç»†çš„åˆ†æç»“æœï¼Œè€Œä¸æ˜¯æ‘˜è¦
                        detailed_analysis = extract_detailed_analysis(pipeline_result)

                        response_data = {
                            'type': 'complete',
                            'success': True,
                            'result': detailed_analysis,
                            'analysis_mode': 'traffic_vlm',
                            'video_source': video_source_path,
                            'model': model,
                            'pipeline': pipeline_result
                        }
                        progress_queues[session_id].put(response_data)
                    except InterruptedError as e:
                        print(f"[Session {session_id}] TrafficVLM pipeline è¢«ç”¨æˆ·åœæ­¢")
                        # ä¸å‘é€é”™è¯¯æ¶ˆæ¯ï¼Œåœæ­¢æ¶ˆæ¯å·²é€šè¿‡ /stop ç«¯ç‚¹å‘é€
                    except Exception as e:
                        progress_queues[session_id].put({
                            'type': 'error',
                            'message': f'TrafficVLM pipeline failed: {str(e)}'
                        })
                    return

                if analysis_mode == 'accident_search':
                    # æ£€æŸ¥æ˜¯å¦å·²è¢«åœæ­¢
                    if is_stopped(session_id):
                        print(f"[Session {session_id}] ä»»åŠ¡å·²è¢«åœæ­¢ï¼ˆaccident pipelineå¯åŠ¨å‰ï¼‰")
                        return

                    print(f"\n{'='*60}")
                    print(f"Accident Search pipeline start (Session: {session_id})")
                    print(f"Source: {video_source_path}")
                    print(f"Camera ID: {camera_id}")
                    print(f"Query: {user_intent}")
                    print(f"{'='*60}\n")

                    try:
                        pipeline = TrafficVLMPipeline(config=TrafficVLMConfig(), progress_cb=pipeline_progress)
                        pipeline_result = pipeline.run(video_source_path, user_intent, camera_id=camera_id, mode="accident")

                        # è¿”å›è¯¦ç»†çš„åˆ†æç»“æœ
                        detailed_analysis = extract_detailed_analysis(pipeline_result)

                        response_data = {
                            'type': 'complete',
                            'success': True,
                            'result': detailed_analysis,
                            'analysis_mode': 'accident_search',
                            'video_source': video_source_path,
                            'model': model,
                            'pipeline': pipeline_result
                        }
                        progress_queues[session_id].put(response_data)
                    except InterruptedError as e:
                        print(f"[Session {session_id}] Accident Search pipeline è¢«ç”¨æˆ·åœæ­¢")
                        # ä¸å‘é€é”™è¯¯æ¶ˆæ¯ï¼Œåœæ­¢æ¶ˆæ¯å·²é€šè¿‡ /stop ç«¯ç‚¹å‘é€
                    except Exception as e:
                        progress_queues[session_id].put({
                            'type': 'error',
                            'message': f'Accident Search pipeline failed: {str(e)}'
                        })
                    return

                if video_url:
                    print(f"\n{'='*60}")
                    print(f"Received video analysis request (Session: {session_id})")
                    print(f"Video URL: {video_url}")
                    print(f"Input method: URL (max 10GB)")
                    print(f"{'='*60}\n")

                    result = analyze_video_with_api(video_url=video_url, prompt=prompt, model=model, session_id=session_id)

                    response_data = {
                        'type': 'complete',
                        'success': True,
                        'result': result,
                        'video_source': video_url,
                        'model': model,
                        'input_method': 'url'
                    }

                    progress_queues[session_id].put(response_data)

                else:
                    file_size_mb = os.path.getsize(filepath) / (1024*1024)

                    print(f"\n{'='*60}")
                    print(f"Received video analysis request (Session: {session_id})")
                    print(f"Video file: {filename}")
                    print(f"Path: {filepath}")
                    print(f"Size: {file_size_mb:.2f} MB")
                    print(f"Auto compress: {auto_compress}")
                    print(f"Sampling: {sampling_strategy}")
                    print(f"{'='*60}\n")

                    final_video_path = filepath
                    compressed_filename = None

                    if auto_compress and file_size_mb > 7.0 and sampling_strategy == 'full_video':
                        print("Large file, start auto compression...")

                        if not check_ffmpeg():
                            progress_queues[session_id].put({
                                'type': 'error',
                                'message': 'FFmpeg not installed, cannot compress.'
                            })
                            return

                        name, ext = os.path.splitext(filename)
                        compressed_filename = f"{name}_compressed{ext}"
                        compressed_path = os.path.join(app.config['UPLOAD_FOLDER'], compressed_filename)

                        target_size_mb = 6.5
                        success = compress_video(filepath, compressed_path, target_size_mb=target_size_mb, session_id=session_id)

                        if success:
                            print(f"Use compressed video: {compressed_filename}")
                            final_video_path = compressed_path
                            try:
                                current_size_mb = os.path.getsize(compressed_path) / (1024 * 1024)
                            except Exception:
                                current_size_mb = None

                            retry = 0
                            while current_size_mb is not None and current_size_mb > TARGET_ORIGINAL_MB and retry < MAX_COMPRESS_RETRY:
                                retry += 1
                                ratio = TARGET_ORIGINAL_MB / max(current_size_mb, 0.01)
                                new_target = max(1.0, target_size_mb * ratio * 0.9)

                                print(f"Compressed still {current_size_mb:.2f} MB, retry {retry}, target {new_target:.2f} MB")
                                progress_queues[session_id].put({
                                    'type': 'compress',
                                    'progress': 15,
                                    'message': f'Re-compress #{retry}, target {new_target:.2f}MB'
                                })

                                target_size_mb = new_target
                                success = compress_video(filepath, compressed_path, target_size_mb=target_size_mb, session_id=session_id)
                                if not success:
                                    print("Adaptive compression failed, keep last result")
                                    break

                                try:
                                    current_size_mb = os.path.getsize(compressed_path) / (1024 * 1024)
                                except Exception:
                                    current_size_mb = None

                            if current_size_mb is not None and current_size_mb > TARGET_ORIGINAL_MB:
                                progress_queues[session_id].put({
                                    'type': 'compress',
                                    'progress': 95,
                                    'message': f'Still above threshold ({current_size_mb:.2f}MB>{TARGET_ORIGINAL_MB:.2f}MB), may fail upload'
                                })
                        else:
                            print("Compression failed, use original video")

                    if sampling_strategy != 'full_video':
                        print(f"\nSampling strategy: {sampling_strategy}")

                        if sampling_strategy == 'uniform_fps':
                            frames, metadata = extract_frames_uniform(final_video_path, fps=uniform_fps, session_id=session_id)
                        elif sampling_strategy == 'keyframe_only':
                            frames, metadata = extract_frames_keyframes(final_video_path, num_keyframes=keyframe_count, session_id=session_id)
                        elif sampling_strategy == 'accident_analysis':
                            frames, metadata = extract_frames_accident_analysis(final_video_path, accident_config, session_id=session_id)
                        else:
                            frames, metadata = extract_frames_uniform(final_video_path, fps=1.0, session_id=session_id)

                        try:
                            save_frames_to_folder(frames, sampling_strategy, filename)
                        except Exception as e:
                            print(f"Save frames failed: {str(e)}")

                        base64_images = frames_to_base64_images(frames, max_tokens=250000)
                        result = analyze_images_with_api(base64_images, prompt=prompt, model=model, session_id=session_id)

                        response_data = {
                            'type': 'complete',
                            'success': True,
                            'result': result,
                            'video_name': filename,
                            'model': model,
                            'input_method': 'upload',
                            'sampling_strategy': sampling_strategy,
                            'frames_extracted': len(frames),
                            'metadata': metadata
                        }

                    else:
                        result = analyze_video_with_api(video_path=final_video_path, prompt=prompt, model=model, session_id=session_id)

                        response_data = {
                            'type': 'complete',
                            'success': True,
                            'result': result,
                            'video_name': filename,
                            'model': model,
                            'input_method': 'upload'
                        }

                    if compressed_filename and os.path.exists(compressed_path):
                        response_data['compressed_video'] = compressed_filename
                        response_data['compressed_size'] = f"{os.path.getsize(compressed_path) / (1024*1024):.2f} MB"
                        response_data['original_size'] = f"{file_size_mb:.2f} MB"

                    progress_queues[session_id].put(response_data)

            except InterruptedError as e:
                # ç”¨æˆ·ä¸»åŠ¨åœæ­¢åˆ†æ
                print(f"\n[Session {session_id}] åˆ†æè¢«ç”¨æˆ·åœæ­¢: {str(e)}\n")
                if compressed_path and os.path.exists(compressed_path):
                    try:
                        os.remove(compressed_path)
                    except:
                        pass
                # ä¸å‘é€é”™è¯¯æ¶ˆæ¯ï¼Œåœæ­¢æ¶ˆæ¯å·²é€šè¿‡ /stop ç«¯ç‚¹å‘é€
            except Exception as e:
                print(f"\nError: {str(e)}\n")
                if compressed_path and os.path.exists(compressed_path):
                    try:
                        os.remove(compressed_path)
                    except:
                        pass

                progress_queues[session_id].put({
                    'type': 'error',
                    'message': str(e)
                })
            finally:
                # æ¸…ç†ä¼šè¯èµ„æº
                if session_id in stop_flags:
                    del stop_flags[session_id]

        # å¯åŠ¨åå°çº¿ç¨‹
        thread = threading.Thread(target=process_video)
        thread.daemon = True
        thread.start()

        # ç«‹å³è¿”å›session_id
        return jsonify({
            'success': True,
            'session_id': session_id
        })

    except Exception as e:
        print(f"\né”™è¯¯: {str(e)}\n")
        return jsonify({'error': str(e)}), 500

@app.route('/download/<filename>')
def download(filename):
    """ä¸‹è½½å‹ç¼©åçš„è§†é¢‘æ–‡ä»¶"""
    try:
        filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
        if os.path.exists(filepath):
            return send_file(filepath, as_attachment=True, download_name=filename)
        else:
            return jsonify({'error': 'æ–‡ä»¶ä¸å­˜åœ¨'}), 404
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/stop/<session_id>', methods=['POST'])
def stop_analysis(session_id):
    """åœæ­¢æŒ‡å®šä¼šè¯çš„åˆ†æä»»åŠ¡"""
    try:
        print(f"\n{'='*60}")
        print(f"æ”¶åˆ°åœæ­¢è¯·æ±‚ (Session: {session_id})")
        print(f"{'='*60}\n")

        # è®¾ç½®åœæ­¢æ ‡å¿—
        stop_flags[session_id] = True

        # å‘é˜Ÿåˆ—å‘é€åœæ­¢æ¶ˆæ¯
        if session_id in progress_queues:
            progress_queues[session_id].put({
                'type': 'stopped',
                'message': 'åˆ†æå·²åœæ­¢'
            })

        return jsonify({
            'success': True,
            'message': 'åœæ­¢è¯·æ±‚å·²å‘é€',
            'session_id': session_id
        })

    except Exception as e:
        print(f"åœæ­¢åˆ†æé”™è¯¯: {str(e)}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/health', methods=['GET'])
def health():
    """å¥åº·æ£€æŸ¥æ¥å£"""
    has_api_key = bool(DASHSCOPE_API_KEY)
    has_ffmpeg = check_ffmpeg()
    return jsonify({
        'status': 'ok',
        'api_configured': has_api_key,
        'ffmpeg_installed': has_ffmpeg,
        'available_models': list(AVAILABLE_MODELS.keys())
    })

@app.route('/config', methods=['GET'])
def config_info():
    """è·å–é…ç½®ä¿¡æ¯"""
    return jsonify({
        'api_key_configured': bool(DASHSCOPE_API_KEY),
        'available_models': AVAILABLE_MODELS,
        'max_video_size_mb': MAX_VIDEO_SIZE / (1024 * 1024),
        'allowed_extensions': list(ALLOWED_EXTENSIONS)
    })


# ============================================================
# å†å²è§†é¢‘è”ç½‘æŸ¥è¯¢åˆ†æ API
# ============================================================

# å¯¼å…¥å†å²è§†é¢‘å¤„ç†æ¨¡å—
from traffic_vlm.tsingcloud_api import TsingcloudAPI, CameraInfo
from traffic_vlm.history_video_processor import HistoryVideoProcessor, EventType
from traffic_vlm.config import TsingcloudConfig, HistoryProcessConfig

# å…¨å±€å˜é‡
_tsingcloud_api = None
_history_processor = None
_history_sse_queues = {}  # task_id -> Queue


def get_tsingcloud_api():
    """è·å–äº‘æ§æ™ºè¡ŒAPIå®¢æˆ·ç«¯ï¼ˆå•ä¾‹ï¼‰"""
    global _tsingcloud_api
    if _tsingcloud_api is None:
        # ä»ç¯å¢ƒå˜é‡æˆ–é…ç½®è·å–å‡­æ®
        app_key = os.environ.get('TSINGCLOUD_APP_KEY', 'wangbowen')
        password = os.environ.get('TSINGCLOUD_PASSWORD', 'YwKSBcgWUI6')
        config = TsingcloudConfig(app_key=app_key, password=password)
        _tsingcloud_api = TsingcloudAPI(
            app_key=config.app_key,
            password=config.password,
            base_url=config.base_url,
            poll_interval=config.poll_interval,
            poll_timeout=config.poll_timeout
        )
    return _tsingcloud_api


def get_history_processor():
    """è·å–å†å²è§†é¢‘å¤„ç†å™¨ï¼ˆå•ä¾‹ï¼‰"""
    global _history_processor
    if _history_processor is None:
        api = get_tsingcloud_api()
        config = HistoryProcessConfig()

        def event_callback(event_type: EventType, data: dict):
            """SSEäº‹ä»¶å›è°ƒ"""
            task_id = data.get('task_id')
            if task_id and task_id in _history_sse_queues:
                _history_sse_queues[task_id].put({
                    'event': event_type.value,
                    'data': data
                })

        # åˆ›å»ºpipelineå‡½æ•°ï¼ˆè°ƒç”¨ç°æœ‰çš„TrafficVLMPipelineï¼‰
        def pipeline_func(video_path, user_query, mode, model, progress_callback=None):
            """è°ƒç”¨è§†é¢‘åˆ†æpipeline

            Args:
                video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
                user_query: ç”¨æˆ·æŸ¥è¯¢
                mode: åˆ†ææ¨¡å¼ (accident/violation)
                model: VLMæ¨¡å‹
                progress_callback: è¿›åº¦å›è°ƒå‡½æ•° (percent: int, message: str) -> None
            """
            import traceback

            # åˆ›å»ºè¿›åº¦å›è°ƒåŒ…è£…å™¨ï¼ˆåŒæ—¶è¾“å‡ºåˆ°æ§åˆ¶å°å’Œå›è°ƒï¼‰
            def progress_cb(percent, message):
                if progress_callback:
                    progress_callback(percent, message)
                print(f"[Pipeline] ({percent}%) {message}")

            progress_cb(0, f"å¼€å§‹åˆ†æ: {video_path}")
            print(f"[Pipeline] æŸ¥è¯¢: {user_query}, æ¨¡å¼: {mode}, æ¨¡å‹: {model}")

            try:
                from traffic_vlm.pipeline import TrafficVLMPipeline
                from traffic_vlm.config import TrafficVLMConfig

                progress_cb(1, "æ­£åœ¨åˆå§‹åŒ– TrafficVLMPipeline...")
                vlm_config = TrafficVLMConfig()
                vlm_config.vlm.model = model

                # ä¼ å…¥ progress_cbï¼Œè®© Pipeline å†…éƒ¨çš„è¿›åº¦ä¹Ÿèƒ½å‘é€åˆ°å‰ç«¯
                pipeline = TrafficVLMPipeline(config=vlm_config, progress_cb=progress_cb)
                progress_cb(2, "Pipeline åˆå§‹åŒ–å®Œæˆï¼Œå¼€å§‹åˆ†æ...")

                result = pipeline.run(video_path, user_query, mode=mode)
                progress_cb(100, f"åˆ†æå®Œæˆï¼Œç»“æœæ•°é‡: {len(result.get('results', []))}")

                # è§£æç»“æœ
                has_event = False
                event_type = None
                confidence = 0.0
                confidence_level = None  # æ–°å¢ï¼šç½®ä¿¡åº¦åˆ†çº§
                confirmed_count = 0
                suspected_count = 0

                for item in result.get('results', []):
                    vlm_out = item.get('vlm_output', {}) or {}

                    # äº‹æ•…æ¨¡å¼ï¼šä½¿ç”¨ç½®ä¿¡åº¦åˆ†çº§ç»“æœ
                    if mode == 'accident':
                        confirmed = vlm_out.get('confirmed_accidents', [])
                        suspected = vlm_out.get('suspected_accidents', [])
                        confirmed_count += len(confirmed)
                        suspected_count += len(suspected)

                        # ä¼˜å…ˆä½¿ç”¨ç¡®å®šäº‹æ•…
                        if confirmed:
                            has_event = True
                            event_type = confirmed[0].get('type', 'ç¡®å®šäº‹æ•…')
                            confidence = confirmed[0].get('confidence', 0.7)
                            confidence_level = 'confirmed'
                        elif suspected and not has_event:
                            has_event = True
                            event_type = suspected[0].get('type', 'ç–‘ä¼¼äº‹æ•…')
                            confidence = suspected[0].get('confidence', 0.5)
                            confidence_level = 'suspected'
                    else:
                        # è¿æ³•æ£€æµ‹æ¨¡å¼ï¼šåŸæœ‰é€»è¾‘
                        if vlm_out.get('has_violation') or vlm_out.get('has_accident'):
                            has_event = True
                            violations = vlm_out.get('violations', [])
                            if violations:
                                event_type = violations[0].get('type', 'æœªçŸ¥äº‹ä»¶')
                                confidence = violations[0].get('confidence', 0.5)
                            else:
                                event_type = 'æ£€å‡ºå¼‚å¸¸'
                                confidence = 0.5
                            break

                print(f"[Pipeline] åˆ†æç»“æœ: has_event={has_event}, event_type={event_type}, confidence_level={confidence_level}")
                if mode == 'accident':
                    print(f"[Pipeline] ç½®ä¿¡åº¦ç»Ÿè®¡: ç¡®å®š={confirmed_count}, ç–‘ä¼¼={suspected_count}")

                return {
                    'has_event': has_event,
                    'event_type': event_type,
                    'confidence': confidence,
                    'confidence_level': confidence_level,  # æ–°å¢
                    'confirmed_count': confirmed_count,    # æ–°å¢
                    'suspected_count': suspected_count,    # æ–°å¢
                    'raw_result': result
                }

            except Exception as e:
                # æ‰“å°å®Œæ•´çš„é”™è¯¯å †æ ˆ
                print(f"[Pipeline] âŒ åˆ†æå¤±è´¥: {e}")
                traceback.print_exc()
                # é‡æ–°æŠ›å‡ºå¼‚å¸¸ï¼Œè®©è°ƒç”¨è€…å¤„ç†
                raise RuntimeError(f"Pipelineåˆ†æå¤±è´¥: {e}") from e

        # åˆ›å»º TsingcloudConfig ç”¨äºç¼“å­˜å…±äº«ï¼ˆæ— è®ºä½¿ç”¨å“ªç§ä¸‹è½½æ–¹å¼ï¼‰
        tsingcloud_config = TsingcloudConfig()

        _history_processor = HistoryVideoProcessor(
            api=api,
            config=config,
            pipeline_func=pipeline_func,
            event_callback=event_callback,
            tsingcloud_config=tsingcloud_config  # å¯ç”¨ç¼“å­˜å…±äº«
        )

    return _history_processor


@app.route('/history')
def history_page():
    """å†å²è§†é¢‘åˆ†æé¡µé¢"""
    return render_template('history.html', models=AVAILABLE_MODELS)


@app.route('/api/history/roads', methods=['GET'])
def get_roads():
    """è·å–å¯ç”¨è·¯å£åˆ—è¡¨"""
    try:
        # ä»rcuid.csvè¯»å–è·¯å£åˆ—è¡¨ï¼ˆä½¿ç”¨æ ‡å‡†åº“csvæ¨¡å—ï¼Œæ— éœ€pandasï¼‰
        import csv
        csv_path = os.path.join(os.path.dirname(__file__), 'è½¦ç½‘è·¯å£è§†é¢‘æµç›¸å…³èµ„æ–™', 'rcuid.csv')

        if os.path.exists(csv_path):
            with open(csv_path, 'r', encoding='utf-8-sig') as f:  # utf-8-sig è‡ªåŠ¨å¤„ç†BOM
                reader = csv.DictReader(f)
                # è·å–å”¯ä¸€çš„è·¯å£ID
                road_ids = set()
                for row in reader:
                    rid = row.get('id', '').strip()
                    if rid:
                        road_ids.add(rid)
                roads = [{'road_id': rid, 'road_name': f'è·¯å£ #{rid}'} for rid in sorted(road_ids, key=lambda x: int(x) if x.isdigit() else 0)]
        else:
            # å¦‚æœCSVä¸å­˜åœ¨ï¼Œè¿”å›é»˜è®¤åˆ—è¡¨
            roads = [{'road_id': str(i), 'road_name': f'è·¯å£ #{i}'} for i in range(1, 11)]

        return jsonify({
            'success': True,
            'roads': roads,
            'total': len(roads)
        })

    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500


@app.route('/api/history/cameras/<road_id>', methods=['GET'])
def get_cameras(road_id):
    """è·å–è·¯å£çš„æ‘„åƒå¤´åˆ—è¡¨"""
    try:
        api = get_tsingcloud_api()

        # ä½¿ç”¨å½“å‰æ—¶é—´ä½œä¸ºæŸ¥è¯¢æ—¶é—´ï¼ˆè·å–æœ€æ–°çš„æ‘„åƒå¤´åˆ—è¡¨ï¼‰
        now = datetime.now()
        start_time = now.strftime("%Y%m%d%H%M%S")
        end_time = (now + timedelta(minutes=5)).strftime("%Y%m%d%H%M%S")

        cameras = api.get_road_cameras(road_id, start_time, end_time)

        camera_list = []
        for cam in cameras:
            camera_list.append({
                'channel_num': cam.channel_num,
                'camera_type': cam.camera_type,
                'camera_type_str': cam.camera_type_str,
                'is_panoramic': cam.is_panoramic
            })

        return jsonify({
            'success': True,
            'road_id': road_id,
            'cameras': camera_list,
            'total': len(camera_list)
        })

    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500


@app.route('/api/history/rtsp-devices/<road_id>', methods=['GET'])
def get_rtsp_devices(road_id):
    """è·å–è·¯å£çš„RTSPè®¾å¤‡åˆ—è¡¨ï¼ˆä»è®¾å¤‡æ˜ å°„æ–‡ä»¶ï¼‰"""
    try:
        from traffic_vlm.tsingcloud_api import DeviceMapper
        from traffic_vlm.config import TsingcloudConfig

        config = TsingcloudConfig()
        mapper = DeviceMapper(config.device_mapping_file)

        # è·å–æ‰€æœ‰è®¾å¤‡
        all_devices = mapper.get_all_devices(road_id)
        dj_devices = mapper.get_all_devices(road_id, "DJ")
        kk_devices = mapper.get_all_devices(road_id, "KK")

        device_list = []
        for i, dev in enumerate(dj_devices):
            device_list.append({
                'device_id': dev['deviceId'],
                'device_cate': 'DJ',
                'device_cate_str': 'å…¨æ™¯æ‘„åƒå¤´',
                'index': i,
                'is_panoramic': True
            })
        for i, dev in enumerate(kk_devices):
            device_list.append({
                'device_id': dev['deviceId'],
                'device_cate': 'KK',
                'device_cate_str': 'æŠ“æ‹æ‘„åƒå¤´',
                'index': i,
                'is_panoramic': False
            })

        return jsonify({
            'success': True,
            'road_id': road_id,
            'devices': device_list,
            'total': len(device_list),
            'dj_count': len(dj_devices),
            'kk_count': len(kk_devices)
        })

    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500


@app.route('/api/history/start', methods=['POST'])
def start_history_analysis():
    """å¯åŠ¨å†å²è§†é¢‘æ‰¹é‡åˆ†æä»»åŠ¡ï¼ˆæ”¯æŒè·¨æ—¥æœŸæ—¶é—´æ®µå’Œå¤šæ‘„åƒå¤´ï¼‰"""
    try:
        data = request.get_json()

        road_id = data.get('road_id')
        channel_num = data.get('channel_num')  # HTTPè½®è¯¢ç”¨ï¼ˆå•æ‘„åƒå¤´ï¼‰
        channel_nums = data.get('channel_nums', [])  # å¤šæ‘„åƒå¤´æ¨¡å¼
        # æ”¯æŒæ–°çš„è·¨æ—¥æœŸæ ¼å¼
        start_date = data.get('start_date') or data.get('date')  # å…¼å®¹æ—§æ ¼å¼
        start_time = data.get('start_time')
        end_date = data.get('end_date') or data.get('date')  # å…¼å®¹æ—§æ ¼å¼
        end_time = data.get('end_time')
        mode = data.get('mode', 'accident')
        model = data.get('model', 'qwen-vl-plus')
        violation_types = data.get('violation_types', [])
        segment_duration = data.get('segment_duration', 300)

        # ä¸‹è½½æ–¹å¼é…ç½®
        download_method = data.get('download_method', 'auto')  # auto, rtsp, http
        device_cate = data.get('device_cate', 'DJ')  # RTSPè®¾å¤‡ç±»å‹
        device_index = data.get('device_index', 0)   # RTSPè®¾å¤‡ç´¢å¼•

        # å…¼å®¹æ–°æ—§å‚æ•°ï¼šå¦‚æœåªä¼ äº†channel_numï¼Œè½¬ä¸ºchannel_nums
        if channel_num and not channel_nums:
            channel_nums = [channel_num]
        if channel_nums and not channel_num:
            channel_num = channel_nums[0]

        # éªŒè¯å¿…è¦å‚æ•°ï¼ˆHTTPè½®è¯¢éœ€è¦channel_numï¼ŒRTSPå¯é€‰ï¼‰
        if not all([road_id, start_date, start_time, end_date, end_time]):
            return jsonify({
                'success': False,
                'error': 'ç¼ºå°‘å¿…è¦å‚æ•°ï¼šroad_id, start_date, start_time, end_date, end_time'
            }), 400

        # HTTPè½®è¯¢æ¨¡å¼éœ€è¦channel_numæˆ–channel_nums
        if download_method == 'http' and not channel_num and not channel_nums:
            return jsonify({
                'success': False,
                'error': 'HTTPè½®è¯¢æ¨¡å¼éœ€è¦channel_numæˆ–channel_numså‚æ•°'
            }), 400

        processor = get_history_processor()

        # åˆ›å»ºä»»åŠ¡ï¼ˆæ”¯æŒè·¨æ—¥æœŸå’Œå¤šæ‘„åƒå¤´ï¼‰
        task = processor.create_task(
            road_id=road_id,
            channel_num=channel_num or '',  # RTSPæ¨¡å¼å¯ä»¥ä¸ºç©º
            start_date=start_date,
            start_time=start_time,
            end_date=end_date,
            end_time=end_time,
            mode=mode,
            model=model,
            violation_types=violation_types,
            segment_duration=segment_duration,
            download_method=download_method,
            device_cate=device_cate,
            device_index=device_index,
            channel_nums=channel_nums  # å¤šæ‘„åƒå¤´æ¨¡å¼
        )

        # åˆ›å»ºSSEé˜Ÿåˆ—
        _history_sse_queues[task.task_id] = Queue()

        # åœ¨åå°çº¿ç¨‹å¯åŠ¨ä»»åŠ¡
        def run_task():
            processor.start_task(task.task_id)

        thread = threading.Thread(target=run_task)
        thread.daemon = True
        thread.start()

        # è®¡ç®—é¢„ä¼°æ—¶é—´ï¼ˆå…¼å®¹å¤šæ‘„åƒå¤´æ¨¡å¼ï¼‰
        if task.is_multi_camera():
            total_segments = sum(len(ct.segments) for ct in task.camera_tasks)
            camera_count = len(task.camera_tasks)
        else:
            total_segments = len(task.segments)
            camera_count = 1

        total_minutes = (total_segments * 5)  # æ¯æ®µçº¦5åˆ†é’Ÿ
        estimated_duration = f"çº¦{total_minutes}åˆ†é’Ÿ"

        return jsonify({
            'success': True,
            'task_id': task.task_id,
            'total_segments': total_segments,
            'camera_count': camera_count,
            'multi_camera': task.is_multi_camera(),
            'mode': mode,
            'model': model,
            'segment_duration': segment_duration,
            'estimated_duration': estimated_duration
        })

    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500


@app.route('/api/history/stop/<task_id>', methods=['POST'])
def stop_history_analysis(task_id):
    """åœæ­¢å†å²è§†é¢‘åˆ†æä»»åŠ¡"""
    try:
        processor = get_history_processor()
        processor.stop_task(task_id)

        return jsonify({
            'success': True,
            'message': f'ä»»åŠ¡ {task_id} å·²åœæ­¢'
        })

    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500


@app.route('/api/history/progress/<task_id>')
def history_progress(task_id):
    """SSEè¿›åº¦æµ"""
    def generate():
        # ç¡®ä¿é˜Ÿåˆ—å­˜åœ¨
        if task_id not in _history_sse_queues:
            yield f"event: error\ndata: {json.dumps({'message': 'ä»»åŠ¡ä¸å­˜åœ¨'})}\n\n"
            return

        q = _history_sse_queues[task_id]

        # å‘é€åˆå§‹è¿æ¥æ¶ˆæ¯
        yield f"event: connected\ndata: {json.dumps({'task_id': task_id})}\n\n"

        try:
            while True:
                try:
                    # å¢åŠ è¶…æ—¶æ—¶é—´åˆ°30ç§’ï¼Œå®¹å¿ä¸‹è½½è¿æ¥å»ºç«‹ç­‰æ…¢æ“ä½œ
                    item = q.get(timeout=30)
                    event_type = item.get('event', 'message')
                    data = item.get('data', {})

                    yield f"event: {event_type}\ndata: {json.dumps(data, ensure_ascii=False)}\n\n"

                    # å¦‚æœæ˜¯å®Œæˆäº‹ä»¶ï¼Œç»“æŸæµ
                    if event_type == 'complete':
                        break

                except Empty:
                    # å‘é€å¿ƒè·³
                    yield f": heartbeat\n\n"
                    continue

        except GeneratorExit:
            pass
        finally:
            # æ¸…ç†é˜Ÿåˆ—
            if task_id in _history_sse_queues:
                del _history_sse_queues[task_id]

    return Response(
        stream_with_context(generate()),
        mimetype='text/event-stream',
        headers={
            'Cache-Control': 'no-cache',
            'X-Accel-Buffering': 'no',
            'Connection': 'keep-alive'
        }
    )


@app.route('/api/history/retry/<task_id>/<int:segment_index>', methods=['POST'])
def retry_segment(task_id, segment_index):
    """é‡è¯•å¤±è´¥çš„ç‰‡æ®µ"""
    try:
        processor = get_history_processor()
        success = processor.retry_segment(task_id, segment_index)

        if success:
            return jsonify({
                'success': True,
                'message': f'ç‰‡æ®µ#{segment_index} å·²åŠ å…¥é‡è¯•é˜Ÿåˆ—'
            })
        else:
            return jsonify({
                'success': False,
                'error': 'é‡è¯•å¤±è´¥ï¼Œä»»åŠ¡æˆ–ç‰‡æ®µä¸å­˜åœ¨'
            }), 400

    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500


@app.route('/api/history/skip/<task_id>/<int:segment_index>', methods=['POST'])
def skip_segment(task_id, segment_index):
    """è·³è¿‡å¤±è´¥çš„ç‰‡æ®µ"""
    try:
        processor = get_history_processor()
        success = processor.skip_segment(task_id, segment_index)

        if success:
            return jsonify({
                'success': True,
                'message': f'ç‰‡æ®µ#{segment_index} å·²æ ‡è®°ä¸ºè·³è¿‡'
            })
        else:
            return jsonify({
                'success': False,
                'error': 'è·³è¿‡å¤±è´¥ï¼Œä»»åŠ¡æˆ–ç‰‡æ®µä¸å­˜åœ¨'
            }), 400

    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500


@app.route('/api/history/report/<task_id>')
def get_history_report(task_id):
    """è·å–åˆ†ææŠ¥å‘Š"""
    try:
        config = HistoryProcessConfig()
        report_path = os.path.join(config.result_dir, task_id, 'report.html')

        if os.path.exists(report_path):
            return send_file(report_path, mimetype='text/html')
        else:
            return jsonify({
                'success': False,
                'error': 'æŠ¥å‘Šä¸å­˜åœ¨'
            }), 404

    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500


@app.route('/api/history/download/<task_id>/<int:segment_index>')
def download_evidence(task_id, segment_index):
    """ä¸‹è½½è¯æ®åŒ…"""
    try:
        config = HistoryProcessConfig()
        segment_dir = os.path.join(config.result_dir, task_id, f'segment_{segment_index:03d}')

        if not os.path.exists(segment_dir):
            return jsonify({
                'success': False,
                'error': 'è¯æ®ä¸å­˜åœ¨'
            }), 404

        # åˆ›å»ºZIPå‹ç¼©åŒ…
        zip_filename = f'{task_id}_segment_{segment_index}.zip'
        zip_path = os.path.join(config.temp_dir, zip_filename)

        shutil.make_archive(zip_path.replace('.zip', ''), 'zip', segment_dir)

        return send_file(zip_path, as_attachment=True, download_name=zip_filename)

    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500


@app.route('/api/history/thumbnail/<task_id>/<int:segment_index>')
def get_thumbnail(task_id, segment_index):
    """è·å–ç‰‡æ®µç¼©ç•¥å›¾"""
    try:
        config = HistoryProcessConfig()
        keyframes_dir = os.path.join(config.result_dir, task_id, f'segment_{segment_index:03d}', 'keyframes')

        # å°è¯•è·å–ç¬¬ä¸€å¼ å…³é”®å¸§ä½œä¸ºç¼©ç•¥å›¾
        if os.path.exists(keyframes_dir):
            frames = os.listdir(keyframes_dir)
            if frames:
                first_frame = os.path.join(keyframes_dir, sorted(frames)[0])
                return send_file(first_frame, mimetype='image/jpeg')

        # å¦‚æœæ²¡æœ‰å…³é”®å¸§ï¼Œè¿”å›é»˜è®¤å›¾ç‰‡
        return jsonify({
            'success': False,
            'error': 'ç¼©ç•¥å›¾ä¸å­˜åœ¨'
        }), 404

    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500


@app.route('/api/history/status/<task_id>')
def get_task_status(task_id):
    """è·å–ä»»åŠ¡çŠ¶æ€"""
    try:
        processor = get_history_processor()
        status = processor.get_task_status(task_id)

        if status:
            return jsonify({
                'success': True,
                **status
            })
        else:
            return jsonify({
                'success': False,
                'error': 'ä»»åŠ¡ä¸å­˜åœ¨'
            }), 404

    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500


# ============================================================
# æ‰¹é‡éå†åˆ†æ API
# ============================================================

from traffic_vlm.batch_processor import BatchVideoProcessor, BatchEventType

# æ‰¹é‡å¤„ç†å™¨å…¨å±€å®ä¾‹
_batch_processor = None
_batch_sse_queues = {}


def get_batch_processor():
    """è·å–æ‰¹é‡è§†é¢‘å¤„ç†å™¨ï¼ˆå•ä¾‹ï¼‰"""
    global _batch_processor

    if _batch_processor is None:
        api = get_tsingcloud_api()
        from traffic_vlm.config import BatchProcessConfig, HistoryProcessConfig

        batch_config = BatchProcessConfig()
        history_config = HistoryProcessConfig()

        # åˆ›å»ºpipelineå‡½æ•°ï¼ˆè°ƒç”¨TrafficVLMPipelineè¿›è¡Œè§†é¢‘åˆ†æï¼‰
        def pipeline_func(video_path, user_query, mode, model, progress_callback=None):
            """è°ƒç”¨è§†é¢‘åˆ†æpipeline"""
            import traceback

            def progress_cb(percent, message):
                if progress_callback:
                    progress_callback(percent, message)
                print(f"[BatchPipeline] ({percent}%) {message}")

            progress_cb(0, f"å¼€å§‹åˆ†æ: {video_path}")

            try:
                from traffic_vlm.pipeline import TrafficVLMPipeline
                from traffic_vlm.config import TrafficVLMConfig

                progress_cb(1, "æ­£åœ¨åˆå§‹åŒ– TrafficVLMPipeline...")
                vlm_config = TrafficVLMConfig()
                vlm_config.vlm.model = model

                pipeline = TrafficVLMPipeline(config=vlm_config, progress_cb=progress_cb)
                progress_cb(2, "Pipeline åˆå§‹åŒ–å®Œæˆï¼Œå¼€å§‹åˆ†æ...")

                result = pipeline.run(video_path, user_query, mode=mode)
                progress_cb(100, f"åˆ†æå®Œæˆï¼Œç»“æœæ•°é‡: {len(result.get('results', []))}")

                # è§£æç»“æœ
                has_event = False
                event_type = None
                confidence = 0.0
                confidence_level = None  # æ–°å¢ï¼šç½®ä¿¡åº¦åˆ†çº§
                confirmed_count = 0
                suspected_count = 0

                for item in result.get('results', []):
                    vlm_out = item.get('vlm_output', {}) or {}

                    # äº‹æ•…æ¨¡å¼ï¼šä½¿ç”¨ç½®ä¿¡åº¦åˆ†çº§ç»“æœ
                    if mode == 'accident':
                        confirmed = vlm_out.get('confirmed_accidents', [])
                        suspected = vlm_out.get('suspected_accidents', [])
                        confirmed_count += len(confirmed)
                        suspected_count += len(suspected)

                        # ä¼˜å…ˆä½¿ç”¨ç¡®å®šäº‹æ•…
                        if confirmed:
                            has_event = True
                            event_type = confirmed[0].get('type', 'ç¡®å®šäº‹æ•…')
                            confidence = confirmed[0].get('confidence', 0.7)
                            confidence_level = 'confirmed'
                        elif suspected and not has_event:
                            has_event = True
                            event_type = suspected[0].get('type', 'ç–‘ä¼¼äº‹æ•…')
                            confidence = suspected[0].get('confidence', 0.5)
                            confidence_level = 'suspected'
                    else:
                        # è¿æ³•æ£€æµ‹æ¨¡å¼ï¼šåŸæœ‰é€»è¾‘
                        if vlm_out.get('has_violation') or vlm_out.get('has_accident'):
                            has_event = True
                            violations = vlm_out.get('violations', [])
                            if violations:
                                event_type = violations[0].get('type', 'æœªçŸ¥äº‹ä»¶')
                                confidence = violations[0].get('confidence', 0.5)
                            else:
                                event_type = 'æ£€å‡ºå¼‚å¸¸'
                                confidence = 0.5
                            break

                return {
                    'has_event': has_event,
                    'event_type': event_type,
                    'confidence': confidence,
                    'confidence_level': confidence_level,  # æ–°å¢
                    'confirmed_count': confirmed_count,    # æ–°å¢
                    'suspected_count': suspected_count,    # æ–°å¢
                    'raw_result': result
                }

            except Exception as e:
                print(f"[BatchPipeline] âŒ åˆ†æå¤±è´¥: {e}")
                traceback.print_exc()
                raise RuntimeError(f"Pipelineåˆ†æå¤±è´¥: {e}") from e

        # è·å–äº‘æ§é…ç½®ï¼ˆç”¨äºRTSPåŒè´¦å·ä¸‹è½½ï¼‰
        from traffic_vlm.config import TsingcloudConfig
        tsingcloud_config = TsingcloudConfig()

        _batch_processor = BatchVideoProcessor(
            api=api,
            batch_config=batch_config,
            history_config=history_config,
            pipeline_func=pipeline_func,
            tsingcloud_config=tsingcloud_config
        )

    return _batch_processor


@app.route('/api/batch/start', methods=['POST'])
def start_batch_analysis():
    """å¯åŠ¨æ‰¹é‡éå†åˆ†æä»»åŠ¡ï¼ˆæ”¯æŒè·¨æ—¥æœŸæ—¶é—´æ®µï¼‰"""
    try:
        data = request.get_json()

        mode = data.get('mode', 'road_traverse')  # time_traverse | road_traverse
        # æ”¯æŒæ–°çš„è·¨æ—¥æœŸæ ¼å¼
        start_date = data.get('start_date') or data.get('date')  # å…¼å®¹æ—§æ ¼å¼
        start_time = data.get('start_time')
        end_date = data.get('end_date') or data.get('date')  # å…¼å®¹æ—§æ ¼å¼
        end_time = data.get('end_time')
        road_ids = data.get('road_ids', [])  # ç©ºåˆ—è¡¨=æ‰€æœ‰è·¯å£
        model = data.get('model', 'qwen-vl-plus')
        analysis_mode = data.get('analysis_mode', 'accident')
        violation_types = data.get('violation_types', [])
        segment_duration = data.get('segment_duration', 300)

        # ä¸‹è½½æ–¹å¼é…ç½®
        download_method = data.get('download_method', 'auto')  # auto, rtsp, http
        device_cate = data.get('device_cate', 'DJ')  # RTSPè®¾å¤‡ç±»å‹
        device_index = data.get('device_index', 0)   # RTSPè®¾å¤‡ç´¢å¼•

        # éªŒè¯å‚æ•°
        if not start_date or not start_time or not end_date or not end_time:
            return jsonify({
                'success': False,
                'error': 'ç¼ºå°‘å¿…éœ€å‚æ•°: start_date, start_time, end_date, end_time'
            }), 400

        processor = get_batch_processor()

        # åˆ›å»ºæ‰¹é‡ä»»åŠ¡ï¼ˆæ”¯æŒè·¨æ—¥æœŸï¼‰
        batch_task = processor.create_batch_task(
            mode=mode,
            start_date=start_date,
            start_time=start_time,
            end_date=end_date,
            end_time=end_time,
            road_ids=road_ids if road_ids else None,
            model=model,
            analysis_mode=analysis_mode,
            violation_types=violation_types,
            segment_duration=segment_duration,
            download_method=download_method,
            device_cate=device_cate,
            device_index=device_index
        )

        batch_id = batch_task.batch_id

        # åˆ›å»ºSSEé˜Ÿåˆ—
        _batch_sse_queues[batch_id] = Queue()

        # è®¾ç½®äº‹ä»¶å›è°ƒ
        def batch_event_callback(event_type, data):
            if batch_id in _batch_sse_queues:
                _batch_sse_queues[batch_id].put((event_type, data))

        processor.event_callback = batch_event_callback

        # åœ¨åå°çº¿ç¨‹å¯åŠ¨ä»»åŠ¡
        def run_batch_task():
            try:
                processor.start_batch_task(batch_id)
            except Exception as e:
                print(f"[Batch] âŒ æ‰¹é‡ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
                if batch_id in _batch_sse_queues:
                    _batch_sse_queues[batch_id].put((
                        BatchEventType.BATCH_ERROR,
                        {"batch_id": batch_id, "error": str(e)}
                    ))

        thread = threading.Thread(target=run_batch_task, name=f"Batch-{batch_id}")
        thread.start()

        return jsonify({
            'success': True,
            'batch_id': batch_id,
            'mode': mode,
            'total_roads': batch_task.total_roads,
            'message': f'æ‰¹é‡ä»»åŠ¡å·²åˆ›å»ºï¼Œå…± {batch_task.total_roads} ä¸ªè·¯å£'
        })

    except Exception as e:
        print(f"[Batch] âŒ åˆ›å»ºæ‰¹é‡ä»»åŠ¡å¤±è´¥: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500


@app.route('/api/batch/stop/<batch_id>', methods=['POST'])
def stop_batch_analysis(batch_id):
    """åœæ­¢æ‰¹é‡åˆ†æä»»åŠ¡"""
    try:
        processor = get_batch_processor()
        processor.stop_batch_task(batch_id)

        return jsonify({
            'success': True,
            'message': 'æ‰¹é‡ä»»åŠ¡å·²åœæ­¢'
        })

    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500


@app.route('/api/batch/progress/<batch_id>')
def batch_progress_stream(batch_id):
    """æ‰¹é‡ä»»åŠ¡SSEè¿›åº¦æµ"""
    def generate():
        if batch_id not in _batch_sse_queues:
            yield f"event: error\ndata: {{\"message\": \"æ‰¹é‡ä»»åŠ¡ä¸å­˜åœ¨\"}}\n\n"
            return

        q = _batch_sse_queues[batch_id]

        # å‘é€åˆå§‹çŠ¶æ€
        processor = get_batch_processor()
        status = processor.get_batch_status(batch_id)
        if status:
            yield f"event: init\ndata: {json.dumps(status, ensure_ascii=False)}\n\n"

        # æŒç»­ç›‘å¬äº‹ä»¶
        while True:
            try:
                event_type, data = q.get(timeout=30)

                # å‘é€äº‹ä»¶
                event_name = event_type.value if hasattr(event_type, 'value') else str(event_type)
                yield f"event: {event_name}\ndata: {json.dumps(data, ensure_ascii=False)}\n\n"

                # ä»»åŠ¡å®Œæˆæˆ–å‡ºé”™åˆ™é€€å‡º
                if event_type in [BatchEventType.BATCH_COMPLETE, BatchEventType.BATCH_ERROR]:
                    break

            except Empty:
                # å‘é€å¿ƒè·³ä¿æŒè¿æ¥
                yield f": heartbeat\n\n"
                continue

        # æ¸…ç†é˜Ÿåˆ—
        if batch_id in _batch_sse_queues:
            del _batch_sse_queues[batch_id]

    return Response(
        stream_with_context(generate()),
        mimetype='text/event-stream',
        headers={
            'Cache-Control': 'no-cache',
            'Connection': 'keep-alive',
            'X-Accel-Buffering': 'no'
        }
    )


@app.route('/api/batch/status/<batch_id>')
def get_batch_status(batch_id):
    """è·å–æ‰¹é‡ä»»åŠ¡çŠ¶æ€"""
    try:
        processor = get_batch_processor()
        status = processor.get_batch_status(batch_id)

        if status:
            return jsonify({
                'success': True,
                **status
            })
        else:
            return jsonify({
                'success': False,
                'error': 'æ‰¹é‡ä»»åŠ¡ä¸å­˜åœ¨'
            }), 404

    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500


@app.route('/api/batch/skip/<batch_id>/<road_id>', methods=['POST'])
def skip_batch_road(batch_id, road_id):
    """è·³è¿‡æŒ‡å®šè·¯å£"""
    try:
        processor = get_batch_processor()
        success = processor.skip_road(batch_id, road_id)

        if success:
            return jsonify({
                'success': True,
                'message': f'è·¯å£ {road_id} å·²è·³è¿‡'
            })
        else:
            return jsonify({
                'success': False,
                'error': 'æ— æ³•è·³è¿‡è¯¥è·¯å£'
            }), 400

    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500


@app.route('/api/batch/report/<batch_id>')
def get_batch_report(batch_id):
    """è·å–æ‰¹é‡ä»»åŠ¡æ±‡æ€»æŠ¥å‘Š"""
    try:
        from traffic_vlm.config import BatchProcessConfig
        config = BatchProcessConfig()
        report_path = os.path.join(config.batch_result_dir, batch_id, 'report.html')

        if os.path.exists(report_path):
            return send_file(report_path, mimetype='text/html')
        else:
            return jsonify({
                'success': False,
                'error': 'æŠ¥å‘Šä¸å­˜åœ¨'
            }), 404

    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500


def _cleanup_on_exit():
    """ç¨‹åºé€€å‡ºæ—¶æ¸…ç†èµ„æº"""
    print("\n[Cleanup] æ­£åœ¨æ¸…ç†èµ„æº...")
    try:
        cleanup_embedding_service()
    except Exception as e:
        print(f"[Cleanup] æ¸…ç†è­¦å‘Š: {e}")
    print("[Cleanup] èµ„æºæ¸…ç†å®Œæˆ")


def _signal_handler(signum, frame):
    """ä¿¡å·å¤„ç†å™¨ï¼ˆCtrl+Cç­‰ï¼‰"""
    print(f"\n[Signal] æ”¶åˆ°ä¿¡å· {signum}ï¼Œæ­£åœ¨é€€å‡º...")
    _cleanup_on_exit()
    sys.exit(0)


if __name__ == '__main__':
    # æ³¨å†Œé€€å‡ºæ¸…ç†
    atexit.register(_cleanup_on_exit)

    # æ³¨å†Œä¿¡å·å¤„ç†ï¼ˆCtrl+Cï¼‰
    signal.signal(signal.SIGINT, _signal_handler)
    signal.signal(signal.SIGTERM, _signal_handler)

    print("=" * 60)
    print("Qwen3-VL è§†é¢‘åˆ†ææœåŠ¡ (DashScope API)")
    print("=" * 60)
    print()

    # æ£€æŸ¥ API Key
    if DASHSCOPE_API_KEY:
        print("âœ“ DashScope API Key å·²é…ç½®")
        print(f"  API Key: {DASHSCOPE_API_KEY[:8]}...")
    else:
        print("âœ— è­¦å‘Š: æœªé…ç½® DashScope API Key")
        print("  è¯·è®¾ç½®ç¯å¢ƒå˜é‡:")
        print("    Windows: set DASHSCOPE_API_KEY=your_api_key")
        print("    Linux/Mac: export DASHSCOPE_API_KEY=your_api_key")
        print("  æˆ–åœ¨ app.py ä¸­ç›´æ¥è®¾ç½® DASHSCOPE_API_KEY å˜é‡")
        print()
        print("  è·å– API Key: https://dashscope.console.aliyun.com/apiKey")

    print()
    print(f"å¯ç”¨æ¨¡å‹: {len(AVAILABLE_MODELS)} ä¸ª")
    for model_id, model_name in AVAILABLE_MODELS.items():
        print(f"  - {model_id}: {model_name}")

    # æ£€æŸ¥ GPU åŠ é€Ÿæ”¯æŒ
    print()
    if check_nvenc_support():
        print("âœ“ NVIDIA GPU ç¡¬ä»¶åŠ é€Ÿå·²å¯ç”¨")
        print("  è§†é¢‘å‹ç¼©å°†ä½¿ç”¨ NVENC åŠ é€Ÿ (æ¯”CPUå¿«3-10å€)")
    else:
        print("âœ— æœªæ£€æµ‹åˆ° NVIDIA GPU æ”¯æŒ")
        print("  è§†é¢‘å‹ç¼©å°†ä½¿ç”¨ CPU ç¼–ç  (è¾ƒæ…¢)")

    print()
    print("=" * 60)
    print("æœåŠ¡å¯åŠ¨åœ¨: http://localhost:5000")
    print("=" * 60)
    print()

    # å¯åŠ¨ Flask åº”ç”¨
    # ç¦ç”¨ reloader é¿å… Windows ä¸Šçš„ WinError 10038 å¥—æ¥å­—é”™è¯¯
    app.run(host='0.0.0.0', port=5000, debug=True, threaded=True, use_reloader=False)
