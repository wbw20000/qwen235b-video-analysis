"""
å†å²è§†é¢‘åˆ†æ®µå¤„ç†å™¨

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. æ—¶é—´æ®µåˆ†ç‰‡ï¼ˆé»˜è®¤5åˆ†é’Ÿä¸€æ®µï¼‰
2. ä¸‹è½½ä¸åˆ†æå¹¶è¡Œæ‰§è¡Œï¼ˆç”Ÿäº§è€…-æ¶ˆè´¹è€…æ¨¡å¼ï¼‰
3. ç»“æœç®¡ç†ï¼ˆæœ‰äº‹æ•…ä¿å­˜è¯æ®ï¼Œæ— äº‹æ•…æ¸…ç†ï¼‰
4. SSEè¿›åº¦æ¨é€
"""
from __future__ import annotations

import os
import json
import uuid
import shutil
import logging
import threading
import time
from queue import Queue, Empty
from datetime import datetime, timedelta
from dataclasses import dataclass, field
from typing import List, Dict, Any, Optional, Callable, Generator
from enum import Enum

from .tsingcloud_api import TsingcloudAPI, CameraInfo, download_video, TsingcloudAPIError
from .config import HistoryProcessConfig, TsingcloudConfig

logger = logging.getLogger(__name__)


class SegmentStatus(Enum):
    """ç‰‡æ®µçŠ¶æ€"""
    PENDING = "pending"      # ç­‰å¾…ä¸­
    DOWNLOADING = "downloading"  # ä¸‹è½½ä¸­
    DOWNLOAD_FAILED = "download_failed"  # ä¸‹è½½å¤±è´¥
    ANALYZING = "analyzing"  # åˆ†æä¸­
    ANALYZE_FAILED = "analyze_failed"  # åˆ†æå¤±è´¥
    COMPLETED = "completed"  # å®Œæˆ
    SKIPPED = "skipped"      # è·³è¿‡


class EventType(Enum):
    """SSEäº‹ä»¶ç±»å‹"""
    QUEUE = "queue"          # é˜Ÿåˆ—çŠ¶æ€æ›´æ–°
    PROGRESS = "progress"    # è¿›åº¦æ›´æ–°
    LOG = "log"              # æ—¥å¿—
    RESULT = "result"        # æ£€å‡ºç»“æœ
    ERROR = "error"          # é”™è¯¯
    COMPLETE = "complete"    # ä»»åŠ¡å®Œæˆ


@dataclass
class SegmentInfo:
    """ç‰‡æ®µä¿¡æ¯"""
    index: int
    start_time: datetime
    end_time: datetime
    time_range: str  # æ˜¾ç¤ºç”¨ï¼Œå¦‚ "09:00-09:05"

    download_status: SegmentStatus = SegmentStatus.PENDING
    analyze_status: SegmentStatus = SegmentStatus.PENDING
    result: Optional[str] = None  # "detected", "cleared", None

    video_path: Optional[str] = None
    request_id: Optional[str] = None
    retry_count: int = 0
    error_message: Optional[str] = None

    # åˆ†æç»“æœè¯¦æƒ…
    event_type: Optional[str] = None  # äº‹æ•…/è¿æ³•ç±»å‹
    confidence: float = 0.0
    evidence_path: Optional[str] = None

    def to_dict(self) -> dict:
        return {
            "index": self.index,
            "time_range": self.time_range,
            "download": self.download_status.value,
            "analyze": self.analyze_status.value,
            "result": self.result,
            "retry_count": self.retry_count,
            "error": self.error_message
        }


@dataclass
class TaskInfo:
    """ä»»åŠ¡ä¿¡æ¯ï¼ˆæ”¯æŒè·¨æ—¥æœŸæ—¶é—´æ®µï¼‰"""
    task_id: str
    road_id: str
    channel_num: str
    start_date: str    # å¼€å§‹æ—¥æœŸï¼Œå¦‚ "2024-12-17"
    start_time: str    # å¼€å§‹æ—¶é—´ï¼Œå¦‚ "20:00"
    end_date: str      # ç»“æŸæ—¥æœŸï¼Œå¦‚ "2024-12-19"
    end_time: str      # ç»“æŸæ—¶é—´ï¼Œå¦‚ "08:00"
    mode: str  # "accident" æˆ– "violation"
    model: str  # VLMæ¨¡å‹
    violation_types: List[str] = field(default_factory=list)

    segments: List[SegmentInfo] = field(default_factory=list)
    created_at: datetime = field(default_factory=datetime.now)
    status: str = "running"  # running, completed, stopped

    events_found: int = 0
    events_cleared: int = 0

    def to_dict(self) -> dict:
        return {
            "task_id": self.task_id,
            "road_id": self.road_id,
            "channel_num": self.channel_num,
            "start_date": self.start_date,
            "start_time": self.start_time,
            "end_date": self.end_date,
            "end_time": self.end_time,
            "mode": self.mode,
            "model": self.model,
            "total_segments": len(self.segments),
            "status": self.status,
            "events_found": self.events_found,
            "events_cleared": self.events_cleared
        }


class HistoryVideoProcessor:
    """
    å†å²è§†é¢‘å¤„ç†å™¨

    å®ç°ä¸‹è½½ä¸åˆ†æçš„å¹¶è¡Œå¤„ç†ï¼š
    - ä¸‹è½½çº¿ç¨‹ï¼ˆç”Ÿäº§è€…ï¼‰ï¼šé¡ºåºä¸‹è½½æ¯ä¸ª5åˆ†é’Ÿç‰‡æ®µ
    - åˆ†æçº¿ç¨‹ï¼ˆæ¶ˆè´¹è€…ï¼‰ï¼šåˆ†æä¸‹è½½å®Œæˆçš„è§†é¢‘
    - ç»“æœæ ¹æ®æ˜¯å¦æ£€å‡ºäº‹ä»¶å†³å®šä¿å­˜æˆ–åˆ é™¤
    """

    def __init__(
        self,
        api: TsingcloudAPI,
        config: HistoryProcessConfig,
        pipeline_func: Callable = None,
        event_callback: Callable[[EventType, dict], None] = None
    ):
        """
        åˆå§‹åŒ–å¤„ç†å™¨

        Args:
            api: äº‘æ§æ™ºè¡ŒAPIå®¢æˆ·ç«¯
            config: å¤„ç†é…ç½®
            pipeline_func: è§†é¢‘åˆ†æå‡½æ•° (video_path, query, mode, model) -> result
            event_callback: SSEäº‹ä»¶å›è°ƒå‡½æ•°
        """
        self.api = api
        self.config = config
        self.pipeline_func = pipeline_func
        self.event_callback = event_callback

        # ä»»åŠ¡ç®¡ç†
        self.tasks: Dict[str, TaskInfo] = {}

        # çº¿ç¨‹åŒæ­¥
        self.download_queue: Queue = Queue()
        self.analyze_queue: Queue = Queue()
        self._stop_flag = threading.Event()
        self._lock = threading.Lock()

    def _emit_event(self, event_type: EventType, data: dict):
        """å‘é€SSEäº‹ä»¶"""
        if self.event_callback:
            try:
                self.event_callback(event_type, data)
            except Exception as e:
                logger.error(f"äº‹ä»¶å›è°ƒå¤±è´¥: {e}")

    def _log(self, task_id: str, level: str, message: str, segment: int = None, details: dict = None, category: str = "general"):
        """
        è®°å½•æ—¥å¿—å¹¶å‘é€äº‹ä»¶

        Args:
            task_id: ä»»åŠ¡ID
            level: æ—¥å¿—çº§åˆ« (info/warning/error/success/debug)
            message: æ—¥å¿—æ¶ˆæ¯
            segment: ç‰‡æ®µç´¢å¼•ï¼ˆå¯é€‰ï¼‰
            details: é¢å¤–è¯¦æƒ…ï¼ˆå¯é€‰ï¼‰
            category: æ—¥å¿—ç±»åˆ« - "download" | "analyze" | "general"
        """
        logger.info(f"[Task {task_id}] {message}")
        self._emit_event(EventType.LOG, {
            "task_id": task_id,
            "timestamp": datetime.now().strftime("%H:%M:%S"),
            "level": level,
            "segment": segment,
            "message": message,
            "category": category,
            "details": details or {}
        })

    def _split_time_range(
        self,
        start_dt: datetime,
        end_dt: datetime,
        segment_duration: int
    ) -> List[SegmentInfo]:
        """å°†æ—¶é—´æ®µæ‹†åˆ†ä¸ºå¤šä¸ªç‰‡æ®µï¼ˆæ”¯æŒè·¨æ—¥æœŸæ—¶é—´èŒƒå›´ï¼‰"""
        segments = []
        current = start_dt
        index = 0

        # åˆ¤æ–­æ˜¯å¦è·¨æ—¥æœŸ
        is_cross_date = start_dt.date() != end_dt.date()

        while current < end_dt:
            seg_end = min(current + timedelta(seconds=segment_duration), end_dt)

            # æ„å»ºæ—¶é—´èŒƒå›´å­—ç¬¦ä¸²
            if is_cross_date:
                # è·¨æ—¥æœŸæ—¶åŒ…å«æ—¥æœŸä¿¡æ¯
                time_range = f"{current.strftime('%m/%d %H:%M')}-{seg_end.strftime('%H:%M')}"
            else:
                # åŒä¸€å¤©åªæ˜¾ç¤ºæ—¶é—´
                time_range = f"{current.strftime('%H:%M')}-{seg_end.strftime('%H:%M')}"

            segments.append(SegmentInfo(
                index=index,
                start_time=current,
                end_time=seg_end,
                time_range=time_range
            ))

            current = seg_end
            index += 1

        return segments

    def create_task(
        self,
        road_id: str,
        channel_num: str,
        start_date: str,
        start_time: str,
        end_date: str,
        end_time: str,
        mode: str = "accident",
        model: str = "qwen-vl-plus",
        violation_types: List[str] = None,
        segment_duration: int = None
    ) -> TaskInfo:
        """
        åˆ›å»ºåˆ†æä»»åŠ¡ï¼ˆæ”¯æŒè·¨æ—¥æœŸæ—¶é—´æ®µï¼‰

        Args:
            road_id: è·¯å£ID
            channel_num: æ‘„åƒå¤´é€šé“å·
            start_date: å¼€å§‹æ—¥æœŸ "2024-12-17"
            start_time: å¼€å§‹æ—¶é—´ "20:00"
            end_date: ç»“æŸæ—¥æœŸ "2024-12-19"
            end_time: ç»“æŸæ—¶é—´ "08:00"
            mode: åˆ†ææ¨¡å¼ "accident" æˆ– "violation"
            model: VLMæ¨¡å‹
            violation_types: è¿æ³•ç±»å‹åˆ—è¡¨
            segment_duration: åˆ†ç‰‡æ—¶é•¿ï¼ˆç§’ï¼‰

        Returns:
            TaskInfo ä»»åŠ¡ä¿¡æ¯
        """
        task_id = str(uuid.uuid4())[:8]
        segment_duration = segment_duration or self.config.segment_duration

        # è§£ææ—¶é—´ï¼ˆæ”¯æŒè·¨æ—¥æœŸï¼‰
        start_dt = datetime.strptime(f"{start_date} {start_time}", "%Y-%m-%d %H:%M")
        end_dt = datetime.strptime(f"{end_date} {end_time}", "%Y-%m-%d %H:%M")

        # åˆ†ç‰‡ï¼ˆè‡ªåŠ¨å¤„ç†è·¨æ—¥æœŸï¼‰
        segments = self._split_time_range(start_dt, end_dt, segment_duration)

        # åˆ›å»ºä»»åŠ¡
        task = TaskInfo(
            task_id=task_id,
            road_id=road_id,
            channel_num=channel_num,
            start_date=start_date,
            start_time=start_time,
            end_date=end_date,
            end_time=end_time,
            mode=mode,
            model=model,
            violation_types=violation_types or [],
            segments=segments
        )

        # ç¡®ä¿ç›®å½•å­˜åœ¨
        self.config.ensure_dirs()
        task_dir = os.path.join(self.config.result_dir, task_id)
        os.makedirs(task_dir, exist_ok=True)

        self.tasks[task_id] = task
        return task

    def start_task(self, task_id: str):
        """å¯åŠ¨ä»»åŠ¡ï¼ˆå¼€å§‹ä¸‹è½½å’Œåˆ†æï¼‰"""
        task = self.tasks.get(task_id)
        if not task:
            raise ValueError(f"ä»»åŠ¡ä¸å­˜åœ¨: {task_id}")

        # ã€ä¿®å¤ã€‘å¯åŠ¨æ–°ä»»åŠ¡å‰ï¼Œå…ˆåœæ­¢æ—§ä»»åŠ¡å¹¶æ¸…ç©ºé˜Ÿåˆ—
        self._stop_flag.set()  # é€šçŸ¥å¯èƒ½å­˜åœ¨çš„æ—§ä»»åŠ¡åœæ­¢
        time.sleep(0.3)  # ç­‰å¾…æ—§çº¿ç¨‹å“åº”

        # æ¸…ç©ºåˆ†æé˜Ÿåˆ—ï¼Œé˜²æ­¢æ—§ä»»åŠ¡çš„ç‰‡æ®µæ··å…¥
        while not self.analyze_queue.empty():
            try:
                self.analyze_queue.get_nowait()
            except Empty:
                break

        self._stop_flag.clear()

        self._log(task_id, "info",
                  f"ä»»åŠ¡å¯åŠ¨ - è·¯å£:{task.road_id}, æ‘„åƒå¤´:{task.channel_num}, "
                  f"{task.start_time}-{task.end_time}, æ¨¡å‹:{task.model}")

        # ã€ä¿®å¤ã€‘ç«‹å³å‘é€åˆå§‹é˜Ÿåˆ—çŠ¶æ€ï¼Œè®©å‰ç«¯æ˜¾ç¤ºè¡¨æ ¼
        self._update_queue_status(task)

        # å¯åŠ¨ä¸‹è½½çº¿ç¨‹
        download_thread = threading.Thread(
            target=self._download_worker,
            args=(task,),
            name=f"Download-{task_id}"
        )

        # å¯åŠ¨åˆ†æçº¿ç¨‹
        analyze_thread = threading.Thread(
            target=self._analyze_worker,
            args=(task,),
            name=f"Analyze-{task_id}"
        )

        download_thread.start()
        analyze_thread.start()

        # ç­‰å¾…å®Œæˆ
        download_thread.join()
        self.analyze_queue.put(None)  # ç»“æŸä¿¡å·
        analyze_thread.join()

        # ç”ŸæˆæŠ¥å‘Š
        self._generate_report(task)

        # å‘é€å®Œæˆäº‹ä»¶
        self._emit_event(EventType.COMPLETE, {
            "task_id": task_id,
            "total_segments": len(task.segments),
            "completed_segments": sum(1 for s in task.segments if s.download_status == SegmentStatus.COMPLETED),
            "skipped_segments": sum(1 for s in task.segments if s.download_status == SegmentStatus.SKIPPED),
            "mode": task.mode,
            "events_found": task.events_found,
            "events_cleared": task.events_cleared,
            "report_url": f"/api/history/report/{task_id}"
        })

        task.status = "completed"

    def stop_task(self, task_id: str):
        """åœæ­¢ä»»åŠ¡"""
        self._stop_flag.set()
        task = self.tasks.get(task_id)
        if task:
            task.status = "stopped"
            self._log(task_id, "warning", "ä»»åŠ¡å·²åœæ­¢")

    def retry_segment(self, task_id: str, segment_index: int):
        """é‡è¯•å¤±è´¥çš„ç‰‡æ®µ"""
        task = self.tasks.get(task_id)
        if not task:
            return False

        if segment_index < 0 or segment_index >= len(task.segments):
            return False

        segment = task.segments[segment_index]
        if segment.download_status == SegmentStatus.DOWNLOAD_FAILED:
            segment.download_status = SegmentStatus.PENDING
            segment.retry_count = 0
            self.download_queue.put(segment)
            self._log(task_id, "info", f"ç‰‡æ®µ#{segment_index} å·²åŠ å…¥é‡è¯•é˜Ÿåˆ—", segment_index)
            return True

        return False

    def skip_segment(self, task_id: str, segment_index: int):
        """è·³è¿‡å¤±è´¥çš„ç‰‡æ®µ"""
        task = self.tasks.get(task_id)
        if not task:
            return False

        if segment_index < 0 or segment_index >= len(task.segments):
            return False

        segment = task.segments[segment_index]
        segment.download_status = SegmentStatus.SKIPPED
        segment.analyze_status = SegmentStatus.SKIPPED
        self._log(task_id, "info", f"ç‰‡æ®µ#{segment_index} å·²æ ‡è®°ä¸ºè·³è¿‡", segment_index)
        return True

    def _download_worker(self, task: TaskInfo):
        """ä¸‹è½½çº¿ç¨‹ï¼šå¹¶è¡Œä¸‹è½½å¤šä¸ªç‰‡æ®µï¼ˆé¢„å–æ¨¡å¼ï¼‰"""
        from concurrent.futures import ThreadPoolExecutor, as_completed

        max_workers = self.config.max_concurrent_downloads
        logger.info(f"[å¹¶è¡Œä¸‹è½½] å¯ç”¨{max_workers}è·¯å¹¶è¡Œä¸‹è½½")

        # ä½¿ç”¨çº¿ç¨‹æ± å®ç°é¢„å–å¼å¹¶è¡Œä¸‹è½½
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = {}
            segment_iter = iter(task.segments)

            # åˆå§‹å¡«å……ï¼šæäº¤å‰Nä¸ªä¸‹è½½ä»»åŠ¡
            for _ in range(max_workers):
                if self._stop_flag.is_set():
                    break
                seg = next(segment_iter, None)
                if seg:
                    future = executor.submit(self._download_segment_return, task, seg)
                    futures[future] = seg

            # å®Œæˆä¸€ä¸ªï¼Œè¡¥å……ä¸€ä¸ªï¼ˆæµæ°´çº¿æ¨¡å¼ï¼‰
            while futures:
                if self._stop_flag.is_set():
                    # å–æ¶ˆæ‰€æœ‰æœªå®Œæˆçš„ä»»åŠ¡
                    for f in futures:
                        f.cancel()
                    break

                # ç­‰å¾…ä»»æ„ä¸€ä¸ªå®Œæˆ
                done_futures = []
                for future in list(futures.keys()):
                    if future.done():
                        done_futures.append(future)

                if not done_futures:
                    # æ²¡æœ‰å®Œæˆçš„ï¼ŒçŸ­æš‚ç­‰å¾…
                    time.sleep(0.1)
                    continue

                for future in done_futures:
                    segment = futures.pop(future)
                    try:
                        success = future.result()
                        if success:
                            logger.info(f"[å¹¶è¡Œä¸‹è½½] ç‰‡æ®µ#{segment.index} å®Œæˆï¼Œæ”¾å…¥åˆ†æé˜Ÿåˆ—")
                    except Exception as e:
                        logger.error(f"[å¹¶è¡Œä¸‹è½½] ç‰‡æ®µ#{segment.index} å¼‚å¸¸: {e}")

                    # è¡¥å……æ–°ä»»åŠ¡
                    if not self._stop_flag.is_set():
                        next_seg = next(segment_iter, None)
                        if next_seg:
                            new_future = executor.submit(self._download_segment_return, task, next_seg)
                            futures[new_future] = next_seg

        logger.info(f"[å¹¶è¡Œä¸‹è½½] ä¸‹è½½çº¿ç¨‹ç»“æŸ")

    def _download_segment_return(self, task: TaskInfo, segment: SegmentInfo) -> bool:
        """ä¸‹è½½å•ä¸ªç‰‡æ®µå¹¶è¿”å›ç»“æœï¼ˆç”¨äºå¹¶è¡Œä¸‹è½½ï¼‰"""
        self._download_segment(task, segment)
        return segment.download_status == SegmentStatus.COMPLETED

    def _download_segment(self, task: TaskInfo, segment: SegmentInfo):
        """ä¸‹è½½å•ä¸ªç‰‡æ®µ"""
        segment.download_status = SegmentStatus.DOWNLOADING

        self._emit_event(EventType.PROGRESS, {
            "task_id": task.task_id,
            "type": "download",
            "segment": segment.index,
            "total": len(task.segments),
            "time_range": segment.time_range,
            "status": "running",
            "message": f"æ­£åœ¨ä¸‹è½½ç‰‡æ®µ #{segment.index}"
        })

        self._log(task.task_id, "info",
                  f"ç‰‡æ®µ#{segment.index} å¼€å§‹ä¸‹è½½ ({segment.time_range})",
                  segment.index, category="download")

        retry_count = 0
        max_retries = self.config.download_retry_count

        while retry_count <= max_retries:
            try:
                # è·å–è§†é¢‘URL
                video_url = self.api.get_video_url_for_segment(
                    task.road_id,
                    task.channel_num,
                    segment.start_time,
                    segment.end_time,
                    progress_callback=lambda a, m, msg: self._log(
                        task.task_id, "debug", f"è½®è¯¢ {a}/{m}: {msg}", segment.index, category="download"
                    )
                )

                # ä¸‹è½½è§†é¢‘
                video_filename = f"segment_{segment.index:03d}_{segment.time_range.replace(':', '').replace('-', '_')}.mp4"
                video_path = os.path.join(self.config.temp_dir, task.task_id, video_filename)
                os.makedirs(os.path.dirname(video_path), exist_ok=True)

                # ä¸‹è½½è¿›åº¦å›è°ƒï¼Œä¿æŒSSEè¿æ¥
                def download_progress(downloaded: int, total: int):
                    if total > 0:
                        progress_mb = downloaded / (1024 * 1024)
                        total_mb = total / (1024 * 1024)
                        self._log(task.task_id, "debug",
                                  f"ä¸‹è½½è¿›åº¦: {progress_mb:.1f}MB / {total_mb:.1f}MB ({downloaded*100//total}%)",
                                  segment.index, category="download")
                    else:
                        # total=0 è¡¨ç¤ºåˆšå¼€å§‹ä¸‹è½½ï¼Œå‘é€å¿ƒè·³æ¶ˆæ¯é˜²æ­¢SSEè¶…æ—¶
                        self._log(task.task_id, "debug",
                                  f"æ­£åœ¨è¿æ¥è§†é¢‘æœåŠ¡å™¨...",
                                  segment.index, category="download")

                if download_video(video_url, video_path, progress_callback=download_progress):
                    segment.video_path = video_path
                    segment.download_status = SegmentStatus.COMPLETED

                    file_size = os.path.getsize(video_path) / (1024 * 1024)
                    self._log(task.task_id, "success",
                              f"ç‰‡æ®µ#{segment.index} ä¸‹è½½å®Œæˆ ({file_size:.1f}MB)",
                              segment.index, {"file_size_mb": file_size}, category="download")

                    # æ”¾å…¥åˆ†æé˜Ÿåˆ—
                    self.analyze_queue.put(segment)
                    self._update_queue_status(task)
                    return

                raise Exception("ä¸‹è½½å¤±è´¥")

            except TsingcloudAPIError as e:
                retry_count += 1
                segment.retry_count = retry_count
                segment.error_message = str(e)

                if retry_count <= max_retries:
                    self._log(task.task_id, "warning",
                              f"ç‰‡æ®µ#{segment.index} ä¸‹è½½å¤±è´¥ï¼Œ{self.config.download_retry_interval}ç§’åé‡è¯• ({retry_count}/{max_retries})",
                              segment.index, category="download")
                    self._emit_event(EventType.ERROR, {
                        "task_id": task.task_id,
                        "segment": segment.index,
                        "type": "download",
                        "message": str(e),
                        "retry_count": retry_count,
                        "max_retry": max_retries,
                        "will_retry": True,
                        "retry_in_seconds": self.config.download_retry_interval
                    })
                    time.sleep(self.config.download_retry_interval)
                else:
                    break

            except Exception as e:
                retry_count += 1
                segment.error_message = str(e)
                if retry_count <= max_retries:
                    time.sleep(self.config.download_retry_interval)
                else:
                    break

        # æ‰€æœ‰é‡è¯•å¤±è´¥
        segment.download_status = SegmentStatus.DOWNLOAD_FAILED
        self._log(task.task_id, "error",
                  f"ç‰‡æ®µ#{segment.index} ä¸‹è½½å¤±è´¥ï¼ˆå·²é‡è¯•{max_retries}æ¬¡ï¼‰: {segment.error_message}",
                  segment.index, category="download")
        self._emit_event(EventType.ERROR, {
            "task_id": task.task_id,
            "segment": segment.index,
            "type": "download",
            "message": segment.error_message,
            "retry_count": max_retries,
            "max_retry": max_retries,
            "will_retry": False
        })
        self._update_queue_status(task)

    def _analyze_worker(self, task: TaskInfo):
        """åˆ†æçº¿ç¨‹ï¼šæ¶ˆè´¹ä¸‹è½½å®Œæˆçš„è§†é¢‘"""
        while True:
            try:
                segment = self.analyze_queue.get(timeout=2)  # å‡å°‘ç­‰å¾…é—´éš™ï¼Œé˜²æ­¢SSEè¶…æ—¶
                if segment is None:  # ç»“æŸä¿¡å·
                    break
                self._analyze_segment(task, segment)
            except Empty:
                if self._stop_flag.is_set():
                    break
                continue

    def _analyze_segment(self, task: TaskInfo, segment: SegmentInfo):
        """åˆ†æå•ä¸ªç‰‡æ®µ"""
        if not segment.video_path or not os.path.exists(segment.video_path):
            segment.analyze_status = SegmentStatus.ANALYZE_FAILED
            segment.error_message = "è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨"
            return

        segment.analyze_status = SegmentStatus.ANALYZING

        self._emit_event(EventType.PROGRESS, {
            "task_id": task.task_id,
            "type": "analyze",
            "segment": segment.index,
            "total": len(task.segments),
            "time_range": segment.time_range,
            "status": "running",
            "message": f"æ­£åœ¨åˆ†æç‰‡æ®µ #{segment.index}"
        })

        self._log(task.task_id, "info",
                  f"ç‰‡æ®µ#{segment.index} å¼€å§‹åˆ†æ",
                  segment.index, category="analyze")

        try:
            # æ„å»ºæŸ¥è¯¢è¯
            if task.mode == "accident":
                user_query = "äº¤é€šäº‹æ•…"
            else:
                user_query = "äº¤é€šè¿æ³•: " + ", ".join(task.violation_types) if task.violation_types else "äº¤é€šè¿æ³•"

            # åˆ›å»ºè¿›åº¦å›è°ƒ - å°† Pipeline å†…éƒ¨è¿›åº¦å‘é€åˆ° SSE
            def progress_callback(percent: int, message: str):
                self._log(task.task_id, "debug",
                          f"[{percent}%] {message}",
                          segment.index, category="analyze")

            # è°ƒç”¨åˆ†æpipeline
            has_event = False
            event_type = None
            confidence = 0.0
            analysis_result = {}

            if self.pipeline_func:
                analysis_result = self.pipeline_func(
                    video_path=segment.video_path,
                    user_query=user_query,
                    mode=task.mode,
                    model=task.model,
                    progress_callback=progress_callback  # ä¼ å…¥è¿›åº¦å›è°ƒ
                )

                # è§£æç»“æœ
                has_event = analysis_result.get("has_event", False)
                event_type = analysis_result.get("event_type")
                confidence = analysis_result.get("confidence", 0.0)
            else:
                # æ²¡æœ‰pipelineï¼Œæ¨¡æ‹Ÿåˆ†æ
                logger.warning("æœªé…ç½®åˆ†æpipelineï¼Œè·³è¿‡å®é™…åˆ†æ")
                time.sleep(2)  # æ¨¡æ‹Ÿåˆ†æè€—æ—¶

            segment.analyze_status = SegmentStatus.COMPLETED

            if has_event:
                # æ£€å‡ºäº‹ä»¶ - ä¿å­˜è¯æ®
                segment.result = "detected"
                segment.event_type = event_type
                segment.confidence = confidence
                task.events_found += 1

                # ä¿å­˜è¯æ®
                evidence_path = self._save_evidence(task, segment, analysis_result)
                segment.evidence_path = evidence_path

                self._log(task.task_id, "warning",
                          f"âš ï¸ ç‰‡æ®µ#{segment.index} æ£€æµ‹åˆ°{event_type} (ç½®ä¿¡åº¦:{confidence:.2f})",
                          segment.index, category="analyze")

                # å‘é€ç»“æœäº‹ä»¶
                self._emit_event(EventType.RESULT, {
                    "task_id": task.task_id,
                    "segment": segment.index,
                    "time": segment.start_time.strftime("%H:%M:%S"),
                    "mode": task.mode,
                    "event_type": event_type,
                    "confidence": confidence,
                    "thumbnail": f"/api/history/thumbnail/{task.task_id}/{segment.index}"
                })

            else:
                # æ— äº‹ä»¶ - æ¸…ç†è§†é¢‘
                segment.result = "cleared"
                task.events_cleared += 1

                if self.config.cleanup_on_no_event:
                    self._cleanup_segment(segment)
                    self._log(task.task_id, "success",
                              f"ç‰‡æ®µ#{segment.index} åˆ†æå®Œæˆ - æ— äº‹æ•… - å·²æ¸…ç† âœ“",
                              segment.index, {"action": "cleanup"}, category="analyze")
                else:
                    self._log(task.task_id, "success",
                              f"ç‰‡æ®µ#{segment.index} åˆ†æå®Œæˆ - æ— äº‹æ•…",
                              segment.index, category="analyze")

        except Exception as e:
            segment.analyze_status = SegmentStatus.ANALYZE_FAILED
            segment.error_message = str(e)
            self._log(task.task_id, "error",
                      f"ç‰‡æ®µ#{segment.index} åˆ†æå¤±è´¥: {e}",
                      segment.index, category="analyze")

        self._update_queue_status(task)

    def _save_evidence(self, task: TaskInfo, segment: SegmentInfo, analysis_result: dict) -> str:
        """ä¿å­˜äº‹ä»¶è¯æ®"""
        task_dir = os.path.join(self.config.result_dir, task.task_id)
        segment_dir = os.path.join(task_dir, f"segment_{segment.index:03d}")
        os.makedirs(segment_dir, exist_ok=True)

        # ç§»åŠ¨åŸå§‹è§†é¢‘
        if segment.video_path and os.path.exists(segment.video_path):
            original_path = os.path.join(segment_dir, "original.mp4")
            shutil.move(segment.video_path, original_path)
            segment.video_path = original_path

        # ä¿å­˜åˆ†æç»“æœ
        result_path = os.path.join(segment_dir, "vlm_result.json")
        with open(result_path, 'w', encoding='utf-8') as f:
            json.dump({
                "segment_index": segment.index,
                "time_range": segment.time_range,
                "event_type": segment.event_type,
                "confidence": segment.confidence,
                "analysis": analysis_result
            }, f, ensure_ascii=False, indent=2)

        # ä¿å­˜å…³é”®å¸§ï¼ˆå¦‚æœæœ‰ï¼‰
        keyframes = analysis_result.get("keyframes", [])
        if keyframes:
            keyframes_dir = os.path.join(segment_dir, "keyframes")
            os.makedirs(keyframes_dir, exist_ok=True)
            for i, kf in enumerate(keyframes):
                if isinstance(kf, str) and os.path.exists(kf):
                    dst = os.path.join(keyframes_dir, f"frame_{i:03d}.jpg")
                    shutil.copy(kf, dst)

        return segment_dir

    def _cleanup_segment(self, segment: SegmentInfo):
        """æ¸…ç†æ— äº‹ä»¶çš„ç‰‡æ®µ"""
        if segment.video_path and os.path.exists(segment.video_path):
            try:
                os.remove(segment.video_path)
                segment.video_path = None
            except Exception as e:
                logger.warning(f"æ¸…ç†è§†é¢‘å¤±è´¥: {e}")

    def _update_queue_status(self, task: TaskInfo):
        """æ›´æ–°å¹¶å‘é€é˜Ÿåˆ—çŠ¶æ€"""
        completed = sum(1 for s in task.segments
                       if s.download_status in [SegmentStatus.COMPLETED, SegmentStatus.SKIPPED]
                       and s.analyze_status in [SegmentStatus.COMPLETED, SegmentStatus.SKIPPED])

        self._emit_event(EventType.QUEUE, {
            "task_id": task.task_id,
            "segments": [s.to_dict() for s in task.segments],
            "completed": completed,
            "total": len(task.segments)
        })

    def _generate_report(self, task: TaskInfo):
        """ç”ŸæˆHTMLæŠ¥å‘Š"""
        task_dir = os.path.join(self.config.result_dir, task.task_id)
        report_path = os.path.join(task_dir, "report.html")

        # æ”¶é›†äº‹ä»¶
        events = []
        for seg in task.segments:
            if seg.result == "detected":
                events.append({
                    "index": seg.index,
                    "time_range": seg.time_range,
                    "event_type": seg.event_type,
                    "confidence": seg.confidence,
                    "evidence_path": seg.evidence_path
                })

        # ç”Ÿæˆç®€å•çš„HTMLæŠ¥å‘Š
        html_content = f"""<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <title>å†å²è§†é¢‘åˆ†ææŠ¥å‘Š - {task.task_id}</title>
    <style>
        body {{ font-family: 'Microsoft YaHei', sans-serif; margin: 40px; background: #f5f5f5; }}
        .container {{ max-width: 1000px; margin: 0 auto; background: white; padding: 30px; border-radius: 10px; }}
        h1 {{ color: #333; border-bottom: 2px solid #007bff; padding-bottom: 10px; }}
        .summary {{ background: #f8f9fa; padding: 20px; border-radius: 8px; margin: 20px 0; }}
        .event-card {{ border: 1px solid #ddd; border-radius: 8px; padding: 15px; margin: 10px 0; }}
        .event-card.detected {{ border-left: 4px solid #ff9800; }}
        .badge {{ display: inline-block; padding: 4px 10px; border-radius: 4px; font-size: 12px; }}
        .badge-warning {{ background: #fff3e0; color: #e65100; }}
        .badge-success {{ background: #e8f5e9; color: #2e7d32; }}
    </style>
</head>
<body>
    <div class="container">
        <h1>ğŸ“Š å†å²è§†é¢‘åˆ†ææŠ¥å‘Š</h1>

        <div class="summary">
            <p><strong>ä»»åŠ¡ID:</strong> {task.task_id}</p>
            <p><strong>è·¯å£:</strong> {task.road_id} | <strong>æ‘„åƒå¤´:</strong> {task.channel_num}</p>
            <p><strong>æ—¶é—´æ®µ:</strong> {task.start_date} {task.start_time} â†’ {task.end_date} {task.end_time}</p>
            <p><strong>åˆ†ææ¨¡å¼:</strong> {"äº¤é€šäº‹æ•…æ£€æµ‹" if task.mode == "accident" else "äº¤é€šè¿æ³•æ£€æµ‹"}</p>
            <p><strong>VLMæ¨¡å‹:</strong> {task.model}</p>
            <hr>
            <p><strong>æ€»ç‰‡æ®µæ•°:</strong> {len(task.segments)}</p>
            <p><strong>æ£€å‡ºäº‹ä»¶:</strong> <span class="badge badge-warning">{task.events_found} èµ·</span></p>
            <p><strong>æ— å¼‚å¸¸:</strong> <span class="badge badge-success">{task.events_cleared} ä¸ª</span></p>
        </div>

        <h2>ğŸ“‹ æ£€å‡ºäº‹ä»¶è¯¦æƒ…</h2>
        {"".join(f'''
        <div class="event-card detected">
            <h3>#{e["index"]} - {e["event_type"]}</h3>
            <p>æ—¶é—´æ®µ: {e["time_range"]}</p>
            <p>ç½®ä¿¡åº¦: {e["confidence"]:.2%}</p>
            <p>è¯æ®è·¯å¾„: {e["evidence_path"]}</p>
        </div>
        ''' for e in events) if events else '<p>æœªæ£€å‡ºä»»ä½•äº‹ä»¶</p>'}
    </div>
</body>
</html>"""

        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(html_content)

        self._log(task.task_id, "info", f"æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
        return report_path

    def get_task_status(self, task_id: str) -> Optional[dict]:
        """è·å–ä»»åŠ¡çŠ¶æ€"""
        task = self.tasks.get(task_id)
        if not task:
            return None

        completed = sum(1 for s in task.segments
                       if s.analyze_status == SegmentStatus.COMPLETED)

        return {
            **task.to_dict(),
            "completed_segments": completed,
            "segments": [s.to_dict() for s in task.segments]
        }

    def stream_progress(self, task_id: str) -> Generator[str, None, None]:
        """SSEè¿›åº¦æµç”Ÿæˆå™¨"""
        task = self.tasks.get(task_id)
        if not task:
            yield f"event: error\ndata: {{\"message\": \"ä»»åŠ¡ä¸å­˜åœ¨\"}}\n\n"
            return

        # åˆå§‹çŠ¶æ€
        yield f"event: queue\ndata: {json.dumps({'segments': [s.to_dict() for s in task.segments], 'completed': 0, 'total': len(task.segments)})}\n\n"

        # æŒç»­æ¨é€ç›´åˆ°ä»»åŠ¡å®Œæˆ
        while task.status == "running":
            time.sleep(1)
            # å®é™…äº‹ä»¶é€šè¿‡event_callbackæ¨é€

        # æœ€ç»ˆçŠ¶æ€
        yield f"event: complete\ndata: {json.dumps(task.to_dict())}\n\n"
